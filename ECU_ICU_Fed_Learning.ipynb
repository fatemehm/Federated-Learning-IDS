{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatemehm/Federated-Learning-IDS/blob/main/ECU_ICU_Fed_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client1 = pd.read_csv('/content/drive/MyDrive/GlobeCom/client_df1.csv')\n",
        "client1_shuffled = client1.sample(frac=1, random_state = 13).reset_index(drop = True)\n",
        "\n",
        "client2 = pd.read_csv('/content/drive/MyDrive/GlobeCom/client_df2.csv')\n",
        "client2_shuffled = client2.sample(frac=1, random_state = 13).reset_index(drop = True)\n",
        "\n",
        "client3 = pd.read_csv('/content/drive/MyDrive/GlobeCom/client_df3.csv')\n",
        "client3_shuffled = client3.sample(frac=1, random_state = 13).reset_index(drop = True)\n",
        "\n",
        "client4 = pd.read_csv('/content/drive/MyDrive/GlobeCom/client_df4.csv')\n",
        "client4_shuffled = client4.sample(frac=1, random_state = 13).reset_index(drop = True)\n",
        "\n",
        "client5 = pd.read_csv('/content/drive/MyDrive/GlobeCom/client_df5.csv')\n",
        "client5_shuffled = client5.sample(frac=1, random_state = 13).reset_index(drop = True)"
      ],
      "metadata": {
        "id": "5FZZfHaJXBOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "BATCH_SIZE = 1024\n",
        "#BATCH_SIZE = 64 #ECU"
      ],
      "metadata": {
        "id": "rykWdF8zXQaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def make_tf_dataset(dataframe, negative_ratio=None, batch_size=None):\n",
        "  \n",
        "    dataset = dataframe.drop(['Unnamed: 0'], axis=1)#, 'SrcGap', 'DstGap', 'DIntPktAct','sMinPktSz', 'Trans'\n",
        "    # Class balancing\n",
        "    pos_df = dataset[dataset['Label'] == 1]\n",
        "    neg_df = dataset[dataset['Label'] == 0]\n",
        "    if negative_ratio:\n",
        "        neg_df = neg_df.iloc[random.sample(range(0, len(neg_df)), len(pos_df)*negative_ratio), :]\n",
        "    balanced_df = pd.concat([pos_df, neg_df], ignore_index=True, sort=False)\n",
        "\n",
        "    y = balanced_df.pop('Label')\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((balanced_df.values, y.to_frame().values))\n",
        "    dataset = dataset.shuffle(4048, seed=SEED) #2048\n",
        "    if batch_size:\n",
        "        dataset = dataset.batch(batch_size)\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "vUjZZJ53XUrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "train_data, val_data = [], []\n",
        "\n",
        "for client_data in [client1_shuffled, client2_shuffled, client3_shuffled, client4_shuffled, client5_shuffled]:\n",
        "                     \n",
        "                   \n",
        "    train_df, val_df = train_test_split(client_data, test_size=0.1, random_state=1337)\n",
        "\n",
        "    # Scaling (Standardization actually hurts performance) \n",
        "    encoder = LabelEncoder()\n",
        "    scaler = StandardScaler() \n",
        "    train_features = scaler.fit_transform(train_df.drop(['Label'], axis=1))\n",
        "    val_features = scaler.transform(val_df.drop(['Label'], axis=1))\n",
        "\n",
        "    train_df[train_df.columns.difference(['Label'])] = train_features\n",
        "    val_df[val_df.columns.difference(['Label'])] = val_features\n",
        "\n",
        "    # TF Datasets\n",
        "    train_data.append(make_tf_dataset(train_df,negative_ratio=2, batch_size=BATCH_SIZE)) #negative_ratio=2\n",
        "    val_data.append(make_tf_dataset(val_df, batch_size=16))"
      ],
      "metadata": {
        "id": "CBajSViPXcH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.metrics import CategoricalAccuracy, Precision, Recall, BinaryAccuracy\n",
        "def input_spec():\n",
        "    return (\n",
        "        tf.TensorSpec([None, 35], tf.float64),\n",
        "        tf.TensorSpec([None, 1], tf.int64)\n",
        "    )\n",
        "\n",
        "def model_fn():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(35,)),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "    ])\n",
        "\n",
        "    return tff.learning.from_keras_model(\n",
        "        model,\n",
        "        input_spec=input_spec(),\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.BinaryAccuracy(), Precision(), Recall()]\n",
        "        )"
      ],
      "metadata": {
        "id": "ncs_0NS3XsrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = tff.learning.build_federated_averaging_process(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.05)#learning_rate=0.01\n",
        ")"
      ],
      "metadata": {
        "id": "A12lqKtBXwRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str(trainer.initialize.type_signature)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Z-lYNrc_X0WK",
        "outputId": "62e78f72-b410-4889-c376-5088e4c541e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'( -> <model=<trainable=<float32[35,32],float32[32],float32[32,64],float32[64],float32[64,32],float32[32],float32[32,1],float32[1]>,non_trainable=<>>,optimizer_state=<int64,float32[35,32],float32[32],float32[32,64],float32[64],float32[64,32],float32[32],float32[32,1],float32[1],float32[35,32],float32[32],float32[32,64],float32[64],float32[64,32],float32[32],float32[32,1],float32[1]>,delta_aggregate_state=<value_sum_process=<>,weight_sum_process=<>>,model_broadcast_state=<>>@SERVER)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state = trainer.initialize()"
      ],
      "metadata": {
        "id": "9KugvyS4X3PM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "#state = trainer.initialize()\n",
        "train_hist = []\n",
        "for i in range(EPOCHS):\n",
        "    state, metrics = trainer.next(state, train_data)\n",
        "    train_hist.append(metrics)\n",
        "\n",
        "    print(f\"\\rRun {i+1}/{EPOCHS}\", end=\"\")\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O77iLIelX-VL",
        "outputId": "112b1daa-241e-44a4-c376-c542a317b980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 50/50Training time: 3.2901763916015625e-05\n",
            "Test time: 1.4543533325195312e-05\n",
            "\n",
            "TIME: 97.76304984092712seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics)"
      ],
      "metadata": {
        "id": "9nzYAbEwYClY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_hist"
      ],
      "metadata": {
        "id": "y6hQsJJDYHNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "federated_metrics = evaluator(state.model, val_data)\n",
        "federated_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NylxveEYNBu",
        "outputId": "c44f3a99-94ad-4d74-cb1e-48fa0e14ddcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('eval',\n",
              "              OrderedDict([('binary_accuracy', 0.9223242),\n",
              "                           ('precision', 0.7183908),\n",
              "                           ('recall', 0.61576355),\n",
              "                           ('loss', 0.257914),\n",
              "                           ('num_examples', 1635),\n",
              "                           ('num_batches', 105)]))])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Centralized-wus**"
      ],
      "metadata": {
        "id": "cu2ypkwsdlXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import missingno as msno\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "zDTU21tkdvHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_uni = pd.read_csv('/content/drive/MyDrive/GlobeCom/clean_wustl.csv')\n",
        "shape = df_uni.shape\n",
        "print('Dataframe shape: ', shape)\n",
        "print('Number of rows: ', shape[0])\n",
        "print('Number of columns: ', shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Iop262ed5Xx",
        "outputId": "0a474987-6119-47a8-bdce-71732a7b0196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe shape:  (16315, 37)\n",
            "Number of rows:  16315\n",
            "Number of columns:  37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_uni.Label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdMMcghud-cI",
        "outputId": "dffb876b-01b4-43a4-f648-58d632e4a298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    14269\n",
              "1     2046\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_columns = ['Unnamed: 0']#, 'Flgs','SrcAddr',\t'DstAddr', 'Dport', 'SrcMac',\t'DstMac',\t'Packet_num']\t\t\n",
        "df_uni= df_uni.drop(columns=drop_columns)\n",
        "df_uni.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAt0zg34eE-E",
        "outputId": "dde385d0-0732-4c08-fd3d-f90e29329a35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16315 entries, 0 to 16314\n",
            "Data columns (total 36 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Sport       16315 non-null  float64\n",
            " 1   SrcBytes    16315 non-null  float64\n",
            " 2   DstBytes    16315 non-null  float64\n",
            " 3   SrcLoad     16315 non-null  float64\n",
            " 4   DstLoad     16315 non-null  float64\n",
            " 5   SrcGap      16315 non-null  float64\n",
            " 6   DstGap      16315 non-null  float64\n",
            " 7   SIntPkt     16315 non-null  float64\n",
            " 8   DIntPkt     16315 non-null  float64\n",
            " 9   SIntPktAct  16315 non-null  float64\n",
            " 10  DIntPktAct  16315 non-null  float64\n",
            " 11  SrcJitter   16315 non-null  float64\n",
            " 12  DstJitter   16315 non-null  float64\n",
            " 13  sMaxPktSz   16315 non-null  float64\n",
            " 14  dMaxPktSz   16315 non-null  float64\n",
            " 15  sMinPktSz   16315 non-null  float64\n",
            " 16  dMinPktSz   16315 non-null  float64\n",
            " 17  Dur         16315 non-null  float64\n",
            " 18  Trans       16315 non-null  float64\n",
            " 19  TotPkts     16315 non-null  float64\n",
            " 20  TotBytes    16315 non-null  float64\n",
            " 21  Load        16315 non-null  float64\n",
            " 22  Loss        16315 non-null  float64\n",
            " 23  pLoss       16315 non-null  float64\n",
            " 24  pSrcLoss    16315 non-null  float64\n",
            " 25  pDstLoss    16315 non-null  float64\n",
            " 26  Rate        16315 non-null  float64\n",
            " 27  Temp        16315 non-null  float64\n",
            " 28  SpO2        16315 non-null  float64\n",
            " 29  Pulse_Rate  16315 non-null  float64\n",
            " 30  SYS         16315 non-null  float64\n",
            " 31  DIA         16315 non-null  float64\n",
            " 32  Heart_rate  16315 non-null  float64\n",
            " 33  Resp_Rate   16315 non-null  float64\n",
            " 34  ST          16315 non-null  float64\n",
            " 35  Label       16315 non-null  int64  \n",
            "dtypes: float64(35), int64(1)\n",
            "memory usage: 4.5 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_uni = df_uni.drop('Label', axis = 1)\n",
        "y_uni = df_uni['Label']\n",
        "X_uni.shape, y_uni.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu-oqo1FeVIu",
        "outputId": "4abf2349-ab48-49f6-eef5-c60775754147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16315, 35), (16315,))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "X_uni_smote, y_uni_smote = SMOTE().fit_resample(X_uni, y_uni)"
      ],
      "metadata": {
        "id": "SjKyHLDtebMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7P09p8XmeguV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "#from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_uni_train, X_uni_test, y_uni_train, y_uni_test = train_test_split(X_uni_smote, y_uni_smote, test_size=0.2, random_state = 1337)"
      ],
      "metadata": {
        "id": "ZdJKxBSFekHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaling = StandardScaler()\n",
        "X_uni_train = scaling.fit_transform(X_uni_train)\n",
        "X_uni_test = scaling.transform(X_uni_test)"
      ],
      "metadata": {
        "id": "RJSDjAwyer9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For CNN and CNN-LSTM\n",
        "X_uni_train = X_uni_train.reshape(X_uni_train.shape[0], X_uni_train.shape[1], 1)\n",
        "X_uni_test = X_uni_test.reshape(X_uni_test.shape[0], X_uni_test.shape[1], 1)"
      ],
      "metadata": {
        "id": "And5IMQX0QpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM**"
      ],
      "metadata": {
        "id": "cpx6MJl_zKOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import time\n",
        "import time\n",
        "start = time.time()\n",
        "#from keras.optimizers import SGD\n",
        "#opt = SGD(lr=0.0001)\n",
        "#batch_size = 64\n",
        "\n",
        "# 1. define the network\n",
        "model = Sequential()\n",
        "model.add(LSTM(4,input_shape = X_uni_train[0].shape))  \n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_uni_train, y_uni_train, epochs=50, batch_size = 20, validation_data=(X_uni_test, y_uni_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_uni_test, y_uni_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_uni_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_uni_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_uni_test, y_preds_cnn))\n",
        "print(accuracy_score(y_uni_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_uni_test, y_preds_cnn))\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8jKHuA0zNO0",
        "outputId": "3459e4d2-9594-4341-b9bf-649b8d0adc64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1142/1142 [==============================] - 22s 16ms/step - loss: 0.6852 - accuracy: 0.5409 - val_loss: 0.6078 - val_accuracy: 0.6780\n",
            "Epoch 2/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6822 - accuracy: 0.5523 - val_loss: 0.6614 - val_accuracy: 0.6137\n",
            "Epoch 3/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6599 - accuracy: 0.5845 - val_loss: 0.6734 - val_accuracy: 0.6163\n",
            "Epoch 4/50\n",
            "1142/1142 [==============================] - 17s 15ms/step - loss: 0.6431 - accuracy: 0.6009 - val_loss: 0.5997 - val_accuracy: 0.7102\n",
            "Epoch 5/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6845 - accuracy: 0.5498 - val_loss: 0.6924 - val_accuracy: 0.5205\n",
            "Epoch 6/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6993 - accuracy: 0.5053 - val_loss: 0.6954 - val_accuracy: 0.4788\n",
            "Epoch 7/50\n",
            "1142/1142 [==============================] - 17s 15ms/step - loss: 0.6880 - accuracy: 0.5330 - val_loss: 0.6937 - val_accuracy: 0.5033\n",
            "Epoch 8/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6910 - accuracy: 0.5293 - val_loss: 0.6845 - val_accuracy: 0.5286\n",
            "Epoch 9/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6871 - accuracy: 0.5338 - val_loss: 0.6922 - val_accuracy: 0.5825\n",
            "Epoch 10/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6805 - accuracy: 0.5490 - val_loss: 0.6716 - val_accuracy: 0.5925\n",
            "Epoch 11/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6823 - accuracy: 0.5483 - val_loss: 0.6689 - val_accuracy: 0.5708\n",
            "Epoch 12/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6744 - accuracy: 0.5538 - val_loss: 0.6706 - val_accuracy: 0.4953\n",
            "Epoch 13/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6849 - accuracy: 0.5323 - val_loss: 0.6544 - val_accuracy: 0.5876\n",
            "Epoch 14/50\n",
            "1142/1142 [==============================] - 17s 14ms/step - loss: 0.6801 - accuracy: 0.5363 - val_loss: 0.6791 - val_accuracy: 0.5296\n",
            "Epoch 15/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6755 - accuracy: 0.5419 - val_loss: 0.6467 - val_accuracy: 0.6197\n",
            "Epoch 16/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6859 - accuracy: 0.5308 - val_loss: 0.6787 - val_accuracy: 0.5559\n",
            "Epoch 17/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6890 - accuracy: 0.5268 - val_loss: 0.6741 - val_accuracy: 0.5589\n",
            "Epoch 18/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6856 - accuracy: 0.5293 - val_loss: 0.6770 - val_accuracy: 0.5836\n",
            "Epoch 19/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6851 - accuracy: 0.5296 - val_loss: 0.6616 - val_accuracy: 0.5690\n",
            "Epoch 20/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6778 - accuracy: 0.5437 - val_loss: 0.6609 - val_accuracy: 0.5785\n",
            "Epoch 21/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6794 - accuracy: 0.5417 - val_loss: 0.6625 - val_accuracy: 0.6056\n",
            "Epoch 22/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6770 - accuracy: 0.5428 - val_loss: 0.6618 - val_accuracy: 0.6072\n",
            "Epoch 23/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6759 - accuracy: 0.5468 - val_loss: 0.6543 - val_accuracy: 0.5897\n",
            "Epoch 24/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6833 - accuracy: 0.5417 - val_loss: 0.6674 - val_accuracy: 0.5950\n",
            "Epoch 25/50\n",
            "1142/1142 [==============================] - 27s 23ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6892 - val_accuracy: 0.5378\n",
            "Epoch 26/50\n",
            "1142/1142 [==============================] - 28s 24ms/step - loss: 0.6983 - accuracy: 0.5061 - val_loss: 0.6917 - val_accuracy: 0.5016\n",
            "Epoch 27/50\n",
            "1142/1142 [==============================] - 25s 22ms/step - loss: 0.6976 - accuracy: 0.5070 - val_loss: 0.6962 - val_accuracy: 0.5039\n",
            "Epoch 28/50\n",
            "1142/1142 [==============================] - 22s 19ms/step - loss: 0.6982 - accuracy: 0.5065 - val_loss: 0.6875 - val_accuracy: 0.5552\n",
            "Epoch 29/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6972 - accuracy: 0.5104 - val_loss: 0.6906 - val_accuracy: 0.5254\n",
            "Epoch 30/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6975 - accuracy: 0.5122 - val_loss: 0.6896 - val_accuracy: 0.5037\n",
            "Epoch 31/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6967 - accuracy: 0.5183 - val_loss: 0.7014 - val_accuracy: 0.5130\n",
            "Epoch 32/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6961 - accuracy: 0.5177 - val_loss: 0.7030 - val_accuracy: 0.5040\n",
            "Epoch 33/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.7012 - accuracy: 0.5012 - val_loss: 0.6966 - val_accuracy: 0.5018\n",
            "Epoch 34/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6968 - accuracy: 0.5127 - val_loss: 0.6787 - val_accuracy: 0.5300\n",
            "Epoch 35/50\n",
            "1142/1142 [==============================] - 17s 15ms/step - loss: 0.6915 - accuracy: 0.5252 - val_loss: 0.6840 - val_accuracy: 0.5361\n",
            "Epoch 36/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.7006 - accuracy: 0.4958 - val_loss: 0.6942 - val_accuracy: 0.4960\n",
            "Epoch 37/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6999 - accuracy: 0.5061 - val_loss: 0.6899 - val_accuracy: 0.5072\n",
            "Epoch 38/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6983 - accuracy: 0.5145 - val_loss: 0.6994 - val_accuracy: 0.5138\n",
            "Epoch 39/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6979 - accuracy: 0.5137 - val_loss: 0.6913 - val_accuracy: 0.5126\n",
            "Epoch 40/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6941 - accuracy: 0.5175 - val_loss: 0.6800 - val_accuracy: 0.5571\n",
            "Epoch 41/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6951 - accuracy: 0.5190 - val_loss: 0.6868 - val_accuracy: 0.5538\n",
            "Epoch 42/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6960 - accuracy: 0.5197 - val_loss: 0.6894 - val_accuracy: 0.5394\n",
            "Epoch 43/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6982 - accuracy: 0.5116 - val_loss: 0.6902 - val_accuracy: 0.5194\n",
            "Epoch 44/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.7006 - accuracy: 0.5016 - val_loss: 0.6903 - val_accuracy: 0.5102\n",
            "Epoch 45/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6997 - accuracy: 0.5054 - val_loss: 0.6972 - val_accuracy: 0.4965\n",
            "Epoch 46/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.7004 - accuracy: 0.5001 - val_loss: 0.6937 - val_accuracy: 0.5095\n",
            "Epoch 47/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6984 - accuracy: 0.5057 - val_loss: 0.6959 - val_accuracy: 0.5075\n",
            "Epoch 48/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6986 - accuracy: 0.5013 - val_loss: 0.6956 - val_accuracy: 0.4960\n",
            "Epoch 49/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.6992 - accuracy: 0.4982 - val_loss: 0.6901 - val_accuracy: 0.5273\n",
            "Epoch 50/50\n",
            "1142/1142 [==============================] - 16s 14ms/step - loss: 0.7017 - accuracy: 0.4991 - val_loss: 0.6939 - val_accuracy: 0.4928\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.6939 - accuracy: 0.4928\n",
            "[0.6938616037368774, 0.49281710386276245]\n",
            "[[1718 1113]\n",
            " [1782 1095]]\n",
            "0.49281709880868957\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.61      0.54      2831\n",
            "           1       0.50      0.38      0.43      2877\n",
            "\n",
            "    accuracy                           0.49      5708\n",
            "   macro avg       0.49      0.49      0.49      5708\n",
            "weighted avg       0.49      0.49      0.49      5708\n",
            "\n",
            "Training time: 5.53131103515625e-05\n",
            "Test time: 1.5735626220703125e-05\n",
            "\n",
            "TIME: 0.0007197856903076172seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DNN**"
      ],
      "metadata": {
        "id": "dtnVOjPWzG0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from keras.layers import LSTM, SimpleRNN, GRU\n",
        "#from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "# 1. define the network\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(35,)),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_uni_train, y_uni_train, epochs=50, batch_size = 20, validation_data=(X_uni_test, y_uni_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_uni_test, y_uni_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_uni_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_uni_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_uni_test, y_preds_cnn))\n",
        "print(accuracy_score(y_uni_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_uni_test, y_preds_cnn))\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY0mMlNxfFU-",
        "outputId": "4b1e27eb-b8f0-4e90-defe-192914d65fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1142/1142 [==============================] - 3s 2ms/step - loss: 0.6669 - accuracy: 0.5853 - val_loss: 0.6960 - val_accuracy: 0.5040\n",
            "Epoch 2/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6963 - accuracy: 0.5022 - val_loss: 0.6937 - val_accuracy: 0.4960\n",
            "Epoch 3/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6961 - accuracy: 0.5023 - val_loss: 0.7028 - val_accuracy: 0.4960\n",
            "Epoch 4/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6954 - accuracy: 0.5038 - val_loss: 0.7013 - val_accuracy: 0.5040\n",
            "Epoch 5/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6961 - accuracy: 0.4957 - val_loss: 0.6968 - val_accuracy: 0.5040\n",
            "Epoch 6/50\n",
            "1142/1142 [==============================] - 3s 2ms/step - loss: 0.6958 - accuracy: 0.5004 - val_loss: 0.7043 - val_accuracy: 0.4960\n",
            "Epoch 7/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6959 - accuracy: 0.5023 - val_loss: 0.6938 - val_accuracy: 0.5040\n",
            "Epoch 8/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6962 - accuracy: 0.4953 - val_loss: 0.6956 - val_accuracy: 0.4960\n",
            "Epoch 9/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6958 - accuracy: 0.4990 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
            "Epoch 10/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6956 - accuracy: 0.5037 - val_loss: 0.6941 - val_accuracy: 0.5040\n",
            "Epoch 11/50\n",
            "1142/1142 [==============================] - 3s 2ms/step - loss: 0.6955 - accuracy: 0.5025 - val_loss: 0.6935 - val_accuracy: 0.5040\n",
            "Epoch 12/50\n",
            "1142/1142 [==============================] - 6s 5ms/step - loss: 0.6960 - accuracy: 0.4967 - val_loss: 0.6935 - val_accuracy: 0.4960\n",
            "Epoch 13/50\n",
            "1142/1142 [==============================] - 5s 5ms/step - loss: 0.6954 - accuracy: 0.4979 - val_loss: 0.6960 - val_accuracy: 0.5040\n",
            "Epoch 14/50\n",
            "1142/1142 [==============================] - 6s 5ms/step - loss: 0.6958 - accuracy: 0.5042 - val_loss: 0.6940 - val_accuracy: 0.5040\n",
            "Epoch 15/50\n",
            "1142/1142 [==============================] - 5s 4ms/step - loss: 0.6957 - accuracy: 0.5000 - val_loss: 0.6948 - val_accuracy: 0.4960\n",
            "Epoch 16/50\n",
            "1142/1142 [==============================] - 5s 5ms/step - loss: 0.6961 - accuracy: 0.5014 - val_loss: 0.6932 - val_accuracy: 0.5040\n",
            "Epoch 17/50\n",
            "1142/1142 [==============================] - 5s 5ms/step - loss: 0.6952 - accuracy: 0.5015 - val_loss: 0.6940 - val_accuracy: 0.5040\n",
            "Epoch 18/50\n",
            "1142/1142 [==============================] - 4s 4ms/step - loss: 0.6955 - accuracy: 0.5062 - val_loss: 0.6957 - val_accuracy: 0.5040\n",
            "Epoch 19/50\n",
            "1142/1142 [==============================] - 4s 4ms/step - loss: 0.6954 - accuracy: 0.5053 - val_loss: 0.6935 - val_accuracy: 0.5040\n",
            "Epoch 20/50\n",
            "1142/1142 [==============================] - 3s 3ms/step - loss: 0.6962 - accuracy: 0.4982 - val_loss: 0.6943 - val_accuracy: 0.4960\n",
            "Epoch 21/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6956 - accuracy: 0.4993 - val_loss: 0.6977 - val_accuracy: 0.4960\n",
            "Epoch 22/50\n",
            "1142/1142 [==============================] - 3s 2ms/step - loss: 0.6953 - accuracy: 0.4975 - val_loss: 0.7022 - val_accuracy: 0.5040\n",
            "Epoch 23/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6961 - accuracy: 0.4960 - val_loss: 0.6946 - val_accuracy: 0.4960\n",
            "Epoch 24/50\n",
            "1142/1142 [==============================] - 3s 2ms/step - loss: 0.6952 - accuracy: 0.5006 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
            "Epoch 25/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6954 - accuracy: 0.5035 - val_loss: 0.6940 - val_accuracy: 0.5040\n",
            "Epoch 26/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6958 - accuracy: 0.5042 - val_loss: 0.6941 - val_accuracy: 0.4960\n",
            "Epoch 27/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6954 - accuracy: 0.4991 - val_loss: 0.7056 - val_accuracy: 0.5040\n",
            "Epoch 28/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6955 - accuracy: 0.4992 - val_loss: 0.6939 - val_accuracy: 0.4960\n",
            "Epoch 29/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6953 - accuracy: 0.5036 - val_loss: 0.6962 - val_accuracy: 0.5040\n",
            "Epoch 30/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6965 - accuracy: 0.5009 - val_loss: 0.6975 - val_accuracy: 0.5040\n",
            "Epoch 31/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6961 - accuracy: 0.5023 - val_loss: 0.6973 - val_accuracy: 0.5040\n",
            "Epoch 32/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6961 - accuracy: 0.4972 - val_loss: 0.7003 - val_accuracy: 0.5040\n",
            "Epoch 33/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6965 - accuracy: 0.4957 - val_loss: 0.6953 - val_accuracy: 0.4960\n",
            "Epoch 34/50\n",
            "1142/1142 [==============================] - 3s 2ms/step - loss: 0.6959 - accuracy: 0.4945 - val_loss: 0.6943 - val_accuracy: 0.4960\n",
            "Epoch 35/50\n",
            "1142/1142 [==============================] - 3s 2ms/step - loss: 0.6960 - accuracy: 0.5006 - val_loss: 0.6932 - val_accuracy: 0.4960\n",
            "Epoch 36/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6958 - accuracy: 0.5083 - val_loss: 0.7067 - val_accuracy: 0.4960\n",
            "Epoch 37/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6964 - accuracy: 0.4993 - val_loss: 0.6952 - val_accuracy: 0.4960\n",
            "Epoch 38/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6962 - accuracy: 0.5007 - val_loss: 0.7006 - val_accuracy: 0.4960\n",
            "Epoch 39/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6956 - accuracy: 0.4968 - val_loss: 0.6987 - val_accuracy: 0.4960\n",
            "Epoch 40/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6959 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
            "Epoch 41/50\n",
            "1142/1142 [==============================] - 3s 3ms/step - loss: 0.6952 - accuracy: 0.4976 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
            "Epoch 42/50\n",
            "1142/1142 [==============================] - 4s 3ms/step - loss: 0.6962 - accuracy: 0.5040 - val_loss: 0.6932 - val_accuracy: 0.4960\n",
            "Epoch 43/50\n",
            "1142/1142 [==============================] - 4s 4ms/step - loss: 0.6959 - accuracy: 0.4995 - val_loss: 0.6949 - val_accuracy: 0.5040\n",
            "Epoch 44/50\n",
            "1142/1142 [==============================] - 5s 4ms/step - loss: 0.6958 - accuracy: 0.5022 - val_loss: 0.6934 - val_accuracy: 0.5040\n",
            "Epoch 45/50\n",
            "1142/1142 [==============================] - 7s 6ms/step - loss: 0.6952 - accuracy: 0.5078 - val_loss: 0.6936 - val_accuracy: 0.5040\n",
            "Epoch 46/50\n",
            "1142/1142 [==============================] - 4s 3ms/step - loss: 0.6964 - accuracy: 0.4993 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
            "Epoch 47/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6966 - accuracy: 0.4951 - val_loss: 0.6949 - val_accuracy: 0.5040\n",
            "Epoch 48/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6958 - accuracy: 0.4913 - val_loss: 0.6932 - val_accuracy: 0.4960\n",
            "Epoch 49/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6955 - accuracy: 0.5000 - val_loss: 0.6975 - val_accuracy: 0.4960\n",
            "Epoch 50/50\n",
            "1142/1142 [==============================] - 2s 2ms/step - loss: 0.6954 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
            "179/179 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5040\n",
            "[0.6931349635124207, 0.5040294528007507]\n",
            "[[   0 2831]\n",
            " [   0 2877]]\n",
            "0.5040294323756132\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      2831\n",
            "           1       0.50      1.00      0.67      2877\n",
            "\n",
            "    accuracy                           0.50      5708\n",
            "   macro avg       0.25      0.50      0.34      5708\n",
            "weighted avg       0.25      0.50      0.34      5708\n",
            "\n",
            "Training time: 7.224082946777344e-05\n",
            "Test time: 2.765655517578125e-05\n",
            "\n",
            "TIME: 0.001308441162109375seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN-LSTM**"
      ],
      "metadata": {
        "id": "G9hvxaMy2M_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###############LSTM###################################\n",
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda\n",
        "\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, Dense, Dropout, Flatten, MaxPooling1D\n",
        "\n",
        "from keras.layers import LSTM, GRU, SimpleRNN\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "lstm_output_size = 20\n",
        "epochs = 10\n",
        "model = Sequential()\n",
        "model.add(Conv1D(32, 2, activation='relu', input_shape = X_uni_train[0].shape))\n",
        "\n",
        "model.add(SimpleRNN(lstm_output_size))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_uni_train, y_uni_train, epochs=50, batch_size = 20, validation_data=(X_uni_test, y_uni_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_uni_test, y_uni_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_uni_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_uni_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_uni_test, y_preds_cnn))\n",
        "print(accuracy_score(y_uni_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_uni_test, y_preds_cnn))\n",
        "\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6HzSFnt2OAH",
        "outputId": "28ed971b-1699-48d5-f3d6-c9ea524354b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1142/1142 [==============================] - 11s 9ms/step - loss: 0.7433 - accuracy: 0.4990 - val_loss: 0.7134 - val_accuracy: 0.4960\n",
            "Epoch 2/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7454 - accuracy: 0.5013 - val_loss: 0.7065 - val_accuracy: 0.4960\n",
            "Epoch 3/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7409 - accuracy: 0.5033 - val_loss: 0.8172 - val_accuracy: 0.4960\n",
            "Epoch 4/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7439 - accuracy: 0.4970 - val_loss: 0.7144 - val_accuracy: 0.4960\n",
            "Epoch 5/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7468 - accuracy: 0.4989 - val_loss: 0.6959 - val_accuracy: 0.5040\n",
            "Epoch 6/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7459 - accuracy: 0.4987 - val_loss: 0.7066 - val_accuracy: 0.4960\n",
            "Epoch 7/50\n",
            "1142/1142 [==============================] - 11s 9ms/step - loss: 0.7487 - accuracy: 0.4982 - val_loss: 0.8688 - val_accuracy: 0.5040\n",
            "Epoch 8/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7503 - accuracy: 0.5008 - val_loss: 0.8633 - val_accuracy: 0.4960\n",
            "Epoch 9/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7394 - accuracy: 0.4993 - val_loss: 0.8863 - val_accuracy: 0.4960\n",
            "Epoch 10/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7404 - accuracy: 0.4965 - val_loss: 0.7169 - val_accuracy: 0.5040\n",
            "Epoch 11/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7294 - accuracy: 0.4985 - val_loss: 0.6934 - val_accuracy: 0.5040\n",
            "Epoch 12/50\n",
            "1142/1142 [==============================] - 10s 8ms/step - loss: 0.7475 - accuracy: 0.4988 - val_loss: 0.7364 - val_accuracy: 0.4960\n",
            "Epoch 13/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7486 - accuracy: 0.5004 - val_loss: 0.6935 - val_accuracy: 0.4960\n",
            "Epoch 14/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7524 - accuracy: 0.4999 - val_loss: 0.8146 - val_accuracy: 0.5040\n",
            "Epoch 15/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7463 - accuracy: 0.5014 - val_loss: 0.7171 - val_accuracy: 0.5040\n",
            "Epoch 16/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7428 - accuracy: 0.5039 - val_loss: 0.8059 - val_accuracy: 0.5040\n",
            "Epoch 17/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7441 - accuracy: 0.5021 - val_loss: 0.7831 - val_accuracy: 0.4960\n",
            "Epoch 18/50\n",
            "1142/1142 [==============================] - 11s 9ms/step - loss: 0.7368 - accuracy: 0.5019 - val_loss: 0.6991 - val_accuracy: 0.5040\n",
            "Epoch 19/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7423 - accuracy: 0.5017 - val_loss: 0.6966 - val_accuracy: 0.4960\n",
            "Epoch 20/50\n",
            "1142/1142 [==============================] - 11s 9ms/step - loss: 0.7570 - accuracy: 0.4989 - val_loss: 0.6941 - val_accuracy: 0.5040\n",
            "Epoch 21/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7408 - accuracy: 0.5045 - val_loss: 0.6967 - val_accuracy: 0.4960\n",
            "Epoch 22/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7444 - accuracy: 0.4960 - val_loss: 0.7107 - val_accuracy: 0.4960\n",
            "Epoch 23/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7391 - accuracy: 0.5052 - val_loss: 0.7289 - val_accuracy: 0.5040\n",
            "Epoch 24/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7380 - accuracy: 0.4960 - val_loss: 0.7073 - val_accuracy: 0.5040\n",
            "Epoch 25/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7411 - accuracy: 0.4994 - val_loss: 0.7012 - val_accuracy: 0.5040\n",
            "Epoch 26/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7440 - accuracy: 0.4925 - val_loss: 0.6964 - val_accuracy: 0.5040\n",
            "Epoch 27/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7472 - accuracy: 0.5037 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
            "Epoch 28/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7419 - accuracy: 0.4992 - val_loss: 0.7064 - val_accuracy: 0.4960\n",
            "Epoch 29/50\n",
            "1142/1142 [==============================] - 11s 9ms/step - loss: 0.7420 - accuracy: 0.5027 - val_loss: 0.7079 - val_accuracy: 0.5040\n",
            "Epoch 30/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7449 - accuracy: 0.4969 - val_loss: 0.8725 - val_accuracy: 0.4960\n",
            "Epoch 31/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7439 - accuracy: 0.4981 - val_loss: 0.7508 - val_accuracy: 0.4960\n",
            "Epoch 32/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7438 - accuracy: 0.4969 - val_loss: 0.7000 - val_accuracy: 0.4960\n",
            "Epoch 33/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7361 - accuracy: 0.4996 - val_loss: 0.7666 - val_accuracy: 0.4960\n",
            "Epoch 34/50\n",
            "1142/1142 [==============================] - 10s 8ms/step - loss: 0.7446 - accuracy: 0.5085 - val_loss: 0.7557 - val_accuracy: 0.4960\n",
            "Epoch 35/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7409 - accuracy: 0.4976 - val_loss: 0.8037 - val_accuracy: 0.4960\n",
            "Epoch 36/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7465 - accuracy: 0.4959 - val_loss: 0.6971 - val_accuracy: 0.4960\n",
            "Epoch 37/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7427 - accuracy: 0.5023 - val_loss: 0.8556 - val_accuracy: 0.5040\n",
            "Epoch 38/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7454 - accuracy: 0.4992 - val_loss: 0.7000 - val_accuracy: 0.5040\n",
            "Epoch 39/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7483 - accuracy: 0.4998 - val_loss: 0.7111 - val_accuracy: 0.4960\n",
            "Epoch 40/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7391 - accuracy: 0.4997 - val_loss: 0.7107 - val_accuracy: 0.5040\n",
            "Epoch 41/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7465 - accuracy: 0.4996 - val_loss: 0.7405 - val_accuracy: 0.4960\n",
            "Epoch 42/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7468 - accuracy: 0.4968 - val_loss: 0.7319 - val_accuracy: 0.4960\n",
            "Epoch 43/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7347 - accuracy: 0.5020 - val_loss: 0.6985 - val_accuracy: 0.4960\n",
            "Epoch 44/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7347 - accuracy: 0.5072 - val_loss: 0.8225 - val_accuracy: 0.5040\n",
            "Epoch 45/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7510 - accuracy: 0.5083 - val_loss: 0.7256 - val_accuracy: 0.4960\n",
            "Epoch 46/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7356 - accuracy: 0.4989 - val_loss: 0.6976 - val_accuracy: 0.4960\n",
            "Epoch 47/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7521 - accuracy: 0.5033 - val_loss: 0.6949 - val_accuracy: 0.4960\n",
            "Epoch 48/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7410 - accuracy: 0.5022 - val_loss: 0.6984 - val_accuracy: 0.4960\n",
            "Epoch 49/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7388 - accuracy: 0.4980 - val_loss: 0.7888 - val_accuracy: 0.5040\n",
            "Epoch 50/50\n",
            "1142/1142 [==============================] - 10s 9ms/step - loss: 0.7431 - accuracy: 0.4947 - val_loss: 0.7112 - val_accuracy: 0.5040\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.7112 - accuracy: 0.5040\n",
            "[0.7111831307411194, 0.5040294528007507]\n",
            "[[   0 2831]\n",
            " [   0 2877]]\n",
            "0.5040294323756132\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      2831\n",
            "           1       0.50      1.00      0.67      2877\n",
            "\n",
            "    accuracy                           0.50      5708\n",
            "   macro avg       0.25      0.50      0.34      5708\n",
            "weighted avg       0.25      0.50      0.34      5708\n",
            "\n",
            "Training time: 4.410743713378906e-05\n",
            "Test time: 1.621246337890625e-05\n",
            "\n",
            "TIME: 0.00028705596923828125seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zkiPlEhj59T"
      },
      "source": [
        "# **ECU-FEDERATED**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl5ZdGNVWJhG",
        "outputId": "8e68f0f8-4545-4488-d1c6-577e323af9f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-federated\n",
            "  Downloading tensorflow_federated-0.20.0-py2.py3-none-any.whl (819 kB)\n",
            "\u001b[K     || 819 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting tensorflow-model-optimization~=0.7.1\n",
            "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
            "\u001b[K     || 237 kB 42.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow~=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-federated) (2.8.0)\n",
            "Collecting tqdm~=4.28.1\n",
            "  Downloading tqdm-4.28.1-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     || 45 kB 3.1 MB/s \n",
            "\u001b[?25hCollecting attrs~=21.2.0\n",
            "  Downloading attrs-21.2.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     || 53 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting jaxlib~=0.1.76\n",
            "  Downloading jaxlib-0.1.76-cp37-none-manylinux2010_x86_64.whl (65.1 MB)\n",
            "\u001b[K     || 65.1 MB 77 kB/s \n",
            "\u001b[?25hRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-federated) (0.1.6)\n",
            "Requirement already satisfied: absl-py~=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-federated) (1.0.0)\n",
            "Collecting tensorflow-privacy~=0.7.3\n",
            "  Downloading tensorflow_privacy-0.7.3-py3-none-any.whl (251 kB)\n",
            "\u001b[K     || 251 kB 39.9 MB/s \n",
            "\u001b[?25hCollecting semantic-version~=2.8.5\n",
            "  Downloading semantic_version-2.8.5-py2.py3-none-any.whl (15 kB)\n",
            "Collecting cachetools~=3.1.1\n",
            "  Downloading cachetools-3.1.1-py2.py3-none-any.whl (11 kB)\n",
            "Collecting farmhashpy~=0.4.0\n",
            "  Downloading farmhashpy-0.4.0-cp37-cp37m-manylinux2010_x86_64.whl (121 kB)\n",
            "\u001b[K     || 121 kB 45.5 MB/s \n",
            "\u001b[?25hCollecting grpcio~=1.34.0\n",
            "  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[K     || 4.0 MB 30.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.21.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-federated) (1.21.5)\n",
            "Requirement already satisfied: portpicker~=1.3.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-federated) (1.3.9)\n",
            "Collecting jax~=0.2.27\n",
            "  Downloading jax-0.2.28.tar.gz (887 kB)\n",
            "\u001b[K     || 887 kB 29.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py~=1.0.0->tensorflow-federated) (1.15.0)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.7/dist-packages (from jax~=0.2.27->tensorflow-federated) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from jax~=0.2.27->tensorflow-federated) (1.4.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (from jax~=0.2.27->tensorflow-federated) (3.10.0.2)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib~=0.1.76->tensorflow-federated) (2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tensorflow-federated) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tensorflow-federated) (57.4.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tensorflow-federated) (13.0.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tensorflow-federated) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tensorflow-federated) (0.24.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tensorflow-federated) (0.5.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tensorflow-federated) (2.8.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     || 462 kB 51.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tensorflow-federated) (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tensorflow-federated) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tensorflow-federated) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tensorflow-federated) (1.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tensorflow-federated) (3.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tensorflow-federated) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tensorflow-federated) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.8.0->tensorflow-federated) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tensorflow-federated) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tensorflow-federated) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tensorflow-federated) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tensorflow-federated) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tensorflow-federated) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tensorflow-federated) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tensorflow-federated) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tensorflow-federated) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tensorflow-federated) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tensorflow-federated) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tensorflow-federated) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tensorflow-federated) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tensorflow-federated) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tensorflow-federated) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tensorflow-federated) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tensorflow-federated) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tensorflow-federated) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tensorflow-federated) (3.2.0)\n",
            "Collecting tensorflow-datasets>=4.4.0\n",
            "  Downloading tensorflow_datasets-4.5.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     || 4.2 MB 22.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: mpmath in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy~=0.7.3->tensorflow-federated) (1.2.1)\n",
            "Requirement already satisfied: tensorflow-estimator>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy~=0.7.3->tensorflow-federated) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-probability>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy~=0.7.3->tensorflow-federated) (0.16.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=4.4.0->tensorflow-privacy~=0.7.3->tensorflow-federated) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=4.4.0->tensorflow-privacy~=0.7.3->tensorflow-federated) (1.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=4.4.0->tensorflow-privacy~=0.7.3->tensorflow-federated) (5.4.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=4.4.0->tensorflow-privacy~=0.7.3->tensorflow-federated) (0.3.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.13.0->tensorflow-privacy~=0.7.3->tensorflow-federated) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.13.0->tensorflow-privacy~=0.7.3->tensorflow-federated) (1.3.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets>=4.4.0->tensorflow-privacy~=0.7.3->tensorflow-federated) (1.56.0)\n",
            "Building wheels for collected packages: jax\n",
            "  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax: filename=jax-0.2.28-py3-none-any.whl size=1028669 sha256=c1092c4507823b155fa31ed2f4d1f24fa9b12ac3cd1da7e92e2167d90b93ac6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/60/4c/0cf931b766116b73950d9b6fca5813a45789d45d412a8d7272\n",
            "Successfully built jax\n",
            "Installing collected packages: cachetools, tqdm, grpcio, tf-estimator-nightly, tensorflow-datasets, attrs, tensorflow-privacy, tensorflow-model-optimization, semantic-version, jaxlib, jax, farmhashpy, tensorflow-federated\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 4.2.4\n",
            "    Uninstalling cachetools-4.2.4:\n",
            "      Successfully uninstalled cachetools-4.2.4\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.63.0\n",
            "    Uninstalling tqdm-4.63.0:\n",
            "      Successfully uninstalled tqdm-4.63.0\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.44.0\n",
            "    Uninstalling grpcio-1.44.0:\n",
            "      Successfully uninstalled grpcio-1.44.0\n",
            "  Attempting uninstall: tensorflow-datasets\n",
            "    Found existing installation: tensorflow-datasets 4.0.1\n",
            "    Uninstalling tensorflow-datasets-4.0.1:\n",
            "      Successfully uninstalled tensorflow-datasets-4.0.1\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 21.4.0\n",
            "    Uninstalling attrs-21.4.0:\n",
            "      Successfully uninstalled attrs-21.4.0\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.3.2+cuda11.cudnn805\n",
            "    Uninstalling jaxlib-0.3.2+cuda11.cudnn805:\n",
            "      Successfully uninstalled jaxlib-0.3.2+cuda11.cudnn805\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.3.4\n",
            "    Uninstalling jax-0.3.4:\n",
            "      Successfully uninstalled jax-0.3.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 2.2.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.28.1 which is incompatible.\n",
            "pymc3 3.11.4 requires cachetools>=4.2.1, but you have cachetools 3.1.1 which is incompatible.\n",
            "panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.28.1 which is incompatible.\n",
            "fbprophet 0.7.1 requires tqdm>=4.36.1, but you have tqdm 4.28.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed attrs-21.2.0 cachetools-3.1.1 farmhashpy-0.4.0 grpcio-1.34.1 jax-0.2.28 jaxlib-0.1.76 semantic-version-2.8.5 tensorflow-datasets-4.5.2 tensorflow-federated-0.20.0 tensorflow-model-optimization-0.7.2 tensorflow-privacy-0.7.3 tf-estimator-nightly-2.8.0.dev2021122109 tqdm-4.28.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow-federated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSRuUNl0Wbfu",
        "outputId": "c614ceea-5316-4625-a568-44c4a95f97e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.8.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrDKyi92We-V",
        "outputId": "f0177163-0336-47aa-e425-9436a440e6e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tensorflow_federated.python.core.impl.computation.computation_impl.ConcreteComputation object at 0x7f6a45731d50>\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_federated as tff \n",
        "print(tff.federated_computation(lambda: 'Hello World'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVcEjsumTeMG"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5La8Y5I_N161"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#import tensorflow_federated as tff\n",
        "\n",
        "#np.random.seed(0)\n",
        "SEED = 1337\n",
        "#tf.random.set_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZg-bTDJyvng"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlXPy4SPNcma"
      },
      "outputs": [],
      "source": [
        "df_FL = pd.read_csv('/content/drive/MyDrive/GlobeCom/clean_ECU.csv')\n",
        "df_ECU= df_FL.sample(frac=1, random_state = 13).reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ETqoX8oWxgUc",
        "outputId": "2aea62e0-281b-42e1-94c6-a5f7f1dd9cdb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1e1c695d-caa3-4d2a-a8d1-67ca6a760d7c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Time</th>\n",
              "      <th>Source</th>\n",
              "      <th>Destination</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Length</th>\n",
              "      <th>Type</th>\n",
              "      <th>Type of attack</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e1c695d-caa3-4d2a-a8d1-67ca6a760d7c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1e1c695d-caa3-4d2a-a8d1-67ca6a760d7c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1e1c695d-caa3-4d2a-a8d1-67ca6a760d7c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  Time  Source  ...  Length  Type  Type of attack\n",
              "0           0   0.0    67.0  ...     0.0     0             0.0\n",
              "1           1   1.0    64.0  ...     0.0     0             0.0\n",
              "2           2   2.0    67.0  ...     0.0     0             0.0\n",
              "3           3   3.0    45.0  ...    23.0     1             3.0\n",
              "4           4   4.0    64.0  ...     0.0     0             0.0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_FL.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyuDdokHvAUB",
        "outputId": "58b55217-6d22-41be-9e50-023e570968fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    87754\n",
              "1    23453\n",
              "Name: Type, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_FL.Type.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ao6pOTlRpBhI"
      },
      "outputs": [],
      "source": [
        "for i, df in enumerate(np.array_split(df_ECU, 5)):\n",
        "    df.to_csv('/content/drive/MyDrive/GlobeCom/'+f\"client_ECU{i+1}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYLRVd1gOGth",
        "outputId": "42aadd42-34ac-4956-fd6b-1dba41c82d84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(111207, 8)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_FL.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE9ysujuvbi0",
        "outputId": "a655d1f0-a177-45ac-b131-101dbeb5b210"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    13145\n",
              "1     9097\n",
              "Name: Type, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client1_ECU.Type.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5qCifzJvtVc",
        "outputId": "7daad420-abb9-4da0-f33d-10ce2854ee5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    17518\n",
              "1     4724\n",
              "Name: Type, dtype: int64"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client2_ECU.Type.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "P57a7Y6mOLbS",
        "outputId": "eefd5fae-982e-4e21-9f9b-d958edfcc859"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b153561f-d08e-4a9f-b0d5-79de549382b5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Time</th>\n",
              "      <th>Source</th>\n",
              "      <th>Destination</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Length</th>\n",
              "      <th>Type</th>\n",
              "      <th>Type of attack</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b153561f-d08e-4a9f-b0d5-79de549382b5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b153561f-d08e-4a9f-b0d5-79de549382b5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b153561f-d08e-4a9f-b0d5-79de549382b5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  Time  Source  ...  Length  Type  Type of attack\n",
              "0           0   0.0    67.0  ...     0.0     0             0.0\n",
              "1           1   1.0    64.0  ...     0.0     0             0.0\n",
              "2           2   2.0    67.0  ...     0.0     0             0.0\n",
              "3           3   3.0    45.0  ...    23.0     1             3.0\n",
              "4           4   4.0    64.0  ...     0.0     0             0.0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_FL.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNy2H8jVOvLs",
        "outputId": "3a5a75f1-1144-4d0a-fc98-b18fe205a963"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    87754\n",
              "1    23453\n",
              "Name: Type, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_FL.Type.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-l4Hu45AxCX"
      },
      "outputs": [],
      "source": [
        "client1_ECU = pd.read_csv('/content/drive/MyDrive/ECU/client_ECU1.csv')\n",
        "client1_ECU_shuffled = client1_ECU.sample(frac=1, random_state = 13).reset_index(drop = True)\n",
        "\n",
        "client2_ECU = pd.read_csv('/content/drive/MyDrive/ECU/client_ECU2.csv')\n",
        "client2_ECU_shuffled = client2_ECU.sample(frac=1, random_state = 13).reset_index(drop = True)\n",
        "\n",
        "client3_ECU = pd.read_csv('/content/drive/MyDrive/ECU/client_ECU3.csv')\n",
        "client3_ECU_shuffled = client3_ECU.sample(frac=1, random_state = 13).reset_index(drop = True)\n",
        "\n",
        "client4_ECU = pd.read_csv('/content/drive/MyDrive/ECU/client_ECU4.csv')\n",
        "client4_ECU_shuffled = client4_ECU.sample(frac=1, random_state = 13).reset_index(drop = True)\n",
        "\n",
        "client5_ECU = pd.read_csv('/content/drive/MyDrive/ECU/client_ECU5.csv')\n",
        "client5_ECU_shuffled = client5_ECU.sample(frac=1, random_state = 13).reset_index(drop = True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCsumoA_uhTg",
        "outputId": "5a24a74c-8a67-41a4-ca21-58d508c66f96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    17645\n",
              "1     4596\n",
              "Name: Type, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client3_ECU.Type.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2mSlYZEI2Bt",
        "outputId": "7b3616c8-aec2-4963-e97f-1ee1ff3100a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    17562\n",
              "1     4680\n",
              "Name: Type, dtype: int64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client1_ECU_shuffled.Type.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20QODo5JIzMq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIKAdy0FA1LK"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "#BATCH_SIZE = 512\n",
        "BATCH_SIZE = 1024 #ECU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hw-4U4B8A4p6"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def make_tf_dataset(dataframe, batch_size=None):\n",
        "  \n",
        "    dataset = dataframe.drop(['Unnamed: 0'], axis=1)\n",
        "    count_FL_0, count_FL_1 = dataset.Type.value_counts()\n",
        "\n",
        "    df_FL_0 = dataset[dataset['Type'] == 0]\n",
        "    df_FL_1 = dataset[dataset['Type'] == 1]\n",
        "\n",
        "    df_FL_0_under = df_FL_0.sample(count_FL_1)\n",
        "    df_FL_under = pd.concat([df_FL_0_under, df_FL_1], axis = 0)\n",
        "    y = df_FL_under.pop('Type')\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((df_FL_under.values, y.to_frame().values))\n",
        "    dataset = dataset.shuffle(4048, seed=SEED) #2048\n",
        "    if batch_size:\n",
        "        dataset = dataset.batch(batch_size)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXWp7E1r9jJc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0wLAm6nD_qL"
      },
      "outputs": [],
      "source": [
        "#########################################ECU#######################################################\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "train_data, val_data = [], []\n",
        "\n",
        "for client_data in [client1_ECU_shuffled, client2_ECU_shuffled, client3_ECU_shuffled, client4_ECU_shuffled, client5_ECU_shuffled]:\n",
        "                     \n",
        "                   \n",
        "    train_df, val_df = train_test_split(client_data, test_size=0.2, random_state=1337)\n",
        "\n",
        "    # Scaling (Standardization actually hurts performance) \n",
        "    #encoder = LabelEncoder()\n",
        "    scaler = StandardScaler() \n",
        "    train_features = scaler.fit_transform(train_df.drop(['Type'], axis=1))\n",
        "    val_features = scaler.transform(val_df.drop(['Type'], axis=1))\n",
        "  \n",
        "    #encoder = LabelEncoder()\n",
        "    #y1 = encoder.fit_transform(y)\n",
        "    #Y= pd.get_dummies(y1).values\n",
        "    train_df[train_df.columns.difference(['Type'])] = train_features\n",
        "    val_df[val_df.columns.difference(['Type'])] = val_features\n",
        "\n",
        "    # TF Datasets\n",
        "    train_data.append(make_tf_dataset(train_df, batch_size=BATCH_SIZE)) #negative_ratio=2\n",
        "    val_data.append(make_tf_dataset(val_df, batch_size=16))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb3CbLjBEPu2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import CategoricalAccuracy, Precision, Recall, BinaryAccuracy\n",
        "def input_spec():\n",
        "    return (\n",
        "        tf.TensorSpec([None, 6], tf.float64),\n",
        "        tf.TensorSpec([None, 1], tf.int64)\n",
        "    )\n",
        "\n",
        "def model_fn():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(6,)),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "    ])\n",
        "\n",
        "    return tff.learning.from_keras_model(\n",
        "        model,\n",
        "        input_spec=input_spec(),\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.BinaryAccuracy(), Precision(), Recall()]\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBGojtB6EbFG"
      },
      "outputs": [],
      "source": [
        "trainer = tff.learning.build_federated_averaging_process(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.05)#learning_rate=0.01\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "dQMI_zANEoTT",
        "outputId": "81c6f9eb-46e5-47fa-b835-8203133dd606"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'( -> <model=<trainable=<float32[6,32],float32[32],float32[32,64],float32[64],float32[64,32],float32[32],float32[32,1],float32[1]>,non_trainable=<>>,optimizer_state=<int64,float32[6,32],float32[32],float32[32,64],float32[64],float32[64,32],float32[32],float32[32,1],float32[1],float32[6,32],float32[32],float32[32,64],float32[64],float32[64,32],float32[32],float32[32,1],float32[1]>,delta_aggregate_state=<value_sum_process=<>,weight_sum_process=<>>,model_broadcast_state=<>>@SERVER)'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(trainer.initialize.type_signature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRVnUDMXIXGI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sz3XfpSSErCe"
      },
      "outputs": [],
      "source": [
        "state = trainer.initialize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CNv1UD9Il8n",
        "outputId": "97131806-923e-4833-db1c-f706c024dfe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 50/50Training time: 3.4809112548828125e-05\n",
            "Test time: 1.430511474609375e-05\n",
            "\n",
            "TIME: 97.74022579193115seconds\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import time\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "#state = trainer.initialize()\n",
        "train_hist = []\n",
        "for i in range(EPOCHS):\n",
        "    state, metrics = trainer.next(state, train_data)\n",
        "    train_hist.append(metrics)\n",
        "\n",
        "    print(f\"\\rRun {i+1}/{EPOCHS}\", end=\"\")\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sc4CPa9g7c-y",
        "outputId": "05441471-d1a4-4d57-fc2b-06bf9e1caf4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('binary_accuracy', 0.9927455), ('precision', 0.9877502), ('recall', 0.99786633), ('loss', 0.04286906), ('num_examples', 37494), ('num_batches', 40)]))])\n"
          ]
        }
      ],
      "source": [
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gXIrEFd7AVz",
        "outputId": "ef147eb5-0c7b-477b-fb2e-7e5abbbd0cbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.80956954),\n",
              "                            ('precision', 0.8300631),\n",
              "                            ('recall', 0.7785246),\n",
              "                            ('loss', 0.4668336),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.90841204),\n",
              "                            ('precision', 0.91699797),\n",
              "                            ('recall', 0.898117),\n",
              "                            ('loss', 0.34919313),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.92636156),\n",
              "                            ('precision', 0.9140593),\n",
              "                            ('recall', 0.94121724),\n",
              "                            ('loss', 0.33951145),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9360698),\n",
              "                            ('precision', 0.91421765),\n",
              "                            ('recall', 0.96244735),\n",
              "                            ('loss', 0.28237733),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9393236),\n",
              "                            ('precision', 0.9152047),\n",
              "                            ('recall', 0.9683683),\n",
              "                            ('loss', 0.23133823),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.94177735),\n",
              "                            ('precision', 0.9154711),\n",
              "                            ('recall', 0.97343576),\n",
              "                            ('loss', 0.20022665),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9343628),\n",
              "                            ('precision', 0.91117954),\n",
              "                            ('recall', 0.96255404),\n",
              "                            ('loss', 0.20031369),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9449512),\n",
              "                            ('precision', 0.91374433),\n",
              "                            ('recall', 0.98266387),\n",
              "                            ('loss', 0.19150941),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9534859),\n",
              "                            ('precision', 0.9180723),\n",
              "                            ('recall', 0.99583936),\n",
              "                            ('loss', 0.16121447),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9555129),\n",
              "                            ('precision', 0.91895205),\n",
              "                            ('recall', 0.9991465),\n",
              "                            ('loss', 0.15322138),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.95612633),\n",
              "                            ('precision', 0.920114),\n",
              "                            ('recall', 0.9989865),\n",
              "                            ('loss', 0.15360409),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.95516616),\n",
              "                            ('precision', 0.9195594),\n",
              "                            ('recall', 0.9975996),\n",
              "                            ('loss', 0.1503735),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.95572627),\n",
              "                            ('precision', 0.91881955),\n",
              "                            ('recall', 0.9997866),\n",
              "                            ('loss', 0.14557181),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.95580626),\n",
              "                            ('precision', 0.91883147),\n",
              "                            ('recall', 0.99994665),\n",
              "                            ('loss', 0.13995305),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.95572627),\n",
              "                            ('precision', 0.91881955),\n",
              "                            ('recall', 0.9997866),\n",
              "                            ('loss', 0.13504021),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9557796),\n",
              "                            ('precision', 0.9188686),\n",
              "                            ('recall', 0.99983996),\n",
              "                            ('loss', 0.13368301),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.95583296),\n",
              "                            ('precision', 0.9189176),\n",
              "                            ('recall', 0.9998933),\n",
              "                            ('loss', 0.13255675),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.956233),\n",
              "                            ('precision', 0.919635),\n",
              "                            ('recall', 0.99983996),\n",
              "                            ('loss', 0.13428679),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9569798),\n",
              "                            ('precision', 0.9209828),\n",
              "                            ('recall', 0.99973327),\n",
              "                            ('loss', 0.13316846),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9581533),\n",
              "                            ('precision', 0.92302006),\n",
              "                            ('recall', 0.9996799),\n",
              "                            ('loss', 0.13558781),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.95858),\n",
              "                            ('precision', 0.9257205),\n",
              "                            ('recall', 0.9971729),\n",
              "                            ('loss', 0.13443075),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9598869),\n",
              "                            ('precision', 0.92640585),\n",
              "                            ('recall', 0.9991465),\n",
              "                            ('loss', 0.1275984),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.96058035),\n",
              "                            ('precision', 0.9280226),\n",
              "                            ('recall', 0.9986131),\n",
              "                            ('loss', 0.12511902),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9603137),\n",
              "                            ('precision', 0.92802936),\n",
              "                            ('recall', 0.9980264),\n",
              "                            ('loss', 0.11984907),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9609004),\n",
              "                            ('precision', 0.93028235),\n",
              "                            ('recall', 0.99647945),\n",
              "                            ('loss', 0.11993239),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.96135384),\n",
              "                            ('precision', 0.929999),\n",
              "                            ('recall', 0.997813),\n",
              "                            ('loss', 0.1174312),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9620473),\n",
              "                            ('precision', 0.9312456),\n",
              "                            ('recall', 0.99775964),\n",
              "                            ('loss', 0.11836291),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9612738),\n",
              "                            ('precision', 0.9343077),\n",
              "                            ('recall', 0.99231875),\n",
              "                            ('loss', 0.11594851),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.96106046),\n",
              "                            ('precision', 0.9371807),\n",
              "                            ('recall', 0.9883715),\n",
              "                            ('loss', 0.112744756),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.96386087),\n",
              "                            ('precision', 0.9391032),\n",
              "                            ('recall', 0.9920521),\n",
              "                            ('loss', 0.10669819),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9646877),\n",
              "                            ('precision', 0.9400859),\n",
              "                            ('recall', 0.9926388),\n",
              "                            ('loss', 0.1020695),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.97223556),\n",
              "                            ('precision', 0.94825315),\n",
              "                            ('recall', 0.9989865),\n",
              "                            ('loss', 0.09197576),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.95332587),\n",
              "                            ('precision', 0.9429763),\n",
              "                            ('recall', 0.9650077),\n",
              "                            ('loss', 0.109093934),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9703153),\n",
              "                            ('precision', 0.9481549),\n",
              "                            ('recall', 0.9950392),\n",
              "                            ('loss', 0.09941098),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9733824),\n",
              "                            ('precision', 0.95178944),\n",
              "                            ('recall', 0.9972796),\n",
              "                            ('loss', 0.092524365),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.97407585),\n",
              "                            ('precision', 0.95153177),\n",
              "                            ('recall', 0.9990398),\n",
              "                            ('loss', 0.08715372),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.97364914),\n",
              "                            ('precision', 0.95062166),\n",
              "                            ('recall', 0.99919987),\n",
              "                            ('loss', 0.08154377),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.97570276),\n",
              "                            ('precision', 0.9565373),\n",
              "                            ('recall', 0.9966928),\n",
              "                            ('loss', 0.07898525),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.97602284),\n",
              "                            ('precision', 0.95665747),\n",
              "                            ('recall', 0.99722624),\n",
              "                            ('loss', 0.07100113),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9774097),\n",
              "                            ('precision', 0.95700574),\n",
              "                            ('recall', 0.99973327),\n",
              "                            ('loss', 0.062906355),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9774897),\n",
              "                            ('precision', 0.95715237),\n",
              "                            ('recall', 0.99973327),\n",
              "                            ('loss', 0.05649968),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.977143),\n",
              "                            ('precision', 0.95726407),\n",
              "                            ('recall', 0.99887985),\n",
              "                            ('loss', 0.051039323),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9775964),\n",
              "                            ('precision', 0.9574881),\n",
              "                            ('recall', 0.9995733),\n",
              "                            ('loss', 0.0487662),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.97756976),\n",
              "                            ('precision', 0.9572523),\n",
              "                            ('recall', 0.9997866),\n",
              "                            ('loss', 0.048027605),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.977143),\n",
              "                            ('precision', 0.95707715),\n",
              "                            ('recall', 0.9990932),\n",
              "                            ('loss', 0.049309473),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.97722304),\n",
              "                            ('precision', 0.95750445),\n",
              "                            ('recall', 0.99877316),\n",
              "                            ('loss', 0.04885983),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.98893154),\n",
              "                            ('precision', 0.9810538),\n",
              "                            ('recall', 0.99711955),\n",
              "                            ('loss', 0.04613496),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.98951834),\n",
              "                            ('precision', 0.98203593),\n",
              "                            ('recall', 0.9972796),\n",
              "                            ('loss', 0.043895584),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9926121),\n",
              "                            ('precision', 0.98723227),\n",
              "                            ('recall', 0.99813306),\n",
              "                            ('loss', 0.04517234),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9927455),\n",
              "                            ('precision', 0.9877502),\n",
              "                            ('recall', 0.99786633),\n",
              "                            ('loss', 0.04286906),\n",
              "                            ('num_examples', 37494),\n",
              "                            ('num_batches', 40)]))])]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_hist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5ND_CMjetlt"
      },
      "outputs": [],
      "source": [
        "evaluator = tff.learning.build_federated_evaluation(model_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68lQgWovqpgm",
        "outputId": "2e3cb1b0-dcbb-4f10-9c25-80dbe6cdcf0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('eval',\n",
              "              OrderedDict([('binary_accuracy', 0.9934127),\n",
              "                           ('precision', 0.98720104),\n",
              "                           ('recall', 0.9997875),\n",
              "                           ('loss', 0.040167395),\n",
              "                           ('num_examples', 9412),\n",
              "                           ('num_batches', 590)]))])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "federated_metrics = evaluator(state.model, val_data)\n",
        "federated_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeWtgGS7kC6K"
      },
      "source": [
        "# **Centralized ECU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WG0t8mAma_Y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZnHAwXykHCF"
      },
      "outputs": [],
      "source": [
        "df_FL1 = pd.read_csv('/content/drive/MyDrive/GlobeCom/clean_ECU.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kreWI_jDLGEw",
        "outputId": "18944d95-68fe-4077-f46c-9be6ec26412b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  Time  Source  Destination  Protocol  Length  Type  \\\n",
              "0           0   0.0    67.0         69.0       0.0     0.0     0   \n",
              "1           1   1.0    64.0         68.0       0.0     0.0     0   \n",
              "2           2   2.0    67.0         69.0       0.0     0.0     0   \n",
              "3           3   3.0    45.0         44.0       2.0    23.0     1   \n",
              "4           4   4.0    64.0         68.0       0.0     0.0     0   \n",
              "\n",
              "   Type of attack  \n",
              "0             0.0  \n",
              "1             0.0  \n",
              "2             0.0  \n",
              "3             3.0  \n",
              "4             0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c33a6684-16df-4df7-8eab-90e8464c4016\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Time</th>\n",
              "      <th>Source</th>\n",
              "      <th>Destination</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Length</th>\n",
              "      <th>Type</th>\n",
              "      <th>Type of attack</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c33a6684-16df-4df7-8eab-90e8464c4016')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c33a6684-16df-4df7-8eab-90e8464c4016 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c33a6684-16df-4df7-8eab-90e8464c4016');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df_FL1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ziim_ysskXUa"
      },
      "outputs": [],
      "source": [
        "drop_columns = ['Unnamed: 0']#, 'Type of attack']\t\t\n",
        "df_FL= df_FL1.drop(columns=drop_columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VT4zw5FyRsB1"
      },
      "outputs": [],
      "source": [
        "count_FL_0, count_FL_1 = df_FL.Type.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NpvtA1uSEYw",
        "outputId": "bc302c26-8293-4745-9277-baf3555d79fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(87754, 23453)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "count_FL_0, count_FL_1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SFLm9mgO5yV"
      },
      "outputs": [],
      "source": [
        "df_FL_0 = df_FL[df_FL['Type'] == 0]\n",
        "df_FL_1 = df_FL[df_FL['Type'] == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3Eour_7RPF_",
        "outputId": "a7d2133c-f12a-4da2-f5ca-deb91cdcfd17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(87754, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df_FL_0.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBW0fsEhRUnq",
        "outputId": "2a4a9fbb-0b48-4822-e4d8-c05e26e04e49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23453, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_FL_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k9J37JWT2Yh",
        "outputId": "9d130910-e252-47ff-a486-aef3b9a93735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random under-sampling:\n",
            "0    23453\n",
            "1    23453\n",
            "Name: Type, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df_FL_0_under = df_FL_0.sample(count_FL_1)\n",
        "df_FL_under = pd.concat([df_FL_0_under, df_FL_1], axis = 0)\n",
        "print('Random under-sampling:')\n",
        "print(df_FL_under.Type.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99F1B_2oc7Lx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWWNuQXkUzwb"
      },
      "outputs": [],
      "source": [
        "X = df_FL_under.drop('Type', axis = 'columns')\n",
        "y = df_FL_under['Type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgUe2_5b_hbA"
      },
      "outputs": [],
      "source": [
        "#X = df_FL.drop('Type', axis = 'columns')\n",
        "#y= df_FL['Type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyhn1zHN6jSu"
      },
      "outputs": [],
      "source": [
        "#from imblearn.over_sampling import SMOTE\n",
        "#X_smote, y_smote = SMOTE().fit_resample(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EruXudWedGLA"
      },
      "outputs": [],
      "source": [
        "#from sklearn.preprocessing import LabelEncoder\n",
        "#encoder = LabelEncoder()\n",
        "#y1 = encoder.fit_transform(y)\n",
        "#Y= pd.get_dummies(y1).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z6XjJn8dMgy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNmNOZQgVJar"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split( X , y, test_size = 0.2, random_state = 1337)#, stratify = Y)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWOvuXQQ6r6g"
      },
      "outputs": [],
      "source": [
        "#from sklearn.model_selection import train_test_split\n",
        "#X_train, X_test, y_train, y_test = train_test_split( X_smote , y_smote, test_size = 0.1, random_state = 1337)#, stratify = Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YFgja4mVsyS"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaling = StandardScaler()\n",
        "X_train = scaling.fit_transform(X_train)\n",
        "X_test = scaling.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtRD4QDr5Ea8"
      },
      "outputs": [],
      "source": [
        "#For CNN and CNN-LSTM\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN**"
      ],
      "metadata": {
        "id": "TBo7SeafEmtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###############LSTM###################################\n",
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda\n",
        "\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, Dense, Dropout, Flatten, MaxPooling1D\n",
        "\n",
        "from keras.layers import LSTM, GRU, SimpleRNN\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(32, 2, activation='relu', input_shape = X_train[0].shape))\n",
        "\n",
        "#model.add(SimpleRNN(lstm_output_size))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_train, y_train, epochs=50, batch_size = 20, validation_data=(X_test, y_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_test, y_preds_cnn))\n",
        "print(accuracy_score(y_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_preds_cnn))\n",
        "\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl371JwBEmAj",
        "outputId": "72851a4e-265a-4b25-effe-672fa3b2ba36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.5761 - accuracy: 0.7476 - val_loss: 0.5312 - val_accuracy: 0.7798\n",
            "Epoch 2/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.5745 - accuracy: 0.7463 - val_loss: 0.5355 - val_accuracy: 0.7630\n",
            "Epoch 3/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.5870 - accuracy: 0.7407 - val_loss: 0.5677 - val_accuracy: 0.7579\n",
            "Epoch 4/50\n",
            "1877/1877 [==============================] - 3s 1ms/step - loss: 0.5923 - accuracy: 0.7370 - val_loss: 0.5760 - val_accuracy: 0.6931\n",
            "Epoch 5/50\n",
            "1877/1877 [==============================] - 3s 1ms/step - loss: 0.5970 - accuracy: 0.7304 - val_loss: 0.5764 - val_accuracy: 0.7669\n",
            "Epoch 6/50\n",
            "1877/1877 [==============================] - 3s 1ms/step - loss: 0.6001 - accuracy: 0.7263 - val_loss: 0.5842 - val_accuracy: 0.7332\n",
            "Epoch 7/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6074 - accuracy: 0.7192 - val_loss: 0.5748 - val_accuracy: 0.7600\n",
            "Epoch 8/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6058 - accuracy: 0.7218 - val_loss: 0.5938 - val_accuracy: 0.7221\n",
            "Epoch 9/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6064 - accuracy: 0.7198 - val_loss: 0.5679 - val_accuracy: 0.7611\n",
            "Epoch 10/50\n",
            "1877/1877 [==============================] - 3s 1ms/step - loss: 0.6066 - accuracy: 0.7178 - val_loss: 0.5684 - val_accuracy: 0.7585\n",
            "Epoch 11/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6083 - accuracy: 0.7184 - val_loss: 0.5742 - val_accuracy: 0.7624\n",
            "Epoch 12/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6069 - accuracy: 0.7180 - val_loss: 0.5730 - val_accuracy: 0.7532\n",
            "Epoch 13/50\n",
            "1877/1877 [==============================] - 3s 1ms/step - loss: 0.6067 - accuracy: 0.7217 - val_loss: 0.5944 - val_accuracy: 0.7161\n",
            "Epoch 14/50\n",
            "1877/1877 [==============================] - 3s 1ms/step - loss: 0.6049 - accuracy: 0.7211 - val_loss: 0.5731 - val_accuracy: 0.7569\n",
            "Epoch 15/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6056 - accuracy: 0.7226 - val_loss: 0.5738 - val_accuracy: 0.7659\n",
            "Epoch 16/50\n",
            "1877/1877 [==============================] - 3s 1ms/step - loss: 0.6080 - accuracy: 0.7183 - val_loss: 0.5741 - val_accuracy: 0.7538\n",
            "Epoch 17/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6069 - accuracy: 0.7184 - val_loss: 0.5698 - val_accuracy: 0.7541\n",
            "Epoch 18/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6076 - accuracy: 0.7197 - val_loss: 0.5682 - val_accuracy: 0.7594\n",
            "Epoch 19/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6063 - accuracy: 0.7199 - val_loss: 0.5686 - val_accuracy: 0.7533\n",
            "Epoch 20/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6074 - accuracy: 0.7190 - val_loss: 0.5805 - val_accuracy: 0.7692\n",
            "Epoch 21/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6078 - accuracy: 0.7193 - val_loss: 0.5833 - val_accuracy: 0.7272\n",
            "Epoch 22/50\n",
            "1877/1877 [==============================] - 3s 1ms/step - loss: 0.6077 - accuracy: 0.7189 - val_loss: 0.5718 - val_accuracy: 0.7524\n",
            "Epoch 23/50\n",
            "1877/1877 [==============================] - 3s 1ms/step - loss: 0.6077 - accuracy: 0.7184 - val_loss: 0.5816 - val_accuracy: 0.7230\n",
            "Epoch 24/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6055 - accuracy: 0.7198 - val_loss: 0.5944 - val_accuracy: 0.7902\n",
            "Epoch 25/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6075 - accuracy: 0.7194 - val_loss: 0.6039 - val_accuracy: 0.6539\n",
            "Epoch 26/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6074 - accuracy: 0.7202 - val_loss: 0.5775 - val_accuracy: 0.7604\n",
            "Epoch 27/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6062 - accuracy: 0.7201 - val_loss: 0.5789 - val_accuracy: 0.7560\n",
            "Epoch 28/50\n",
            "1877/1877 [==============================] - 3s 1ms/step - loss: 0.6062 - accuracy: 0.7217 - val_loss: 0.5702 - val_accuracy: 0.7548\n",
            "Epoch 29/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6092 - accuracy: 0.7168 - val_loss: 0.5739 - val_accuracy: 0.7668\n",
            "Epoch 30/50\n",
            "1877/1877 [==============================] - 3s 1ms/step - loss: 0.6062 - accuracy: 0.7190 - val_loss: 0.5674 - val_accuracy: 0.7768\n",
            "Epoch 31/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6077 - accuracy: 0.7192 - val_loss: 0.5810 - val_accuracy: 0.7806\n",
            "Epoch 32/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6079 - accuracy: 0.7182 - val_loss: 0.5680 - val_accuracy: 0.7554\n",
            "Epoch 33/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6067 - accuracy: 0.7192 - val_loss: 0.5662 - val_accuracy: 0.7780\n",
            "Epoch 34/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6053 - accuracy: 0.7214 - val_loss: 0.5697 - val_accuracy: 0.7526\n",
            "Epoch 35/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6080 - accuracy: 0.7189 - val_loss: 0.5811 - val_accuracy: 0.7339\n",
            "Epoch 36/50\n",
            "1877/1877 [==============================] - 3s 1ms/step - loss: 0.6073 - accuracy: 0.7201 - val_loss: 0.5746 - val_accuracy: 0.7418\n",
            "Epoch 37/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6053 - accuracy: 0.7216 - val_loss: 0.5813 - val_accuracy: 0.7514\n",
            "Epoch 38/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6073 - accuracy: 0.7197 - val_loss: 0.5709 - val_accuracy: 0.7714\n",
            "Epoch 39/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6057 - accuracy: 0.7195 - val_loss: 0.5720 - val_accuracy: 0.7576\n",
            "Epoch 40/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6060 - accuracy: 0.7208 - val_loss: 0.5684 - val_accuracy: 0.7567\n",
            "Epoch 41/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6080 - accuracy: 0.7196 - val_loss: 0.5800 - val_accuracy: 0.7539\n",
            "Epoch 42/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6052 - accuracy: 0.7229 - val_loss: 0.6270 - val_accuracy: 0.6241\n",
            "Epoch 43/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6081 - accuracy: 0.7175 - val_loss: 0.5813 - val_accuracy: 0.7760\n",
            "Epoch 44/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6075 - accuracy: 0.7197 - val_loss: 0.5724 - val_accuracy: 0.7437\n",
            "Epoch 45/50\n",
            "1877/1877 [==============================] - 3s 1ms/step - loss: 0.6070 - accuracy: 0.7194 - val_loss: 0.5705 - val_accuracy: 0.7720\n",
            "Epoch 46/50\n",
            "1877/1877 [==============================] - 3s 1ms/step - loss: 0.6058 - accuracy: 0.7192 - val_loss: 0.5694 - val_accuracy: 0.7691\n",
            "Epoch 47/50\n",
            "1877/1877 [==============================] - 3s 1ms/step - loss: 0.6071 - accuracy: 0.7193 - val_loss: 0.5758 - val_accuracy: 0.7657\n",
            "Epoch 48/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6077 - accuracy: 0.7197 - val_loss: 0.6029 - val_accuracy: 0.6439\n",
            "Epoch 49/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6080 - accuracy: 0.7194 - val_loss: 0.5690 - val_accuracy: 0.7674\n",
            "Epoch 50/50\n",
            "1877/1877 [==============================] - 3s 2ms/step - loss: 0.6067 - accuracy: 0.7207 - val_loss: 0.6074 - val_accuracy: 0.6428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM**"
      ],
      "metadata": {
        "id": "RyrjCepDz1Je"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYuwGEMj5Pwt",
        "outputId": "172d78a1-2ba4-4f8a-e768-673f71af7391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1877/1877 [==============================] - 10s 4ms/step - loss: 0.2250 - accuracy: 0.9135 - val_loss: 0.1344 - val_accuracy: 0.9565\n",
            "Epoch 2/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1960 - accuracy: 0.9252 - val_loss: 0.1501 - val_accuracy: 0.9529\n",
            "Epoch 3/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1949 - accuracy: 0.9269 - val_loss: 0.1055 - val_accuracy: 0.9731\n",
            "Epoch 4/50\n",
            "1877/1877 [==============================] - 9s 5ms/step - loss: 0.1557 - accuracy: 0.9252 - val_loss: 0.0926 - val_accuracy: 0.9565\n",
            "Epoch 5/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1507 - accuracy: 0.9220 - val_loss: 0.0718 - val_accuracy: 0.9858\n",
            "Epoch 6/50\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.1738 - accuracy: 0.9169 - val_loss: 0.0789 - val_accuracy: 0.9553\n",
            "Epoch 7/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1488 - accuracy: 0.9264 - val_loss: 0.0842 - val_accuracy: 0.9565\n",
            "Epoch 8/50\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.1428 - accuracy: 0.9348 - val_loss: 0.0632 - val_accuracy: 0.9844\n",
            "Epoch 9/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1310 - accuracy: 0.9351 - val_loss: 0.0685 - val_accuracy: 0.9844\n",
            "Epoch 10/50\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.1354 - accuracy: 0.9335 - val_loss: 0.0689 - val_accuracy: 0.9845\n",
            "Epoch 11/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1982 - accuracy: 0.9232 - val_loss: 0.1207 - val_accuracy: 0.9692\n",
            "Epoch 12/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1560 - accuracy: 0.9336 - val_loss: 0.1027 - val_accuracy: 0.9565\n",
            "Epoch 13/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1546 - accuracy: 0.9241 - val_loss: 0.0865 - val_accuracy: 0.9565\n",
            "Epoch 14/50\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.1548 - accuracy: 0.9233 - val_loss: 0.0870 - val_accuracy: 0.9565\n",
            "Epoch 15/50\n",
            "1877/1877 [==============================] - 7s 3ms/step - loss: 0.1573 - accuracy: 0.9211 - val_loss: 0.0795 - val_accuracy: 0.9858\n",
            "Epoch 16/50\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.1586 - accuracy: 0.9242 - val_loss: 0.0993 - val_accuracy: 0.9565\n",
            "Epoch 17/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1551 - accuracy: 0.9240 - val_loss: 0.0819 - val_accuracy: 0.9564\n",
            "Epoch 18/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1518 - accuracy: 0.9307 - val_loss: 0.0826 - val_accuracy: 0.9856\n",
            "Epoch 19/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1548 - accuracy: 0.9367 - val_loss: 0.0808 - val_accuracy: 0.9858\n",
            "Epoch 20/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1493 - accuracy: 0.9398 - val_loss: 0.0841 - val_accuracy: 0.9852\n",
            "Epoch 21/50\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.1422 - accuracy: 0.9381 - val_loss: 0.0797 - val_accuracy: 0.9858\n",
            "Epoch 22/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1435 - accuracy: 0.9368 - val_loss: 0.0915 - val_accuracy: 0.9660\n",
            "Epoch 23/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1534 - accuracy: 0.9355 - val_loss: 0.0840 - val_accuracy: 0.9787\n",
            "Epoch 24/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1443 - accuracy: 0.9403 - val_loss: 0.0836 - val_accuracy: 0.9858\n",
            "Epoch 25/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1456 - accuracy: 0.9386 - val_loss: 0.0830 - val_accuracy: 0.9858\n",
            "Epoch 26/50\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.1414 - accuracy: 0.9369 - val_loss: 0.0812 - val_accuracy: 0.9841\n",
            "Epoch 27/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1491 - accuracy: 0.9347 - val_loss: 0.0840 - val_accuracy: 0.9858\n",
            "Epoch 28/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1486 - accuracy: 0.9363 - val_loss: 0.0799 - val_accuracy: 0.9849\n",
            "Epoch 29/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1508 - accuracy: 0.9384 - val_loss: 0.0773 - val_accuracy: 0.9854\n",
            "Epoch 30/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1550 - accuracy: 0.9362 - val_loss: 0.0891 - val_accuracy: 0.9823\n",
            "Epoch 31/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1982 - accuracy: 0.9102 - val_loss: 0.0914 - val_accuracy: 0.9825\n",
            "Epoch 32/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1596 - accuracy: 0.9393 - val_loss: 0.0881 - val_accuracy: 0.9854\n",
            "Epoch 33/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1626 - accuracy: 0.9445 - val_loss: 0.0973 - val_accuracy: 0.9855\n",
            "Epoch 34/50\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.1553 - accuracy: 0.9421 - val_loss: 0.0893 - val_accuracy: 0.9857\n",
            "Epoch 35/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1605 - accuracy: 0.9426 - val_loss: 0.0955 - val_accuracy: 0.9860\n",
            "Epoch 36/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1686 - accuracy: 0.9419 - val_loss: 0.0802 - val_accuracy: 0.9859\n",
            "Epoch 37/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1663 - accuracy: 0.9415 - val_loss: 0.0945 - val_accuracy: 0.9750\n",
            "Epoch 38/50\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.1760 - accuracy: 0.9358 - val_loss: 0.0905 - val_accuracy: 0.9856\n",
            "Epoch 39/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1721 - accuracy: 0.9349 - val_loss: 0.0940 - val_accuracy: 0.9719\n",
            "Epoch 40/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1967 - accuracy: 0.9263 - val_loss: 0.0999 - val_accuracy: 0.9807\n",
            "Epoch 41/50\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.1688 - accuracy: 0.9371 - val_loss: 0.0920 - val_accuracy: 0.9861\n",
            "Epoch 42/50\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.1645 - accuracy: 0.9407 - val_loss: 0.1267 - val_accuracy: 0.9567\n",
            "Epoch 43/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.1651 - accuracy: 0.9404 - val_loss: 0.0936 - val_accuracy: 0.9744\n",
            "Epoch 44/50\n",
            "1877/1877 [==============================] - 7s 3ms/step - loss: 0.2095 - accuracy: 0.9227 - val_loss: 0.1576 - val_accuracy: 0.9568\n",
            "Epoch 45/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.2454 - accuracy: 0.9094 - val_loss: 0.1608 - val_accuracy: 0.9419\n",
            "Epoch 46/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.2175 - accuracy: 0.9215 - val_loss: 0.1206 - val_accuracy: 0.9566\n",
            "Epoch 47/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.2047 - accuracy: 0.9227 - val_loss: 0.1117 - val_accuracy: 0.9686\n",
            "Epoch 48/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.2014 - accuracy: 0.9234 - val_loss: 0.1543 - val_accuracy: 0.9564\n",
            "Epoch 49/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.2281 - accuracy: 0.9173 - val_loss: 0.1596 - val_accuracy: 0.9563\n",
            "Epoch 50/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.2341 - accuracy: 0.9121 - val_loss: 0.1406 - val_accuracy: 0.9562\n",
            "294/294 [==============================] - 0s 1ms/step - loss: 0.1406 - accuracy: 0.9562\n",
            "[0.14059120416641235, 0.9561927318572998]\n",
            "[[4217  408]\n",
            " [   3 4754]]\n",
            "0.9561927094436155\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.91      0.95      4625\n",
            "           1       0.92      1.00      0.96      4757\n",
            "\n",
            "    accuracy                           0.96      9382\n",
            "   macro avg       0.96      0.96      0.96      9382\n",
            "weighted avg       0.96      0.96      0.96      9382\n",
            "\n",
            "Training time: 3.790855407714844e-05\n",
            "Test time: 3.24249267578125e-05\n",
            "\n",
            "TIME: 0.0002932548522949219seconds\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import time\n",
        "import time\n",
        "start = time.time()\n",
        "#from keras.optimizers import SGD\n",
        "#opt = SGD(lr=0.0001)\n",
        "#batch_size = 64\n",
        "\n",
        "# 1. define the network\n",
        "model = Sequential()\n",
        "model.add(LSTM(4,input_shape = X_train[0].shape))  \n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_train, y_train, epochs=50, batch_size = 20, validation_data=(X_test, y_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_test, y_preds_cnn))\n",
        "print(accuracy_score(y_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_preds_cnn))\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DNN**"
      ],
      "metadata": {
        "id": "oRjh2qoky5gN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1s8tki09nL8Q",
        "outputId": "d97d20d2-84c8-49c4-a158-d26f9bc6e9f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1877/1877 [==============================] - 8s 3ms/step - loss: 0.2229 - accuracy: 0.9926 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
            "Epoch 2/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.0949 - accuracy: 0.9801 - val_loss: 0.1464 - val_accuracy: 0.9456\n",
            "Epoch 3/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1138 - accuracy: 0.9432 - val_loss: 0.1115 - val_accuracy: 0.9456\n",
            "Epoch 4/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1063 - accuracy: 0.9432 - val_loss: 0.1051 - val_accuracy: 0.9456\n",
            "Epoch 5/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1062 - accuracy: 0.9429 - val_loss: 0.1080 - val_accuracy: 0.9456\n",
            "Epoch 6/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1065 - accuracy: 0.9432 - val_loss: 0.1060 - val_accuracy: 0.9456\n",
            "Epoch 7/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1066 - accuracy: 0.9432 - val_loss: 0.1072 - val_accuracy: 0.9456\n",
            "Epoch 8/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1066 - accuracy: 0.9432 - val_loss: 0.1055 - val_accuracy: 0.9456\n",
            "Epoch 9/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1064 - accuracy: 0.9429 - val_loss: 0.1052 - val_accuracy: 0.9456\n",
            "Epoch 10/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1064 - accuracy: 0.9432 - val_loss: 0.1055 - val_accuracy: 0.9456\n",
            "Epoch 11/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1064 - accuracy: 0.9429 - val_loss: 0.1057 - val_accuracy: 0.9456\n",
            "Epoch 12/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1065 - accuracy: 0.9432 - val_loss: 0.1054 - val_accuracy: 0.9456\n",
            "Epoch 13/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1065 - accuracy: 0.9432 - val_loss: 0.1051 - val_accuracy: 0.9456\n",
            "Epoch 14/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1066 - accuracy: 0.9430 - val_loss: 0.1058 - val_accuracy: 0.9456\n",
            "Epoch 15/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1068 - accuracy: 0.9430 - val_loss: 0.1054 - val_accuracy: 0.9456\n",
            "Epoch 16/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1059 - accuracy: 0.9431 - val_loss: 13.4849 - val_accuracy: 0.9619\n",
            "Epoch 17/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.2851 - accuracy: 0.9427 - val_loss: 0.1790 - val_accuracy: 0.9456\n",
            "Epoch 18/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1845 - accuracy: 0.9432 - val_loss: 0.1792 - val_accuracy: 0.9456\n",
            "Epoch 19/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1845 - accuracy: 0.9432 - val_loss: 0.1806 - val_accuracy: 0.9456\n",
            "Epoch 20/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1847 - accuracy: 0.9432 - val_loss: 0.1787 - val_accuracy: 0.9456\n",
            "Epoch 21/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1847 - accuracy: 0.9432 - val_loss: 0.1786 - val_accuracy: 0.9456\n",
            "Epoch 22/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1845 - accuracy: 0.9432 - val_loss: 0.1818 - val_accuracy: 0.9456\n",
            "Epoch 23/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1844 - accuracy: 0.9432 - val_loss: 0.1787 - val_accuracy: 0.9456\n",
            "Epoch 24/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1848 - accuracy: 0.9432 - val_loss: 0.1790 - val_accuracy: 0.9456\n",
            "Epoch 25/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1846 - accuracy: 0.9432 - val_loss: 0.1786 - val_accuracy: 0.9456\n",
            "Epoch 26/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1852 - accuracy: 0.9432 - val_loss: 0.1793 - val_accuracy: 0.9456\n",
            "Epoch 27/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1846 - accuracy: 0.9432 - val_loss: 0.1788 - val_accuracy: 0.9456\n",
            "Epoch 28/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1843 - accuracy: 0.9432 - val_loss: 0.1841 - val_accuracy: 0.9456\n",
            "Epoch 29/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1850 - accuracy: 0.9432 - val_loss: 0.1800 - val_accuracy: 0.9456\n",
            "Epoch 30/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1846 - accuracy: 0.9432 - val_loss: 0.1792 - val_accuracy: 0.9456\n",
            "Epoch 31/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1848 - accuracy: 0.9432 - val_loss: 0.1793 - val_accuracy: 0.9456\n",
            "Epoch 32/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1845 - accuracy: 0.9432 - val_loss: 0.1815 - val_accuracy: 0.9456\n",
            "Epoch 33/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1846 - accuracy: 0.9432 - val_loss: 0.1786 - val_accuracy: 0.9456\n",
            "Epoch 34/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1847 - accuracy: 0.9432 - val_loss: 0.1787 - val_accuracy: 0.9456\n",
            "Epoch 35/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1846 - accuracy: 0.9432 - val_loss: 0.1795 - val_accuracy: 0.9456\n",
            "Epoch 36/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1845 - accuracy: 0.9432 - val_loss: 0.1787 - val_accuracy: 0.9456\n",
            "Epoch 37/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1847 - accuracy: 0.9432 - val_loss: 0.1799 - val_accuracy: 0.9456\n",
            "Epoch 38/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1847 - accuracy: 0.9432 - val_loss: 0.1794 - val_accuracy: 0.9456\n",
            "Epoch 39/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1846 - accuracy: 0.9432 - val_loss: 0.1801 - val_accuracy: 0.9456\n",
            "Epoch 40/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1851 - accuracy: 0.9432 - val_loss: 0.1798 - val_accuracy: 0.9456\n",
            "Epoch 41/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1846 - accuracy: 0.9432 - val_loss: 0.1787 - val_accuracy: 0.9456\n",
            "Epoch 42/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1845 - accuracy: 0.9432 - val_loss: 0.1791 - val_accuracy: 0.9456\n",
            "Epoch 43/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1845 - accuracy: 0.9432 - val_loss: 0.1786 - val_accuracy: 0.9456\n",
            "Epoch 44/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1847 - accuracy: 0.9432 - val_loss: 0.1786 - val_accuracy: 0.9456\n",
            "Epoch 45/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1846 - accuracy: 0.9432 - val_loss: 0.1790 - val_accuracy: 0.9456\n",
            "Epoch 46/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1844 - accuracy: 0.9432 - val_loss: 0.1824 - val_accuracy: 0.9456\n",
            "Epoch 47/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1845 - accuracy: 0.9432 - val_loss: 0.1797 - val_accuracy: 0.9456\n",
            "Epoch 48/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1846 - accuracy: 0.9432 - val_loss: 0.1803 - val_accuracy: 0.9456\n",
            "Epoch 49/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1848 - accuracy: 0.9432 - val_loss: 0.1789 - val_accuracy: 0.9456\n",
            "Epoch 50/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1847 - accuracy: 0.9432 - val_loss: 0.1788 - val_accuracy: 0.9456\n",
            "294/294 [==============================] - 0s 1ms/step - loss: 0.1788 - accuracy: 0.9456\n",
            "[0.17883165180683136, 0.9456405639648438]\n",
            "[[4115  510]\n",
            " [   0 4757]]\n",
            "0.9456405883606906\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      4625\n",
            "           1       0.90      1.00      0.95      4757\n",
            "\n",
            "    accuracy                           0.95      9382\n",
            "   macro avg       0.95      0.94      0.95      9382\n",
            "weighted avg       0.95      0.95      0.95      9382\n",
            "\n",
            "Training time: 4.172325134277344e-05\n",
            "Test time: 4.482269287109375e-05\n",
            "\n",
            "TIME: 0.0003063678741455078seconds\n"
          ]
        }
      ],
      "source": [
        "#from keras.layers import LSTM, SimpleRNN, GRU\n",
        "#from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "# 1. define the network\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(6,)),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_train, y_train, epochs=50, batch_size = 20, validation_data=(X_test, y_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_test, y_preds_cnn))\n",
        "print(accuracy_score(y_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_preds_cnn))\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN-LSTM**"
      ],
      "metadata": {
        "id": "09Xu0Bywxt4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###############LSTM###################################\n",
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda\n",
        "\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, Dense, Dropout, Flatten, MaxPooling1D\n",
        "\n",
        "from keras.layers import LSTM, GRU, SimpleRNN\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "lstm_output_size = 20\n",
        "epochs = 10\n",
        "model = Sequential()\n",
        "model.add(Conv1D(32, 2, activation='relu', input_shape = X_train[0].shape))\n",
        "\n",
        "model.add(SimpleRNN(lstm_output_size))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_train, y_train, epochs=50, batch_size = 20, validation_data=(X_test, y_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_test, y_preds_cnn))\n",
        "print(accuracy_score(y_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_preds_cnn))\n",
        "\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cppjxvtqxzx8",
        "outputId": "d475f247-5a46-4657-fbed-79c7fda8cdc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1877/1877 [==============================] - 7s 3ms/step - loss: 0.2169 - accuracy: 0.9323 - val_loss: 0.1699 - val_accuracy: 0.9302\n",
            "Epoch 2/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2227 - accuracy: 0.9317 - val_loss: 0.2153 - val_accuracy: 0.9294\n",
            "Epoch 3/50\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.2366 - accuracy: 0.9244 - val_loss: 0.1837 - val_accuracy: 0.9444\n",
            "Epoch 4/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2314 - accuracy: 0.9238 - val_loss: 0.2053 - val_accuracy: 0.9441\n",
            "Epoch 5/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2299 - accuracy: 0.9271 - val_loss: 0.1754 - val_accuracy: 0.9448\n",
            "Epoch 6/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2399 - accuracy: 0.9239 - val_loss: 0.2157 - val_accuracy: 0.9444\n",
            "Epoch 7/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2332 - accuracy: 0.9267 - val_loss: 0.1764 - val_accuracy: 0.9443\n",
            "Epoch 8/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2304 - accuracy: 0.9275 - val_loss: 0.1750 - val_accuracy: 0.9443\n",
            "Epoch 9/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2341 - accuracy: 0.9254 - val_loss: 0.1932 - val_accuracy: 0.9293\n",
            "Epoch 10/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2325 - accuracy: 0.9242 - val_loss: 0.1910 - val_accuracy: 0.9444\n",
            "Epoch 11/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2321 - accuracy: 0.9244 - val_loss: 0.2440 - val_accuracy: 0.9293\n",
            "Epoch 12/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2301 - accuracy: 0.9263 - val_loss: 0.1785 - val_accuracy: 0.9443\n",
            "Epoch 13/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2292 - accuracy: 0.9273 - val_loss: 0.1758 - val_accuracy: 0.9443\n",
            "Epoch 14/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2339 - accuracy: 0.9254 - val_loss: 0.1789 - val_accuracy: 0.9294\n",
            "Epoch 15/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2294 - accuracy: 0.9255 - val_loss: 0.2290 - val_accuracy: 0.9443\n",
            "Epoch 16/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2341 - accuracy: 0.9255 - val_loss: 0.1990 - val_accuracy: 0.9443\n",
            "Epoch 17/50\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.2363 - accuracy: 0.9250 - val_loss: 0.2005 - val_accuracy: 0.9293\n",
            "Epoch 18/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2335 - accuracy: 0.9259 - val_loss: 0.2000 - val_accuracy: 0.9443\n",
            "Epoch 19/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2343 - accuracy: 0.9268 - val_loss: 0.1691 - val_accuracy: 0.9443\n",
            "Epoch 20/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2377 - accuracy: 0.9242 - val_loss: 0.2014 - val_accuracy: 0.9293\n",
            "Epoch 21/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2349 - accuracy: 0.9254 - val_loss: 0.2052 - val_accuracy: 0.9293\n",
            "Epoch 22/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2282 - accuracy: 0.9261 - val_loss: 0.2130 - val_accuracy: 0.9443\n",
            "Epoch 23/50\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.2316 - accuracy: 0.9251 - val_loss: 0.2777 - val_accuracy: 0.9293\n",
            "Epoch 24/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2357 - accuracy: 0.9246 - val_loss: 0.1752 - val_accuracy: 0.9443\n",
            "Epoch 25/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2336 - accuracy: 0.9268 - val_loss: 0.2440 - val_accuracy: 0.9293\n",
            "Epoch 26/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2251 - accuracy: 0.9288 - val_loss: 0.1710 - val_accuracy: 0.9444\n",
            "Epoch 27/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2319 - accuracy: 0.9262 - val_loss: 0.2029 - val_accuracy: 0.9293\n",
            "Epoch 28/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2384 - accuracy: 0.9242 - val_loss: 0.1912 - val_accuracy: 0.9293\n",
            "Epoch 29/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.2361 - accuracy: 0.9256 - val_loss: 0.1712 - val_accuracy: 0.9443\n",
            "Epoch 30/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.2275 - accuracy: 0.9286 - val_loss: 0.1817 - val_accuracy: 0.9293\n",
            "Epoch 31/50\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.2347 - accuracy: 0.9246 - val_loss: 0.1937 - val_accuracy: 0.9293\n",
            "Epoch 32/50\n",
            "1877/1877 [==============================] - 9s 5ms/step - loss: 0.2346 - accuracy: 0.9246 - val_loss: 0.2110 - val_accuracy: 0.9443\n",
            "Epoch 33/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2342 - accuracy: 0.9246 - val_loss: 0.2074 - val_accuracy: 0.9293\n",
            "Epoch 34/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2333 - accuracy: 0.9259 - val_loss: 0.2158 - val_accuracy: 0.9293\n",
            "Epoch 35/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2367 - accuracy: 0.9244 - val_loss: 0.1744 - val_accuracy: 0.9444\n",
            "Epoch 36/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2326 - accuracy: 0.9261 - val_loss: 0.2249 - val_accuracy: 0.9293\n",
            "Epoch 37/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2338 - accuracy: 0.9242 - val_loss: 0.1902 - val_accuracy: 0.9293\n",
            "Epoch 38/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.2369 - accuracy: 0.9247 - val_loss: 0.2506 - val_accuracy: 0.9293\n",
            "Epoch 39/50\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.2401 - accuracy: 0.9236 - val_loss: 0.1811 - val_accuracy: 0.9293\n",
            "Epoch 40/50\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.2308 - accuracy: 0.9259 - val_loss: 0.1738 - val_accuracy: 0.9293\n",
            "Epoch 41/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.2333 - accuracy: 0.9256 - val_loss: 0.1929 - val_accuracy: 0.9443\n",
            "Epoch 42/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.2291 - accuracy: 0.9274 - val_loss: 0.2132 - val_accuracy: 0.9443\n",
            "Epoch 43/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.2289 - accuracy: 0.9266 - val_loss: 0.1806 - val_accuracy: 0.9293\n",
            "Epoch 44/50\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.2324 - accuracy: 0.9267 - val_loss: 0.3281 - val_accuracy: 0.9293\n",
            "Epoch 45/50\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.2335 - accuracy: 0.9267 - val_loss: 0.2103 - val_accuracy: 0.9293\n",
            "Epoch 46/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.2389 - accuracy: 0.9251 - val_loss: 0.1949 - val_accuracy: 0.9293\n",
            "Epoch 47/50\n",
            "1877/1877 [==============================] - 7s 3ms/step - loss: 0.2304 - accuracy: 0.9262 - val_loss: 0.2100 - val_accuracy: 0.9293\n",
            "Epoch 48/50\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.2346 - accuracy: 0.9243 - val_loss: 0.1719 - val_accuracy: 0.9443\n",
            "Epoch 49/50\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.2346 - accuracy: 0.9254 - val_loss: 0.1900 - val_accuracy: 0.9443\n",
            "Epoch 50/50\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.2320 - accuracy: 0.9256 - val_loss: 0.1793 - val_accuracy: 0.9293\n",
            "294/294 [==============================] - 1s 2ms/step - loss: 0.1793 - accuracy: 0.9293\n",
            "[0.17933616042137146, 0.9293327927589417]\n",
            "[[4235  390]\n",
            " [ 273 4484]]\n",
            "0.9293327648688979\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.92      0.93      4625\n",
            "           1       0.92      0.94      0.93      4757\n",
            "\n",
            "    accuracy                           0.93      9382\n",
            "   macro avg       0.93      0.93      0.93      9382\n",
            "weighted avg       0.93      0.93      0.93      9382\n",
            "\n",
            "Training time: 3.743171691894531e-05\n",
            "Test time: 1.811981201171875e-05\n",
            "\n",
            "TIME: 0.0002818107604980469seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPvdsaOhkBxo"
      },
      "source": [
        "# **ICU-Federated**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCB02TKElpff"
      },
      "outputs": [],
      "source": [
        "import numpy as np  \n",
        "import pandas as pd\n",
        "import os \n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0lF22s2kRqd",
        "outputId": "32b44914-e9a8-49e9-c4c6-3194fba36432"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['frame.time_delta', 'frame.time_relative', 'frame.len', 'ip.src',\n",
              "       'ip.dst', 'tcp.srcport', 'tcp.dstport', 'tcp.flags', 'tcp.time_delta',\n",
              "       'tcp.len', 'tcp.ack', 'tcp.connection.fin', 'tcp.connection.rst',\n",
              "       'tcp.connection.sack', 'tcp.connection.syn', 'tcp.flags.ack',\n",
              "       'tcp.flags.fin', 'tcp.flags.push', 'tcp.flags.reset', 'tcp.flags.syn',\n",
              "       'tcp.flags.urg', 'tcp.hdr_len', 'tcp.payload', 'tcp.pdu.size',\n",
              "       'tcp.window_size_value', 'tcp.checksum', 'mqtt.clientid',\n",
              "       'mqtt.clientid_len', 'mqtt.conack.flags', 'mqtt.conack.val',\n",
              "       'mqtt.conflag.passwd', 'mqtt.conflag.qos', 'mqtt.conflag.reserved',\n",
              "       'mqtt.conflag.retain', 'mqtt.conflag.willflag', 'mqtt.conflags',\n",
              "       'mqtt.dupflag', 'mqtt.hdrflags', 'mqtt.kalive', 'mqtt.len', 'mqtt.msg',\n",
              "       'mqtt.msgtype', 'mqtt.qos', 'mqtt.retain', 'mqtt.topic',\n",
              "       'mqtt.topic_len', 'mqtt.ver', 'mqtt.willmsg_len', 'ip.proto', 'ip.ttl',\n",
              "       'class', 'label'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1 = pd.read_csv('/content/drive/MyDrive/ICU/environmentMonitoring.csv')\n",
        "df1.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GByA-wsDkecN",
        "outputId": "2847472b-e420-46d5-f8be-70bb79531a5c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['environmentMonitoring.csv', 'Attack.csv']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "path = '/content/drive/MyDrive/ICU/'\n",
        "csvs = os.listdir(path)\n",
        "csvs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUOXLjZckcg4",
        "outputId": "68260f9a-3e68-4927-8d31-b29a51f4041f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---- Reading environmentMonitoring.csv ----\n",
            "df.shape: (31758, 52)\n",
            "empty_cols: 0\n",
            "[]\n",
            "df1.shape: (31758, 52)\n",
            "---- Reading Attack.csv ----\n",
            "df.shape: (80126, 52)\n",
            "empty_cols: 0\n",
            "[]\n",
            "df1.shape: (111884, 52)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (26,28,35) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "df1 = pd.DataFrame()\n",
        "\n",
        "for csv in csvs:\n",
        "  print(f'---- Reading {csv} ----')\n",
        "  df = pd.read_csv(path+csv)\n",
        "  print(f'df.shape: {df.shape}')\n",
        "  empty_cols = [col for col in df.columns if df[col].isnull().all()]\n",
        "  print(f'empty_cols: {len(empty_cols)}')\n",
        "  print(empty_cols)\n",
        "  df.fillna(0, inplace=True)\n",
        "  df1 = df1.append(df, ignore_index=True)\n",
        "  print(f'df1.shape: {df1.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMYMJj1umiv5"
      },
      "outputs": [],
      "source": [
        "feats = ['ip.src', 'ip.dst', 'tcp.srcport', 'tcp.dstport','mqtt.topic', 'mqtt.msg', 'tcp.payload','mqtt.clientid', 'mqtt.conflags', 'mqtt.conack.flags', 'class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_EKi1dQmmGr",
        "outputId": "21043f41-01d8-409f-ef78-2058f3f8a31e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(111884, 41)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.drop(labels=feats, axis=1, inplace=True)\n",
        "df1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGa--i10XJuK",
        "outputId": "f27df765-581c-4f9e-ecf1-54659d6e9f60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 111884 entries, 0 to 111883\n",
            "Data columns (total 41 columns):\n",
            " #   Column                 Non-Null Count   Dtype  \n",
            "---  ------                 --------------   -----  \n",
            " 0   frame.time_delta       111884 non-null  float64\n",
            " 1   frame.time_relative    111884 non-null  float64\n",
            " 2   frame.len              111884 non-null  int64  \n",
            " 3   tcp.flags              111884 non-null  object \n",
            " 4   tcp.time_delta         111884 non-null  float64\n",
            " 5   tcp.len                111884 non-null  int64  \n",
            " 6   tcp.ack                111884 non-null  int64  \n",
            " 7   tcp.connection.fin     111884 non-null  float64\n",
            " 8   tcp.connection.rst     111884 non-null  float64\n",
            " 9   tcp.connection.sack    111884 non-null  float64\n",
            " 10  tcp.connection.syn     111884 non-null  float64\n",
            " 11  tcp.flags.ack          111884 non-null  int64  \n",
            " 12  tcp.flags.fin          111884 non-null  int64  \n",
            " 13  tcp.flags.push         111884 non-null  int64  \n",
            " 14  tcp.flags.reset        111884 non-null  int64  \n",
            " 15  tcp.flags.syn          111884 non-null  int64  \n",
            " 16  tcp.flags.urg          111884 non-null  int64  \n",
            " 17  tcp.hdr_len            111884 non-null  int64  \n",
            " 18  tcp.pdu.size           111884 non-null  float64\n",
            " 19  tcp.window_size_value  111884 non-null  int64  \n",
            " 20  tcp.checksum           111884 non-null  object \n",
            " 21  mqtt.clientid_len      111884 non-null  float64\n",
            " 22  mqtt.conack.val        111884 non-null  float64\n",
            " 23  mqtt.conflag.passwd    111884 non-null  float64\n",
            " 24  mqtt.conflag.qos       111884 non-null  float64\n",
            " 25  mqtt.conflag.reserved  111884 non-null  float64\n",
            " 26  mqtt.conflag.retain    111884 non-null  float64\n",
            " 27  mqtt.conflag.willflag  111884 non-null  float64\n",
            " 28  mqtt.dupflag           111884 non-null  float64\n",
            " 29  mqtt.hdrflags          111884 non-null  object \n",
            " 30  mqtt.kalive            111884 non-null  float64\n",
            " 31  mqtt.len               111884 non-null  float64\n",
            " 32  mqtt.msgtype           111884 non-null  float64\n",
            " 33  mqtt.qos               111884 non-null  float64\n",
            " 34  mqtt.retain            111884 non-null  float64\n",
            " 35  mqtt.topic_len         111884 non-null  float64\n",
            " 36  mqtt.ver               111884 non-null  float64\n",
            " 37  mqtt.willmsg_len       111884 non-null  float64\n",
            " 38  ip.proto               111884 non-null  int64  \n",
            " 39  ip.ttl                 111884 non-null  int64  \n",
            " 40  label                  111884 non-null  int64  \n",
            "dtypes: float64(24), int64(14), object(3)\n",
            "memory usage: 35.0+ MB\n"
          ]
        }
      ],
      "source": [
        "df1.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "QoWN808rm2bA",
        "outputId": "7007f18d-b449-4cd2-f111-d03cc982f154"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-66f2ee1a-e95e-493f-83cf-3b963bf4002c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frame.time_delta</th>\n",
              "      <th>frame.time_relative</th>\n",
              "      <th>frame.len</th>\n",
              "      <th>tcp.flags</th>\n",
              "      <th>tcp.time_delta</th>\n",
              "      <th>tcp.len</th>\n",
              "      <th>tcp.ack</th>\n",
              "      <th>tcp.connection.fin</th>\n",
              "      <th>tcp.connection.rst</th>\n",
              "      <th>tcp.connection.sack</th>\n",
              "      <th>tcp.connection.syn</th>\n",
              "      <th>tcp.flags.ack</th>\n",
              "      <th>tcp.flags.fin</th>\n",
              "      <th>tcp.flags.push</th>\n",
              "      <th>tcp.flags.reset</th>\n",
              "      <th>tcp.flags.syn</th>\n",
              "      <th>tcp.flags.urg</th>\n",
              "      <th>tcp.hdr_len</th>\n",
              "      <th>tcp.pdu.size</th>\n",
              "      <th>tcp.window_size_value</th>\n",
              "      <th>tcp.checksum</th>\n",
              "      <th>mqtt.clientid_len</th>\n",
              "      <th>mqtt.conack.val</th>\n",
              "      <th>mqtt.conflag.passwd</th>\n",
              "      <th>mqtt.conflag.qos</th>\n",
              "      <th>mqtt.conflag.reserved</th>\n",
              "      <th>mqtt.conflag.retain</th>\n",
              "      <th>mqtt.conflag.willflag</th>\n",
              "      <th>mqtt.dupflag</th>\n",
              "      <th>mqtt.hdrflags</th>\n",
              "      <th>mqtt.kalive</th>\n",
              "      <th>mqtt.len</th>\n",
              "      <th>mqtt.msgtype</th>\n",
              "      <th>mqtt.qos</th>\n",
              "      <th>mqtt.retain</th>\n",
              "      <th>mqtt.topic_len</th>\n",
              "      <th>mqtt.ver</th>\n",
              "      <th>mqtt.willmsg_len</th>\n",
              "      <th>ip.proto</th>\n",
              "      <th>ip.ttl</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>105</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>37.0</td>\n",
              "      <td>512</td>\n",
              "      <td>0x00001141</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0x00000010</td>\n",
              "      <td>60.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000053</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>72</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>4</td>\n",
              "      <td>38</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>4.0</td>\n",
              "      <td>512</td>\n",
              "      <td>0x00001120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0x00000020</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000043</td>\n",
              "      <td>0.000096</td>\n",
              "      <td>105</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>37.0</td>\n",
              "      <td>512</td>\n",
              "      <td>0x00001143</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0x00000010</td>\n",
              "      <td>60.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>72</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>4</td>\n",
              "      <td>38</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>4.0</td>\n",
              "      <td>512</td>\n",
              "      <td>0x00001122</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0x00000020</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000132</td>\n",
              "      <td>105</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>37.0</td>\n",
              "      <td>512</td>\n",
              "      <td>0x00001145</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0x00000010</td>\n",
              "      <td>60.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66f2ee1a-e95e-493f-83cf-3b963bf4002c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-66f2ee1a-e95e-493f-83cf-3b963bf4002c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-66f2ee1a-e95e-493f-83cf-3b963bf4002c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   frame.time_delta  frame.time_relative  frame.len  ... ip.proto  ip.ttl  label\n",
              "0          0.000000             0.000000        105  ...        6      64      0\n",
              "1          0.000053             0.000053         72  ...        6      64      0\n",
              "2          0.000043             0.000096        105  ...        6      64      0\n",
              "3          0.000020             0.000116         72  ...        6      64      0\n",
              "4          0.000016             0.000132        105  ...        6      64      0\n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJWyFCPym71B",
        "outputId": "b6a20770-e4bd-4cac-d4c3-307fef6afaa4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    80126\n",
              "0    31758\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "Sr_KvgJjHdNV",
        "outputId": "5c7245e3-7ccc-4e20-e7fc-7a9995a42aec"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x360 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import missingno as msno\n",
        "figure, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,5))\n",
        "msno.matrix(df, ax=ax1, sparkline=False, color=(0.45, 0.25, 0.35))\n",
        "msno.bar(df1, ax=ax2, color=(0.25, 0.35, 0.25))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5-JDA7OH2OZ",
        "outputId": "17e72152-8d89-4e24-be8a-298472cc934b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "frame.time_delta         0\n",
              "frame.time_relative      0\n",
              "frame.len                0\n",
              "tcp.flags                0\n",
              "tcp.time_delta           0\n",
              "tcp.len                  0\n",
              "tcp.ack                  0\n",
              "tcp.connection.fin       0\n",
              "tcp.connection.rst       0\n",
              "tcp.connection.sack      0\n",
              "tcp.connection.syn       0\n",
              "tcp.flags.ack            0\n",
              "tcp.flags.fin            0\n",
              "tcp.flags.push           0\n",
              "tcp.flags.reset          0\n",
              "tcp.flags.syn            0\n",
              "tcp.flags.urg            0\n",
              "tcp.hdr_len              0\n",
              "tcp.pdu.size             0\n",
              "tcp.window_size_value    0\n",
              "tcp.checksum             0\n",
              "mqtt.clientid_len        0\n",
              "mqtt.conack.val          0\n",
              "mqtt.conflag.passwd      0\n",
              "mqtt.conflag.qos         0\n",
              "mqtt.conflag.reserved    0\n",
              "mqtt.conflag.retain      0\n",
              "mqtt.conflag.willflag    0\n",
              "mqtt.dupflag             0\n",
              "mqtt.hdrflags            0\n",
              "mqtt.kalive              0\n",
              "mqtt.len                 0\n",
              "mqtt.msgtype             0\n",
              "mqtt.qos                 0\n",
              "mqtt.retain              0\n",
              "mqtt.topic_len           0\n",
              "mqtt.ver                 0\n",
              "mqtt.willmsg_len         0\n",
              "ip.proto                 0\n",
              "ip.ttl                   0\n",
              "label                    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gBwqEKJH6To",
        "outputId": "bf7ce9e4-73e8-4233-af5c-4b52b950da2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 41)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1[df1.duplicated()].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDsu2rnYIE9o"
      },
      "outputs": [],
      "source": [
        "\n",
        "df1 = df1.drop(df1[df1.duplicated()].index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvIptj4KILrQ",
        "outputId": "4f3a696b-6e21-4a10-869b-6bbc359fd2bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0, 41)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1[df1.duplicated()].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1o4lcmU1XgAj",
        "outputId": "80e3e6df-8116-4df8-a105-52f9e73cf0d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 111882 entries, 0 to 111883\n",
            "Data columns (total 41 columns):\n",
            " #   Column                 Non-Null Count   Dtype  \n",
            "---  ------                 --------------   -----  \n",
            " 0   frame.time_delta       111882 non-null  float64\n",
            " 1   frame.time_relative    111882 non-null  float64\n",
            " 2   frame.len              111882 non-null  int64  \n",
            " 3   tcp.flags              111882 non-null  object \n",
            " 4   tcp.time_delta         111882 non-null  float64\n",
            " 5   tcp.len                111882 non-null  int64  \n",
            " 6   tcp.ack                111882 non-null  int64  \n",
            " 7   tcp.connection.fin     111882 non-null  float64\n",
            " 8   tcp.connection.rst     111882 non-null  float64\n",
            " 9   tcp.connection.sack    111882 non-null  float64\n",
            " 10  tcp.connection.syn     111882 non-null  float64\n",
            " 11  tcp.flags.ack          111882 non-null  int64  \n",
            " 12  tcp.flags.fin          111882 non-null  int64  \n",
            " 13  tcp.flags.push         111882 non-null  int64  \n",
            " 14  tcp.flags.reset        111882 non-null  int64  \n",
            " 15  tcp.flags.syn          111882 non-null  int64  \n",
            " 16  tcp.flags.urg          111882 non-null  int64  \n",
            " 17  tcp.hdr_len            111882 non-null  int64  \n",
            " 18  tcp.pdu.size           111882 non-null  float64\n",
            " 19  tcp.window_size_value  111882 non-null  int64  \n",
            " 20  tcp.checksum           111882 non-null  object \n",
            " 21  mqtt.clientid_len      111882 non-null  float64\n",
            " 22  mqtt.conack.val        111882 non-null  float64\n",
            " 23  mqtt.conflag.passwd    111882 non-null  float64\n",
            " 24  mqtt.conflag.qos       111882 non-null  float64\n",
            " 25  mqtt.conflag.reserved  111882 non-null  float64\n",
            " 26  mqtt.conflag.retain    111882 non-null  float64\n",
            " 27  mqtt.conflag.willflag  111882 non-null  float64\n",
            " 28  mqtt.dupflag           111882 non-null  float64\n",
            " 29  mqtt.hdrflags          111882 non-null  object \n",
            " 30  mqtt.kalive            111882 non-null  float64\n",
            " 31  mqtt.len               111882 non-null  float64\n",
            " 32  mqtt.msgtype           111882 non-null  float64\n",
            " 33  mqtt.qos               111882 non-null  float64\n",
            " 34  mqtt.retain            111882 non-null  float64\n",
            " 35  mqtt.topic_len         111882 non-null  float64\n",
            " 36  mqtt.ver               111882 non-null  float64\n",
            " 37  mqtt.willmsg_len       111882 non-null  float64\n",
            " 38  ip.proto               111882 non-null  int64  \n",
            " 39  ip.ttl                 111882 non-null  int64  \n",
            " 40  label                  111882 non-null  int64  \n",
            "dtypes: float64(24), int64(14), object(3)\n",
            "memory usage: 35.9+ MB\n"
          ]
        }
      ],
      "source": [
        "df1.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjukQQOXZzUA"
      },
      "outputs": [],
      "source": [
        "col=['tcp.flags.ack', 'tcp.flags.fin']\n",
        "#col = ['tcp.flags', 'tcp.checksum', 'mqtt.hdrflags', 'tcp.flags.ack', 'tcp.flags.fin']\n",
        "df1 = df1.drop(columns=col)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhv2NXnDXkFK",
        "outputId": "99330586-e084-4aec-bc87-f7e2d90c5ee1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 111882 entries, 0 to 111883\n",
            "Data columns (total 43 columns):\n",
            " #   Column                 Non-Null Count   Dtype  \n",
            "---  ------                 --------------   -----  \n",
            " 0   frame.time_delta       111882 non-null  float64\n",
            " 1   frame.time_relative    111882 non-null  float64\n",
            " 2   frame.len              111882 non-null  float64\n",
            " 3   tcp.flags              111882 non-null  object \n",
            " 4   tcp.time_delta         111882 non-null  float64\n",
            " 5   tcp.len                111882 non-null  float64\n",
            " 6   tcp.ack                111882 non-null  float64\n",
            " 7   tcp.connection.fin     111882 non-null  float64\n",
            " 8   tcp.connection.rst     111882 non-null  float64\n",
            " 9   tcp.connection.sack    111882 non-null  float64\n",
            " 10  tcp.connection.syn     111882 non-null  float64\n",
            " 11  tcp.flags.ack          111882 non-null  int64  \n",
            " 12  tcp.flags.fin          111882 non-null  int64  \n",
            " 13  tcp.flags.push         111882 non-null  float64\n",
            " 14  tcp.flags.reset        111882 non-null  float64\n",
            " 15  tcp.flags.syn          111882 non-null  float64\n",
            " 16  tcp.flags.urg          111882 non-null  float64\n",
            " 17  tcp.hdr_len            111882 non-null  float64\n",
            " 18  tcp.pdu.size           111882 non-null  float64\n",
            " 19  tcp.window_size_value  111882 non-null  float64\n",
            " 20  tcp.checksum           111882 non-null  object \n",
            " 21  mqtt.clientid_len      111882 non-null  float64\n",
            " 22  mqtt.conack.val        111882 non-null  float64\n",
            " 23  mqtt.conflag.passwd    111882 non-null  float64\n",
            " 24  mqtt.conflag.qos       111882 non-null  float64\n",
            " 25  mqtt.conflag.reserved  111882 non-null  float64\n",
            " 26  mqtt.conflag.retain    111882 non-null  float64\n",
            " 27  mqtt.conflag.willflag  111882 non-null  float64\n",
            " 28  mqtt.dupflag           111882 non-null  float64\n",
            " 29  mqtt.hdrflags          111882 non-null  object \n",
            " 30  mqtt.kalive            111882 non-null  float64\n",
            " 31  mqtt.len               111882 non-null  float64\n",
            " 32  mqtt.msgtype           111882 non-null  float64\n",
            " 33  mqtt.qos               111882 non-null  float64\n",
            " 34  mqtt.retain            111882 non-null  float64\n",
            " 35  mqtt.topic_len         111882 non-null  float64\n",
            " 36  mqtt.ver               111882 non-null  float64\n",
            " 37  mqtt.willmsg_len       111882 non-null  float64\n",
            " 38  ip.proto               111882 non-null  float64\n",
            " 39  ip.ttl                 111882 non-null  float64\n",
            " 40  label                  111882 non-null  int64  \n",
            " 41  tcp.flags.ack          111882 non-null  float64\n",
            " 42  tcp.flags.fin          111882 non-null  float64\n",
            "dtypes: float64(37), int64(3), object(3)\n",
            "memory usage: 37.6+ MB\n"
          ]
        }
      ],
      "source": [
        "  \n",
        "df1['frame.len'] = df1['frame.len'].astype(float)\n",
        "#df1['tcp.flags'] = df1['tcp.flags'].astype(float)\n",
        "df1['tcp.len'] = df1['tcp.len'].astype(float)\n",
        "df1['tcp.ack'] = df1['tcp.ack'].astype(float)\n",
        "df1['tcp.flags.ack '] = df1['tcp.flags.ack'].astype(float)\n",
        "df1['tcp.flags.fin '] = df1['tcp.flags.fin'].astype(float)\n",
        "df1['tcp.flags.push'] = df1['tcp.flags.push'].astype(float)\n",
        "df1['tcp.flags.reset'] = df1['tcp.flags.reset'].astype(float)\n",
        "df1['tcp.flags.syn'] = df1['tcp.flags.syn'].astype(float)\n",
        "df1['tcp.flags.urg'] = df1['tcp.flags.urg'].astype(float)\n",
        "df1['tcp.hdr_len'] = df1['tcp.hdr_len'].astype(float)\n",
        "df1['tcp.window_size_value'] = df1['tcp.window_size_value'].astype(float)\n",
        "#df1['tcp.checksum'] = df1['tcp.checksum'].astype(float)\n",
        "\n",
        "#df1['mqtt.hdrflags'] = df1['mqtt.hdrflags'].astype(float)\n",
        "df1['ip.proto'] = df1['ip.proto'].astype(float)\n",
        "df1['ip.ttl'] = df1['ip.ttl'].astype(float)\n",
        "\n",
        "df1.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1tgGdY7b89L"
      },
      "outputs": [],
      "source": [
        "df1['tcp.flags.ack '] = df1['tcp.flags.ack'].astype(float)\n",
        "df1['tcp.flags.fin '] = df1['tcp.flags.fin'].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "w2Kz7YpBb-04",
        "outputId": "d96d12c5-db16-46fd-d2cc-451644bc33a1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9f646ace-d0b0-4281-9d74-f728bbf6b774\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frame.time_delta</th>\n",
              "      <th>frame.time_relative</th>\n",
              "      <th>frame.len</th>\n",
              "      <th>tcp.flags</th>\n",
              "      <th>tcp.time_delta</th>\n",
              "      <th>tcp.len</th>\n",
              "      <th>tcp.ack</th>\n",
              "      <th>tcp.connection.fin</th>\n",
              "      <th>tcp.connection.rst</th>\n",
              "      <th>tcp.connection.sack</th>\n",
              "      <th>tcp.connection.syn</th>\n",
              "      <th>tcp.flags.ack</th>\n",
              "      <th>tcp.flags.fin</th>\n",
              "      <th>tcp.flags.push</th>\n",
              "      <th>tcp.flags.reset</th>\n",
              "      <th>tcp.flags.syn</th>\n",
              "      <th>tcp.flags.urg</th>\n",
              "      <th>tcp.hdr_len</th>\n",
              "      <th>tcp.pdu.size</th>\n",
              "      <th>tcp.window_size_value</th>\n",
              "      <th>tcp.checksum</th>\n",
              "      <th>mqtt.clientid_len</th>\n",
              "      <th>mqtt.conack.val</th>\n",
              "      <th>mqtt.conflag.passwd</th>\n",
              "      <th>mqtt.conflag.qos</th>\n",
              "      <th>mqtt.conflag.reserved</th>\n",
              "      <th>mqtt.conflag.retain</th>\n",
              "      <th>mqtt.conflag.willflag</th>\n",
              "      <th>mqtt.dupflag</th>\n",
              "      <th>mqtt.hdrflags</th>\n",
              "      <th>mqtt.kalive</th>\n",
              "      <th>mqtt.len</th>\n",
              "      <th>mqtt.msgtype</th>\n",
              "      <th>mqtt.qos</th>\n",
              "      <th>mqtt.retain</th>\n",
              "      <th>mqtt.topic_len</th>\n",
              "      <th>mqtt.ver</th>\n",
              "      <th>mqtt.willmsg_len</th>\n",
              "      <th>ip.proto</th>\n",
              "      <th>ip.ttl</th>\n",
              "      <th>label</th>\n",
              "      <th>tcp.flags.ack</th>\n",
              "      <th>tcp.flags.fin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>105.0</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>512.0</td>\n",
              "      <td>0x00001141</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0x00000010</td>\n",
              "      <td>60.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000053</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>4.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>512.0</td>\n",
              "      <td>0x00001120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0x00000020</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000043</td>\n",
              "      <td>0.000096</td>\n",
              "      <td>105.0</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>512.0</td>\n",
              "      <td>0x00001143</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0x00000010</td>\n",
              "      <td>60.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>4.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>512.0</td>\n",
              "      <td>0x00001122</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0x00000020</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000132</td>\n",
              "      <td>105.0</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>512.0</td>\n",
              "      <td>0x00001145</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0x00000010</td>\n",
              "      <td>60.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f646ace-d0b0-4281-9d74-f728bbf6b774')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f646ace-d0b0-4281-9d74-f728bbf6b774 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f646ace-d0b0-4281-9d74-f728bbf6b774');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   frame.time_delta  frame.time_relative  ...  tcp.flags.ack  tcp.flags.fin \n",
              "0          0.000000             0.000000  ...             1.0            0.0\n",
              "1          0.000053             0.000053  ...             1.0            0.0\n",
              "2          0.000043             0.000096  ...             1.0            0.0\n",
              "3          0.000020             0.000116  ...             1.0            0.0\n",
              "4          0.000016             0.000132  ...             1.0            0.0\n",
              "\n",
              "[5 rows x 43 columns]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8AJpuPcrtRQ"
      },
      "outputs": [],
      "source": [
        "df1.tcp.flags.fin.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwaUMzxi0l-g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOZ1OKaPi8ck"
      },
      "outputs": [],
      "source": [
        "df1.to_csv('/content/drive/MyDrive/ICU/clean_ICU.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKLMJgsXpUbG"
      },
      "outputs": [],
      "source": [
        "df_ICU1 = pd.read_csv('/content/drive/MyDrive/ICU/clean_ICU.csv')\n",
        "df_ICU= df_ICU1.sample(frac=1, random_state = 13).reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "pnT6mk4C0sia",
        "outputId": "cfe81bfe-8075-4195-ebb4-e36c875e6949"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ee97a20b-a244-4632-917a-81f779b68375\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>frame.time_delta</th>\n",
              "      <th>frame.time_relative</th>\n",
              "      <th>frame.len</th>\n",
              "      <th>tcp.flags</th>\n",
              "      <th>tcp.time_delta</th>\n",
              "      <th>tcp.len</th>\n",
              "      <th>tcp.ack</th>\n",
              "      <th>tcp.connection.fin</th>\n",
              "      <th>tcp.connection.rst</th>\n",
              "      <th>tcp.connection.sack</th>\n",
              "      <th>tcp.connection.syn</th>\n",
              "      <th>tcp.flags.ack</th>\n",
              "      <th>tcp.flags.fin</th>\n",
              "      <th>tcp.flags.push</th>\n",
              "      <th>tcp.flags.reset</th>\n",
              "      <th>tcp.flags.syn</th>\n",
              "      <th>tcp.flags.urg</th>\n",
              "      <th>tcp.hdr_len</th>\n",
              "      <th>tcp.pdu.size</th>\n",
              "      <th>tcp.window_size_value</th>\n",
              "      <th>tcp.checksum</th>\n",
              "      <th>mqtt.clientid_len</th>\n",
              "      <th>mqtt.conack.val</th>\n",
              "      <th>mqtt.conflag.passwd</th>\n",
              "      <th>mqtt.conflag.qos</th>\n",
              "      <th>mqtt.conflag.reserved</th>\n",
              "      <th>mqtt.conflag.retain</th>\n",
              "      <th>mqtt.conflag.willflag</th>\n",
              "      <th>mqtt.dupflag</th>\n",
              "      <th>mqtt.hdrflags</th>\n",
              "      <th>mqtt.kalive</th>\n",
              "      <th>mqtt.len</th>\n",
              "      <th>mqtt.msgtype</th>\n",
              "      <th>mqtt.qos</th>\n",
              "      <th>mqtt.retain</th>\n",
              "      <th>mqtt.topic_len</th>\n",
              "      <th>mqtt.ver</th>\n",
              "      <th>mqtt.willmsg_len</th>\n",
              "      <th>ip.proto</th>\n",
              "      <th>ip.ttl</th>\n",
              "      <th>label</th>\n",
              "      <th>tcp.flags.ack</th>\n",
              "      <th>tcp.flags.fin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>106364</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>124.501195</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0x00000011</td>\n",
              "      <td>0.000387</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>513.0</td>\n",
              "      <td>0x0000517f</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>42451</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>4.103763</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>8.0</td>\n",
              "      <td>29055.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>513.0</td>\n",
              "      <td>0x0000904c</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0x00000040</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>92699</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>55.687269</td>\n",
              "      <td>1514.0</td>\n",
              "      <td>0x00000010</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>1460.0</td>\n",
              "      <td>20765.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>166.0</td>\n",
              "      <td>4094.0</td>\n",
              "      <td>0x0000b189</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0x00000032</td>\n",
              "      <td>0.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>87923</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>51.196503</td>\n",
              "      <td>1514.0</td>\n",
              "      <td>0x00000010</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>1460.0</td>\n",
              "      <td>25001.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>4094.0</td>\n",
              "      <td>0x0000ad98</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0x00000032</td>\n",
              "      <td>0.0</td>\n",
              "      <td>169.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25956</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>949.246403</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3872.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>512.0</td>\n",
              "      <td>0x0000413e</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0x00000040</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee97a20b-a244-4632-917a-81f779b68375')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ee97a20b-a244-4632-917a-81f779b68375 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ee97a20b-a244-4632-917a-81f779b68375');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  frame.time_delta  ...  tcp.flags.ack   tcp.flags.fin \n",
              "0      106364          0.000002  ...             1.0             1.0\n",
              "1       42451          0.000001  ...             1.0             0.0\n",
              "2       92699          0.000067  ...             1.0             0.0\n",
              "3       87923          0.000082  ...             1.0             0.0\n",
              "4       25956          0.000011  ...             1.0             0.0\n",
              "\n",
              "[5 rows x 44 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_ICU.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "5DwoVG-407ce",
        "outputId": "951941db-fd88-4440-9842-3f0f4491a723"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3dc2b97c-123a-4e31-94a0-4f3c6b8e46e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>frame.time_delta</th>\n",
              "      <th>frame.time_relative</th>\n",
              "      <th>frame.len</th>\n",
              "      <th>tcp.flags</th>\n",
              "      <th>tcp.time_delta</th>\n",
              "      <th>tcp.len</th>\n",
              "      <th>tcp.ack</th>\n",
              "      <th>tcp.connection.fin</th>\n",
              "      <th>tcp.connection.rst</th>\n",
              "      <th>tcp.connection.sack</th>\n",
              "      <th>tcp.connection.syn</th>\n",
              "      <th>tcp.flags.push</th>\n",
              "      <th>tcp.flags.reset</th>\n",
              "      <th>tcp.flags.syn</th>\n",
              "      <th>tcp.flags.urg</th>\n",
              "      <th>tcp.hdr_len</th>\n",
              "      <th>tcp.pdu.size</th>\n",
              "      <th>tcp.window_size_value</th>\n",
              "      <th>mqtt.clientid_len</th>\n",
              "      <th>mqtt.conack.val</th>\n",
              "      <th>mqtt.conflag.passwd</th>\n",
              "      <th>mqtt.conflag.qos</th>\n",
              "      <th>mqtt.conflag.reserved</th>\n",
              "      <th>mqtt.conflag.retain</th>\n",
              "      <th>mqtt.conflag.willflag</th>\n",
              "      <th>mqtt.dupflag</th>\n",
              "      <th>mqtt.kalive</th>\n",
              "      <th>mqtt.len</th>\n",
              "      <th>mqtt.msgtype</th>\n",
              "      <th>mqtt.qos</th>\n",
              "      <th>mqtt.retain</th>\n",
              "      <th>mqtt.topic_len</th>\n",
              "      <th>mqtt.ver</th>\n",
              "      <th>mqtt.willmsg_len</th>\n",
              "      <th>ip.proto</th>\n",
              "      <th>ip.ttl</th>\n",
              "      <th>label</th>\n",
              "      <th>tcp.flags.ack</th>\n",
              "      <th>tcp.flags.fin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3dc2b97c-123a-4e31-94a0-4f3c6b8e46e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3dc2b97c-123a-4e31-94a0-4f3c6b8e46e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3dc2b97c-123a-4e31-94a0-4f3c6b8e46e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Unnamed: 0, frame.time_delta, frame.time_relative, frame.len, tcp.flags, tcp.time_delta, tcp.len, tcp.ack, tcp.connection.fin, tcp.connection.rst, tcp.connection.sack, tcp.connection.syn, tcp.flags.push, tcp.flags.reset, tcp.flags.syn, tcp.flags.urg, tcp.hdr_len, tcp.pdu.size, tcp.window_size_value, mqtt.clientid_len, mqtt.conack.val, mqtt.conflag.passwd, mqtt.conflag.qos, mqtt.conflag.reserved, mqtt.conflag.retain, mqtt.conflag.willflag, mqtt.dupflag, mqtt.kalive, mqtt.len, mqtt.msgtype, mqtt.qos, mqtt.retain, mqtt.topic_len, mqtt.ver, mqtt.willmsg_len, ip.proto, ip.ttl, label, tcp.flags.ack , tcp.flags.fin ]\n",
              "Index: []"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_ICU.loc[df_ICU['frame.time_delta'] == '0x00000012']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rd1Iv4Uaqkyo"
      },
      "outputs": [],
      "source": [
        "col = ['tcp.flags', 'tcp.checksum', 'mqtt.hdrflags', 'tcp.flags.ack', 'tcp.flags.fin']\n",
        "df_ICU= df_ICU.drop(columns = col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "HlAbES8C2dMN",
        "outputId": "c052e343-60f6-4cd3-d62b-2929e0a53be1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-afb9b87c-577b-4976-af79-37200bd08860\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>frame.time_delta</th>\n",
              "      <th>frame.time_relative</th>\n",
              "      <th>frame.len</th>\n",
              "      <th>tcp.flags</th>\n",
              "      <th>tcp.time_delta</th>\n",
              "      <th>tcp.len</th>\n",
              "      <th>tcp.ack</th>\n",
              "      <th>tcp.connection.fin</th>\n",
              "      <th>tcp.connection.rst</th>\n",
              "      <th>tcp.connection.sack</th>\n",
              "      <th>tcp.connection.syn</th>\n",
              "      <th>tcp.flags.push</th>\n",
              "      <th>tcp.flags.reset</th>\n",
              "      <th>tcp.flags.syn</th>\n",
              "      <th>tcp.flags.urg</th>\n",
              "      <th>tcp.hdr_len</th>\n",
              "      <th>tcp.pdu.size</th>\n",
              "      <th>tcp.window_size_value</th>\n",
              "      <th>mqtt.clientid_len</th>\n",
              "      <th>mqtt.conack.val</th>\n",
              "      <th>mqtt.conflag.passwd</th>\n",
              "      <th>mqtt.conflag.qos</th>\n",
              "      <th>mqtt.conflag.reserved</th>\n",
              "      <th>mqtt.conflag.retain</th>\n",
              "      <th>mqtt.conflag.willflag</th>\n",
              "      <th>mqtt.dupflag</th>\n",
              "      <th>mqtt.kalive</th>\n",
              "      <th>mqtt.len</th>\n",
              "      <th>mqtt.msgtype</th>\n",
              "      <th>mqtt.qos</th>\n",
              "      <th>mqtt.retain</th>\n",
              "      <th>mqtt.topic_len</th>\n",
              "      <th>mqtt.ver</th>\n",
              "      <th>mqtt.willmsg_len</th>\n",
              "      <th>ip.proto</th>\n",
              "      <th>ip.ttl</th>\n",
              "      <th>label</th>\n",
              "      <th>tcp.flags.ack</th>\n",
              "      <th>tcp.flags.fin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>106364</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>124.501195</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0x00000011</td>\n",
              "      <td>0.000387</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>513.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>42451</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>4.103763</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>8.0</td>\n",
              "      <td>29055.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>513.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>92699</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>55.687269</td>\n",
              "      <td>1514.0</td>\n",
              "      <td>0x00000010</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>1460.0</td>\n",
              "      <td>20765.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>166.0</td>\n",
              "      <td>4094.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>87923</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>51.196503</td>\n",
              "      <td>1514.0</td>\n",
              "      <td>0x00000010</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>1460.0</td>\n",
              "      <td>25001.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>4094.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>169.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25956</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>949.246403</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3872.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>512.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afb9b87c-577b-4976-af79-37200bd08860')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-afb9b87c-577b-4976-af79-37200bd08860 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-afb9b87c-577b-4976-af79-37200bd08860');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  frame.time_delta  ...  tcp.flags.ack   tcp.flags.fin \n",
              "0      106364          0.000002  ...             1.0             1.0\n",
              "1       42451          0.000001  ...             1.0             0.0\n",
              "2       92699          0.000067  ...             1.0             0.0\n",
              "3       87923          0.000082  ...             1.0             0.0\n",
              "4       25956          0.000011  ...             1.0             0.0\n",
              "\n",
              "[5 rows x 40 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_ICU.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyZgDkkP2kPo"
      },
      "outputs": [],
      "source": [
        "df_ICU.loc[df_ICU['tcp.checksum'] == '0x00000012']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K484mi9zqzW4",
        "outputId": "81833300-5d19-4302-e706-e03ccb9db974"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(111882, 40)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_ICU.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzXY23F0LFi4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "for i, df in enumerate(np.array_split(df_ICU, 5)):\n",
        "    df.to_csv('/content/drive/MyDrive/ICU/'+f\"ICU-Env{i+1}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "is-DyOfDMEMd"
      },
      "outputs": [],
      "source": [
        "ICU1 = pd.read_csv('/content/drive/MyDrive/ICU/ICU-Env1.csv')\n",
        "ICU1_shuffled = ICU1.sample(frac=1, random_state = 13).reset_index(drop = True)\n",
        "\n",
        "ICU2 = pd.read_csv('/content/drive/MyDrive/ICU/ICU-Env2.csv')\n",
        "ICU2_shuffled = ICU2.sample(frac=1, random_state = 13).reset_index(drop = True)\n",
        "\n",
        "ICU3 = pd.read_csv('/content/drive/MyDrive/ICU/ICU-Env3.csv')\n",
        "ICU3_shuffled = ICU3.sample(frac=1, random_state = 13).reset_index(drop = True)\n",
        "\n",
        "ICU4 = pd.read_csv('/content/drive/MyDrive/ICU/ICU-Env4.csv')\n",
        "ICU4_shuffled =ICU4.sample(frac=1, random_state = 13).reset_index(drop = True)\n",
        "\n",
        "ICU5 = pd.read_csv('/content/drive/MyDrive/ICU/ICU-Env5.csv')\n",
        "ICU5_shuffled = ICU5.sample(frac=1, random_state = 13).reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46APAmtrRJO0",
        "outputId": "de5a803d-f1d2-4819-86f9-b1269bf0ea89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    16081\n",
              "0     6295\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "ICU5_shuffled.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riqABLJjNxMz"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "#BATCH_SIZE = 512\n",
        "BATCH_SIZE = 1024 #ECU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfsXEKbhKsb1"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def make_tf_dataset(dataframe1, batch_size=None):\n",
        "    \n",
        "    dataset = dataframe1.drop(['Unnamed: 0'], axis=1)\n",
        "    count_ICU_0, count_ICU_1 = dataset.label.value_counts()\n",
        "\n",
        "    df_ICU_0 = dataset[dataset['label'] == 0]\n",
        "    df_ICU_1 = dataset[dataset['label'] == 1]\n",
        "\n",
        "    df_ICU_0_under = df_ICU_0.sample(count_ICU_1)\n",
        "    df_ICU_under = pd.concat([df_ICU_0_under, df_ICU_1], axis = 0)\n",
        "    y = df_ICU_under.pop('label')\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((df_ICU_under.values, y.to_frame().values))\n",
        "    dataset = dataset.shuffle(4048, seed=SEED) #2048\n",
        "    if batch_size:\n",
        "        dataset = dataset.batch(batch_size)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jCNprvEKz6E"
      },
      "outputs": [],
      "source": [
        "#########################################ECU#######################################################\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "train_data, val_data = [], []\n",
        "\n",
        "for client_data in [ICU1_shuffled, ICU2_shuffled, ICU3_shuffled, ICU4_shuffled, ICU5_shuffled]:\n",
        "                     \n",
        "                   \n",
        "    train_df, val_df = train_test_split(client_data, test_size=0.2, random_state=1337)\n",
        "\n",
        "    # Scaling (Standardization actually hurts performance) \n",
        "    encoder = LabelEncoder()\n",
        "    scaler = StandardScaler() \n",
        "    train_features = scaler.fit_transform(train_df.drop(['label'], axis=1))\n",
        "    val_features = scaler.transform(val_df.drop(['label'], axis=1))\n",
        "  \n",
        "    #encoder = LabelEncoder()\n",
        "    #y1 = encoder.fit_transform(y)\n",
        "    #Y= pd.get_dummies(y1).values\n",
        "    train_df[train_df.columns.difference(['label'])] = train_features\n",
        "    val_df[val_df.columns.difference(['label'])] = val_features\n",
        "\n",
        "    # TF Datasets\n",
        "    train_data.append(make_tf_dataset(train_df, batch_size=BATCH_SIZE)) #negative_ratio=2\n",
        "    val_data.append(make_tf_dataset(val_df, batch_size=16))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCnMmO0M4128"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import CategoricalAccuracy, Precision, Recall, BinaryAccuracy\n",
        "def input_spec():\n",
        "    return (\n",
        "        tf.TensorSpec([None, 37], tf.float64),\n",
        "        tf.TensorSpec([None, 1], tf.int64)\n",
        "    )\n",
        "\n",
        "def model_fn():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(37,)),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "    ])\n",
        "\n",
        "    return tff.learning.from_keras_model(\n",
        "        model,\n",
        "        input_spec=input_spec(),\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.BinaryAccuracy(), Precision(), Recall()]\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5P_fmw25VSQ"
      },
      "outputs": [],
      "source": [
        "trainer = tff.learning.build_federated_averaging_process(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.05)#learning_rate=0.01\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "UsRuiCbw5aYa",
        "outputId": "bcb1049c-21d2-4b00-e00c-43064d6b42fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'( -> <model=<trainable=<float32[37,32],float32[32],float32[32,64],float32[64],float32[64,32],float32[32],float32[32,1],float32[1]>,non_trainable=<>>,optimizer_state=<int64,float32[37,32],float32[32],float32[32,64],float32[64],float32[64,32],float32[32],float32[32,1],float32[1],float32[37,32],float32[32],float32[32,64],float32[64],float32[64,32],float32[32],float32[32,1],float32[1]>,delta_aggregate_state=<value_sum_process=<>,weight_sum_process=<>>,model_broadcast_state=<>>@SERVER)'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "str(trainer.initialize.type_signature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXiMGPyS5cwx"
      },
      "outputs": [],
      "source": [
        "state = trainer.initialize()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "#state = trainer.initialize()\n",
        "train_hist = []\n",
        "for i in range(EPOCHS):\n",
        "    state, metrics = trainer.next(state, train_data)\n",
        "    train_hist.append(metrics)\n",
        "\n",
        "    print(f\"\\rRun {i+1}/{EPOCHS}\", end=\"\")\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cf0ovRzCIXeh",
        "outputId": "f99f7f38-34f6-439c-86f5-ce3099e1ff84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 50/50Training time: 3.361701965332031e-05\n",
            "Test time: 1.4781951904296875e-05\n",
            "\n",
            "TIME: 108.73073935508728seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Czq2Yly9Ij2_",
        "outputId": "9a21e049-189f-4ad3-faca-9c6a521538a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('binary_accuracy', 0.99960893), ('precision', 0.9994539), ('recall', 1.0), ('loss', 0.001371521), ('num_examples', 89502), ('num_batches', 90)]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_hist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IF00J49ItnA",
        "outputId": "48a54eaf-3b09-4b29-8f29-e16ab5c387d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.82564634),\n",
              "                            ('precision', 0.92851835),\n",
              "                            ('recall', 0.81946766),\n",
              "                            ('loss', 0.3522904),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9794306),\n",
              "                            ('precision', 0.98533404),\n",
              "                            ('recall', 0.98593396),\n",
              "                            ('loss', 0.083164014),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9951509),\n",
              "                            ('precision', 0.9978403),\n",
              "                            ('recall', 0.995379),\n",
              "                            ('loss', 0.015863238),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99573195),\n",
              "                            ('precision', 0.9979822),\n",
              "                            ('recall', 0.9960503),\n",
              "                            ('loss', 0.014921089),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9945811),\n",
              "                            ('precision', 0.99723107),\n",
              "                            ('recall', 0.99519163),\n",
              "                            ('loss', 0.017187074),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99547493),\n",
              "                            ('precision', 0.9972345),\n",
              "                            ('recall', 0.99644053),\n",
              "                            ('loss', 0.014248836),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9962347),\n",
              "                            ('precision', 0.9975481),\n",
              "                            ('recall', 0.99718994),\n",
              "                            ('loss', 0.012981623),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99720675),\n",
              "                            ('precision', 0.99804854),\n",
              "                            ('recall', 0.99804854),\n",
              "                            ('loss', 0.008309986),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9990727),\n",
              "                            ('precision', 0.99934435),\n",
              "                            ('recall', 0.9993599),\n",
              "                            ('loss', 0.003965745),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9992961),\n",
              "                            ('precision', 0.9994225),\n",
              "                            ('recall', 0.9995941),\n",
              "                            ('loss', 0.0030827043),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9994302),\n",
              "                            ('precision', 0.99948496),\n",
              "                            ('recall', 0.99971896),\n",
              "                            ('loss', 0.0022580782),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9994749),\n",
              "                            ('precision', 0.9994538),\n",
              "                            ('recall', 0.99981266),\n",
              "                            ('loss', 0.0024195125),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99954194),\n",
              "                            ('precision', 0.99945384),\n",
              "                            ('recall', 0.9999063),\n",
              "                            ('loss', 0.0021524339),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.002340733),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.002052683),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9994749),\n",
              "                            ('precision', 0.9994538),\n",
              "                            ('recall', 0.99981266),\n",
              "                            ('loss', 0.0023442367),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.999486),\n",
              "                            ('precision', 0.9994538),\n",
              "                            ('recall', 0.9998283),\n",
              "                            ('loss', 0.004099036),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9995978),\n",
              "                            ('precision', 0.9994383),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0021929028),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0019110056),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0018330913),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0017411802),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.00153661),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0014295971),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0014647065),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9995978),\n",
              "                            ('precision', 0.9994383),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0012995106),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.001550847),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0014078919),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0013816281),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99956423),\n",
              "                            ('precision', 0.99946946),\n",
              "                            ('recall', 0.9999219),\n",
              "                            ('loss', 0.0017285795),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0013432878),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0013399541),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0013950064),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.001574279),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0014317593),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0014176012),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.001543543),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0016876225),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0015276727),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0014874004),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.001555202),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0013857975),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0015794814),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0015273879),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.001628943),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0016090695),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0015573783),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0013822755),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.001695213),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0014024634),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99960893),\n",
              "                            ('precision', 0.9994539),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.001371521),\n",
              "                            ('num_examples', 89502),\n",
              "                            ('num_batches', 90)]))])]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = tff.learning.build_federated_evaluation(model_fn)"
      ],
      "metadata": {
        "id": "OSEtkkCBIdNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "federated_metrics = evaluator(state.model, val_data)\n",
        "federated_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FJ8kV-jIgkm",
        "outputId": "c768a92e-beb1-4e2f-a57c-a71489c2abf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('eval',\n",
              "              OrderedDict([('binary_accuracy', 0.9996872),\n",
              "                           ('precision', 0.9995646),\n",
              "                           ('recall', 1.0),\n",
              "                           ('loss', 0.0019161723),\n",
              "                           ('num_examples', 22380),\n",
              "                           ('num_batches', 1400)]))])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2g9tqlFY6FrE"
      },
      "outputs": [],
      "source": [
        "evaluator = tff.learning.build_federated_evaluation(model_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGBO9fWJ6Jqn",
        "outputId": "e865ddc6-334d-4f4a-b0d4-d3c636166ae7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('eval',\n",
              "              OrderedDict([('binary_accuracy', 0.9996872),\n",
              "                           ('precision', 0.9995646),\n",
              "                           ('recall', 1.0),\n",
              "                           ('loss', 0.0021721823),\n",
              "                           ('num_examples', 22380),\n",
              "                           ('num_batches', 1400)]))])"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "federated_metrics = evaluator(state.model, val_data)\n",
        "federated_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eIphgncAOed"
      },
      "source": [
        "**ICU-ENV centralized**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pkMNtrBAZpu",
        "outputId": "dd2a52ba-d958-4529-f3a9-a0139f6b1a67"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(111882, 44)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df_ICU_ENV = pd.read_csv('/content/drive/MyDrive/ICU/clean_ICU.csv')\n",
        "df_ICU_ENV.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "_TnT94sFCWYC",
        "outputId": "d7456554-cd75-43b5-ce44-2e4b0e99d413"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-93211b1a-3a39-46db-aba1-58c29c5e9205\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>frame.time_delta</th>\n",
              "      <th>frame.time_relative</th>\n",
              "      <th>frame.len</th>\n",
              "      <th>tcp.flags</th>\n",
              "      <th>tcp.time_delta</th>\n",
              "      <th>tcp.len</th>\n",
              "      <th>tcp.ack</th>\n",
              "      <th>tcp.connection.fin</th>\n",
              "      <th>tcp.connection.rst</th>\n",
              "      <th>...</th>\n",
              "      <th>mqtt.qos</th>\n",
              "      <th>mqtt.retain</th>\n",
              "      <th>mqtt.topic_len</th>\n",
              "      <th>mqtt.ver</th>\n",
              "      <th>mqtt.willmsg_len</th>\n",
              "      <th>ip.proto</th>\n",
              "      <th>ip.ttl</th>\n",
              "      <th>label</th>\n",
              "      <th>tcp.flags.ack</th>\n",
              "      <th>tcp.flags.fin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>105.0</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>4.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>0.000096</td>\n",
              "      <td>105.0</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>4.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000132</td>\n",
              "      <td>105.0</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  44 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93211b1a-3a39-46db-aba1-58c29c5e9205')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-93211b1a-3a39-46db-aba1-58c29c5e9205 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-93211b1a-3a39-46db-aba1-58c29c5e9205');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  frame.time_delta  frame.time_relative  frame.len   tcp.flags  \\\n",
              "0           0          0.000000             0.000000      105.0  0x00000018   \n",
              "1           1          0.000053             0.000053       72.0  0x00000018   \n",
              "2           2          0.000043             0.000096      105.0  0x00000018   \n",
              "3           3          0.000020             0.000116       72.0  0x00000018   \n",
              "4           4          0.000016             0.000132      105.0  0x00000018   \n",
              "\n",
              "   tcp.time_delta  tcp.len  tcp.ack  tcp.connection.fin  tcp.connection.rst  \\\n",
              "0        0.000000     37.0      1.0                 0.0                 0.0   \n",
              "1        0.000053      4.0     38.0                 0.0                 0.0   \n",
              "2        0.000000     37.0      1.0                 0.0                 0.0   \n",
              "3        0.000020      4.0     38.0                 0.0                 0.0   \n",
              "4        0.000000     37.0      1.0                 0.0                 0.0   \n",
              "\n",
              "   ...  mqtt.qos  mqtt.retain  mqtt.topic_len  mqtt.ver  mqtt.willmsg_len  \\\n",
              "0  ...       0.0          0.0             0.0       4.0               0.0   \n",
              "1  ...       0.0          0.0             0.0       0.0               0.0   \n",
              "2  ...       0.0          0.0             0.0       4.0               0.0   \n",
              "3  ...       0.0          0.0             0.0       0.0               0.0   \n",
              "4  ...       0.0          0.0             0.0       4.0               0.0   \n",
              "\n",
              "   ip.proto  ip.ttl  label  tcp.flags.ack   tcp.flags.fin   \n",
              "0       6.0    64.0      0             1.0             0.0  \n",
              "1       6.0    64.0      0             1.0             0.0  \n",
              "2       6.0    64.0      0             1.0             0.0  \n",
              "3       6.0    64.0      0             1.0             0.0  \n",
              "4       6.0    64.0      0             1.0             0.0  \n",
              "\n",
              "[5 rows x 44 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df_ICU_ENV.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EM0wl5IiC8dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etP7KmpLAqh1",
        "outputId": "164c081a-57c6-4a25-97c4-5f401f80f64d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(111882, 38)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "col = ['Unnamed: 0','tcp.flags', 'tcp.checksum', 'mqtt.hdrflags', 'tcp.flags.ack', 'tcp.flags.fin']\n",
        "df_ICU_ENV = df_ICU_ENV.drop(columns=col, axis=1)\n",
        "df_ICU_ENV.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#count_FL_0, count_FL_1 = df_ICU_ENV.label.value_counts()\n"
      ],
      "metadata": {
        "id": "CjBGTdMh_idy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_FL_0 = df_ICU_ENV[df_ICU_ENV['label'] == 0]\n",
        "#df_FL_1 = df_ICU_ENV[df_ICU_ENV['label'] == 1]"
      ],
      "metadata": {
        "id": "aNqdkgFt_5Q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_FL_1_under = df_FL_1.sample(count_FL_0)\n",
        "#df_FL_under = pd.concat([df_FL_1_under, df_FL_0], axis = 0)\n",
        "#print('Random under-sampling:')\n",
        "#print(df_FL_under.label.value_counts())"
      ],
      "metadata": {
        "id": "mRaymYsbDmDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_ENV_1_under = df_ENV_1.sample(count_ENV_0)\n",
        "#df_ENV_under = pd.concat([df_ENV_1_under, df_ENV_0], axis = 0)\n",
        "#print('Random under-sampling:')\n",
        "#print(df_ENV_under.label.value_counts())"
      ],
      "metadata": {
        "id": "Jaiouj-vAWig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMwOEML8Axs6",
        "outputId": "00f787cd-b23b-464b-8bc9-e53d3f3cd998"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((111882, 37), (111882,))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "X = df_ICU_ENV.drop('label', axis = 1)\n",
        "y = df_ICU_ENV['label']\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uZ7iLDJKdDe"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import NearMiss\n",
        "# define the undersampling method\n",
        "undersample = NearMiss(version=1, n_neighbors=2)\n",
        "# transform the dataset\n",
        "X, y = undersample.fit_resample(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgXjrEIfCnh9"
      },
      "outputs": [],
      "source": [
        "#from sklearn.preprocessing import LabelEncoder\n",
        "#encoder = LabelEncoder()\n",
        "#y1 = encoder.fit_transform(y)\n",
        "#Y= pd.get_dummies(y1).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gt5dWFczCs-j"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1337)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-5wiONBEGIB"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaling = StandardScaler()\n",
        "X_train = scaling.fit_transform(X_train)\n",
        "X_test = scaling.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuoRaE0wLdnz"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM**"
      ],
      "metadata": {
        "id": "o-cELddJgp1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import time\n",
        "import time\n",
        "start = time.time()\n",
        "#from keras.optimizers import SGD\n",
        "#opt = SGD(lr=0.0001)\n",
        "#batch_size = 64\n",
        "\n",
        "# 1. define the network\n",
        "model = Sequential()\n",
        "model.add(LSTM(4,input_shape = X_train[0].shape))  \n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_train, y_train, epochs=50, batch_size = 20, validation_data=(X_test, y_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_test, y_preds_cnn))\n",
        "print(accuracy_score(y_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_preds_cnn))\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJBsOsk29oUk",
        "outputId": "a481261a-0151-418a-f6ab-4ad123f54260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2541/2541 [==============================] - 38s 14ms/step - loss: 0.5364 - accuracy: 0.6865 - val_loss: 0.6582 - val_accuracy: 0.5444\n",
            "Epoch 2/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.5496 - accuracy: 0.6815 - val_loss: 0.4636 - val_accuracy: 0.7716\n",
            "Epoch 3/50\n",
            "2541/2541 [==============================] - 37s 15ms/step - loss: 0.5370 - accuracy: 0.6992 - val_loss: 0.4570 - val_accuracy: 0.7716\n",
            "Epoch 4/50\n",
            "2541/2541 [==============================] - 36s 14ms/step - loss: 0.5378 - accuracy: 0.6950 - val_loss: 0.4564 - val_accuracy: 0.7716\n",
            "Epoch 5/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.5348 - accuracy: 0.7005 - val_loss: 0.4567 - val_accuracy: 0.7716\n",
            "Epoch 6/50\n",
            "2541/2541 [==============================] - 37s 15ms/step - loss: 0.4382 - accuracy: 0.7775 - val_loss: 0.0927 - val_accuracy: 0.9994\n",
            "Epoch 7/50\n",
            "2541/2541 [==============================] - 36s 14ms/step - loss: 0.4864 - accuracy: 0.7486 - val_loss: 0.4544 - val_accuracy: 0.7716\n",
            "Epoch 8/50\n",
            "2541/2541 [==============================] - 36s 14ms/step - loss: 0.4999 - accuracy: 0.7361 - val_loss: 0.4562 - val_accuracy: 0.7716\n",
            "Epoch 9/50\n",
            "2541/2541 [==============================] - 36s 14ms/step - loss: 0.5644 - accuracy: 0.6701 - val_loss: 0.6205 - val_accuracy: 0.5955\n",
            "Epoch 10/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.6372 - accuracy: 0.5750 - val_loss: 0.6081 - val_accuracy: 0.6504\n",
            "Epoch 11/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.5596 - accuracy: 0.6560 - val_loss: 0.4528 - val_accuracy: 0.7716\n",
            "Epoch 12/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.4418 - accuracy: 0.7324 - val_loss: 0.2059 - val_accuracy: 0.9821\n",
            "Epoch 13/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.3556 - accuracy: 0.7854 - val_loss: 0.6284 - val_accuracy: 0.5194\n",
            "Epoch 14/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.5255 - accuracy: 0.6925 - val_loss: 0.2304 - val_accuracy: 0.9547\n",
            "Epoch 15/50\n",
            "2541/2541 [==============================] - 36s 14ms/step - loss: 0.4768 - accuracy: 0.7170 - val_loss: 0.1937 - val_accuracy: 0.9965\n",
            "Epoch 16/50\n",
            "2541/2541 [==============================] - 36s 14ms/step - loss: 0.4933 - accuracy: 0.7645 - val_loss: 0.1719 - val_accuracy: 0.9850\n",
            "Epoch 17/50\n",
            "2541/2541 [==============================] - 36s 14ms/step - loss: 0.3988 - accuracy: 0.8225 - val_loss: 0.1418 - val_accuracy: 0.9850\n",
            "Epoch 18/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.3233 - accuracy: 0.8689 - val_loss: 0.1093 - val_accuracy: 0.9850\n",
            "Epoch 19/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.2789 - accuracy: 0.8977 - val_loss: 0.1259 - val_accuracy: 0.9850\n",
            "Epoch 20/50\n",
            "2541/2541 [==============================] - 36s 14ms/step - loss: 0.3115 - accuracy: 0.9003 - val_loss: 0.1113 - val_accuracy: 0.9850\n",
            "Epoch 21/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.2535 - accuracy: 0.9099 - val_loss: 0.1140 - val_accuracy: 0.9850\n",
            "Epoch 22/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.3333 - accuracy: 0.8633 - val_loss: 0.1797 - val_accuracy: 0.9689\n",
            "Epoch 23/50\n",
            "2541/2541 [==============================] - 36s 14ms/step - loss: 0.3314 - accuracy: 0.8619 - val_loss: 0.1298 - val_accuracy: 0.9850\n",
            "Epoch 24/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.2539 - accuracy: 0.9128 - val_loss: 0.1087 - val_accuracy: 0.9850\n",
            "Epoch 25/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.2554 - accuracy: 0.9092 - val_loss: 0.0956 - val_accuracy: 0.9850\n",
            "Epoch 26/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.2656 - accuracy: 0.9096 - val_loss: 0.0988 - val_accuracy: 0.9850\n",
            "Epoch 27/50\n",
            "2541/2541 [==============================] - 36s 14ms/step - loss: 0.2653 - accuracy: 0.9092 - val_loss: 0.1029 - val_accuracy: 0.9850\n",
            "Epoch 28/50\n",
            "2541/2541 [==============================] - 34s 14ms/step - loss: 0.2508 - accuracy: 0.9126 - val_loss: 0.0724 - val_accuracy: 0.9850\n",
            "Epoch 29/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.2138 - accuracy: 0.9328 - val_loss: 0.0603 - val_accuracy: 0.9996\n",
            "Epoch 30/50\n",
            "2541/2541 [==============================] - 36s 14ms/step - loss: 0.1993 - accuracy: 0.9378 - val_loss: 0.0773 - val_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.1663 - accuracy: 0.9514 - val_loss: 0.0424 - val_accuracy: 0.9864\n",
            "Epoch 32/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.1688 - accuracy: 0.9503 - val_loss: 0.0879 - val_accuracy: 0.9850\n",
            "Epoch 33/50\n",
            "2541/2541 [==============================] - 36s 14ms/step - loss: 0.2548 - accuracy: 0.9228 - val_loss: 0.4220 - val_accuracy: 0.8031\n",
            "Epoch 34/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.4751 - accuracy: 0.7707 - val_loss: 0.3849 - val_accuracy: 0.8380\n",
            "Epoch 35/50\n",
            "2541/2541 [==============================] - 36s 14ms/step - loss: 0.4403 - accuracy: 0.7855 - val_loss: 0.3775 - val_accuracy: 0.8380\n",
            "Epoch 36/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.3692 - accuracy: 0.8379 - val_loss: 0.1761 - val_accuracy: 0.9689\n",
            "Epoch 37/50\n",
            "2541/2541 [==============================] - 34s 14ms/step - loss: 0.3360 - accuracy: 0.8591 - val_loss: 0.0906 - val_accuracy: 0.9850\n",
            "Epoch 38/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.2222 - accuracy: 0.9273 - val_loss: 0.0870 - val_accuracy: 0.9850\n",
            "Epoch 39/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.2032 - accuracy: 0.9307 - val_loss: 0.0692 - val_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.2176 - accuracy: 0.9382 - val_loss: 0.0741 - val_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "2541/2541 [==============================] - 34s 13ms/step - loss: 0.5473 - accuracy: 0.9418 - val_loss: 0.0730 - val_accuracy: 0.9850\n",
            "Epoch 42/50\n",
            "2541/2541 [==============================] - 34s 13ms/step - loss: 0.1677 - accuracy: 0.9572 - val_loss: 0.0516 - val_accuracy: 0.9903\n",
            "Epoch 43/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.1557 - accuracy: 0.9575 - val_loss: 0.0512 - val_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.1719 - accuracy: 0.9504 - val_loss: 0.0751 - val_accuracy: 0.9850\n",
            "Epoch 45/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.1541 - accuracy: 0.9556 - val_loss: 0.0458 - val_accuracy: 0.9850\n",
            "Epoch 46/50\n",
            "2541/2541 [==============================] - 34s 13ms/step - loss: 0.1464 - accuracy: 0.9595 - val_loss: 0.0404 - val_accuracy: 0.9996\n",
            "Epoch 47/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.1521 - accuracy: 0.9572 - val_loss: 0.0666 - val_accuracy: 0.9994\n",
            "Epoch 48/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.1566 - accuracy: 0.9561 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.1618 - accuracy: 0.9558 - val_loss: 0.0303 - val_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "2541/2541 [==============================] - 35s 14ms/step - loss: 0.1457 - accuracy: 0.9594 - val_loss: 0.0431 - val_accuracy: 1.0000\n",
            "397/397 [==============================] - 2s 4ms/step - loss: 0.0431 - accuracy: 1.0000\n",
            "[0.04306909069418907, 1.0]\n",
            "[[6255    0]\n",
            " [   0 6449]]\n",
            "1.0\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      6255\n",
            "           1       1.00      1.00      1.00      6449\n",
            "\n",
            "    accuracy                           1.00     12704\n",
            "   macro avg       1.00      1.00      1.00     12704\n",
            "weighted avg       1.00      1.00      1.00     12704\n",
            "\n",
            "Training time: 4.291534423828125e-05\n",
            "Test time: 1.6689300537109375e-05\n",
            "\n",
            "TIME: 0.000701904296875seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6IShRTXHked"
      },
      "source": [
        "**DNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98-PeUhJEk7C",
        "outputId": "e907ebda-b961-45e8-d242-5ca946b72f93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2541/2541 [==============================] - 10s 3ms/step - loss: 0.2727 - accuracy: 0.9954 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
            "Epoch 2/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0061 - val_accuracy: 0.9985\n",
            "Epoch 3/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0064 - val_accuracy: 0.9985\n",
            "Epoch 4/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 5/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 6/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
            "Epoch 7/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0061 - val_accuracy: 0.9985\n",
            "Epoch 8/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0063 - val_accuracy: 0.9985\n",
            "Epoch 9/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
            "Epoch 10/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0062 - val_accuracy: 0.9985\n",
            "Epoch 11/50\n",
            "2541/2541 [==============================] - 7s 3ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0065 - val_accuracy: 0.9985\n",
            "Epoch 12/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0068 - val_accuracy: 0.9985\n",
            "Epoch 13/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
            "Epoch 14/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 15/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 16/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 17/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0062 - val_accuracy: 0.9985\n",
            "Epoch 18/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 19/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0067 - val_accuracy: 0.9985\n",
            "Epoch 20/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0061 - val_accuracy: 0.9985\n",
            "Epoch 21/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 22/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 23/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0062 - val_accuracy: 0.9985\n",
            "Epoch 24/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
            "Epoch 25/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 26/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
            "Epoch 27/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0062 - val_accuracy: 0.9985\n",
            "Epoch 28/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0064 - val_accuracy: 0.9985\n",
            "Epoch 29/50\n",
            "2541/2541 [==============================] - 7s 3ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 30/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
            "Epoch 31/50\n",
            "2541/2541 [==============================] - 8s 3ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
            "Epoch 32/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0061 - val_accuracy: 0.9985\n",
            "Epoch 33/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 34/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0063 - val_accuracy: 0.9985\n",
            "Epoch 35/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0063 - val_accuracy: 0.9985\n",
            "Epoch 36/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
            "Epoch 37/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
            "Epoch 38/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
            "Epoch 39/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
            "Epoch 40/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 41/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 42/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
            "Epoch 43/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0065 - val_accuracy: 0.9985\n",
            "Epoch 44/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
            "Epoch 45/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
            "Epoch 46/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0067 - val_accuracy: 0.9985\n",
            "Epoch 47/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 48/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
            "Epoch 49/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0064 - val_accuracy: 0.9985\n",
            "Epoch 50/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0061 - val_accuracy: 0.9985\n",
            "397/397 [==============================] - 1s 2ms/step - loss: 0.0061 - accuracy: 0.9985\n",
            "[0.006056053098291159, 0.9985044002532959]\n",
            "[[6236   19]\n",
            " [   0 6449]]\n",
            "0.9985044080604534\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      6255\n",
            "           1       1.00      1.00      1.00      6449\n",
            "\n",
            "    accuracy                           1.00     12704\n",
            "   macro avg       1.00      1.00      1.00     12704\n",
            "weighted avg       1.00      1.00      1.00     12704\n",
            "\n",
            "Training time: 4.410743713378906e-05\n",
            "Test time: 1.71661376953125e-05\n",
            "\n",
            "TIME: 0.0002980232238769531seconds\n"
          ]
        }
      ],
      "source": [
        "#from keras.layers import LSTM, SimpleRNN, GRU\n",
        "#from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "# 1. define the network\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(37,)),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer=Adam(lr=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_train, y_train, epochs=50, batch_size = 20, validation_data=(X_test, y_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_test, y_preds_cnn))\n",
        "print(accuracy_score(y_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_preds_cnn))\n",
        "\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51t_7QolWHxd"
      },
      "source": [
        "**CNN-LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZfzTYTHWLJb",
        "outputId": "9692d4b1-d96d-4d5a-bd0d-7b7c38b25b12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "2541/2541 [==============================] - 46s 17ms/step - loss: 0.6710 - accuracy: 0.5952 - val_loss: 0.6316 - val_accuracy: 0.5955\n",
            "Epoch 2/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.6863 - accuracy: 0.5631 - val_loss: 0.6305 - val_accuracy: 0.5076\n",
            "Epoch 3/50\n",
            "2541/2541 [==============================] - 33s 13ms/step - loss: 0.6873 - accuracy: 0.5598 - val_loss: 0.6705 - val_accuracy: 0.5076\n",
            "Epoch 4/50\n",
            "2541/2541 [==============================] - 33s 13ms/step - loss: 0.6914 - accuracy: 0.5616 - val_loss: 0.6323 - val_accuracy: 0.5076\n",
            "Epoch 5/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.6940 - accuracy: 0.5600 - val_loss: 0.7043 - val_accuracy: 0.5955\n",
            "Epoch 6/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.6957 - accuracy: 0.5611 - val_loss: 0.6320 - val_accuracy: 0.5955\n",
            "Epoch 7/50\n",
            "2541/2541 [==============================] - 33s 13ms/step - loss: 0.7226 - accuracy: 0.5316 - val_loss: 0.6665 - val_accuracy: 0.5444\n",
            "Epoch 8/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.7131 - accuracy: 0.5300 - val_loss: 0.6917 - val_accuracy: 0.5444\n",
            "Epoch 9/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.7181 - accuracy: 0.5269 - val_loss: 0.7013 - val_accuracy: 0.5444\n",
            "Epoch 10/50\n",
            "2541/2541 [==============================] - 33s 13ms/step - loss: 0.7226 - accuracy: 0.5301 - val_loss: 0.6723 - val_accuracy: 0.5076\n",
            "Epoch 11/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.7149 - accuracy: 0.5308 - val_loss: 0.6600 - val_accuracy: 0.5444\n",
            "Epoch 12/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.7215 - accuracy: 0.5271 - val_loss: 0.6716 - val_accuracy: 0.5444\n",
            "Epoch 13/50\n",
            "2541/2541 [==============================] - 33s 13ms/step - loss: 0.7186 - accuracy: 0.5258 - val_loss: 0.6873 - val_accuracy: 0.5076\n",
            "Epoch 14/50\n",
            "2541/2541 [==============================] - 33s 13ms/step - loss: 0.7198 - accuracy: 0.5264 - val_loss: 0.6884 - val_accuracy: 0.5076\n",
            "Epoch 15/50\n",
            "2541/2541 [==============================] - 33s 13ms/step - loss: 0.7241 - accuracy: 0.5312 - val_loss: 0.7192 - val_accuracy: 0.5076\n",
            "Epoch 16/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.7253 - accuracy: 0.5270 - val_loss: 0.6652 - val_accuracy: 0.5444\n",
            "Epoch 17/50\n",
            "2541/2541 [==============================] - 32s 12ms/step - loss: 0.7135 - accuracy: 0.5285 - val_loss: 0.6650 - val_accuracy: 0.5076\n",
            "Epoch 18/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.7191 - accuracy: 0.5311 - val_loss: 0.7390 - val_accuracy: 0.5076\n",
            "Epoch 19/50\n",
            "2541/2541 [==============================] - 33s 13ms/step - loss: 0.7171 - accuracy: 0.5305 - val_loss: 0.6842 - val_accuracy: 0.5076\n",
            "Epoch 20/50\n",
            "2541/2541 [==============================] - 33s 13ms/step - loss: 0.7214 - accuracy: 0.5287 - val_loss: 0.6632 - val_accuracy: 0.5076\n",
            "Epoch 21/50\n",
            "2541/2541 [==============================] - 33s 13ms/step - loss: 0.7254 - accuracy: 0.5256 - val_loss: 0.6768 - val_accuracy: 0.5444\n",
            "Epoch 22/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.7178 - accuracy: 0.5305 - val_loss: 0.7407 - val_accuracy: 0.5076\n",
            "Epoch 23/50\n",
            "2541/2541 [==============================] - 33s 13ms/step - loss: 0.7171 - accuracy: 0.5310 - val_loss: 0.6801 - val_accuracy: 0.5076\n",
            "Epoch 24/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.7226 - accuracy: 0.5297 - val_loss: 0.6628 - val_accuracy: 0.5444\n",
            "Epoch 25/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.7156 - accuracy: 0.5250 - val_loss: 0.7920 - val_accuracy: 0.5076\n",
            "Epoch 26/50\n",
            "2541/2541 [==============================] - 33s 13ms/step - loss: 0.7186 - accuracy: 0.5299 - val_loss: 0.6635 - val_accuracy: 0.5444\n",
            "Epoch 27/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.7264 - accuracy: 0.5289 - val_loss: 0.6739 - val_accuracy: 0.5076\n",
            "Epoch 28/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.7174 - accuracy: 0.5312 - val_loss: 0.7308 - val_accuracy: 0.5076\n",
            "Epoch 29/50\n",
            "2541/2541 [==============================] - 30s 12ms/step - loss: 0.7216 - accuracy: 0.5232 - val_loss: 0.6752 - val_accuracy: 0.5444\n",
            "Epoch 30/50\n",
            "2541/2541 [==============================] - 24s 10ms/step - loss: 0.7173 - accuracy: 0.5259 - val_loss: 0.6802 - val_accuracy: 0.5076\n",
            "Epoch 31/50\n",
            "2541/2541 [==============================] - 24s 9ms/step - loss: 0.7112 - accuracy: 0.5281 - val_loss: 0.8316 - val_accuracy: 0.5444\n",
            "Epoch 32/50\n",
            "2541/2541 [==============================] - 29s 11ms/step - loss: 0.7160 - accuracy: 0.5305 - val_loss: 0.7647 - val_accuracy: 0.5076\n",
            "Epoch 33/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.7201 - accuracy: 0.5303 - val_loss: 0.7400 - val_accuracy: 0.5076\n",
            "Epoch 34/50\n",
            "2541/2541 [==============================] - 29s 11ms/step - loss: 0.7172 - accuracy: 0.5275 - val_loss: 0.7108 - val_accuracy: 0.5444\n",
            "Epoch 35/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.7181 - accuracy: 0.5283 - val_loss: 0.6888 - val_accuracy: 0.5076\n",
            "Epoch 36/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.7223 - accuracy: 0.5290 - val_loss: 0.6774 - val_accuracy: 0.5076\n",
            "Epoch 37/50\n",
            "2541/2541 [==============================] - 25s 10ms/step - loss: 0.7217 - accuracy: 0.5284 - val_loss: 0.6639 - val_accuracy: 0.5076\n",
            "Epoch 38/50\n",
            "2541/2541 [==============================] - 24s 9ms/step - loss: 0.7161 - accuracy: 0.5233 - val_loss: 0.6814 - val_accuracy: 0.5444\n",
            "Epoch 39/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.7183 - accuracy: 0.5262 - val_loss: 0.7388 - val_accuracy: 0.5444\n",
            "Epoch 40/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.7157 - accuracy: 0.5287 - val_loss: 0.6604 - val_accuracy: 0.5444\n",
            "Epoch 41/50\n",
            "2541/2541 [==============================] - 33s 13ms/step - loss: 0.7182 - accuracy: 0.5257 - val_loss: 0.7850 - val_accuracy: 0.5076\n",
            "Epoch 42/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.7212 - accuracy: 0.5264 - val_loss: 0.6789 - val_accuracy: 0.5076\n",
            "Epoch 43/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.7197 - accuracy: 0.5304 - val_loss: 0.7753 - val_accuracy: 0.5444\n",
            "Epoch 44/50\n",
            "2541/2541 [==============================] - 31s 12ms/step - loss: 0.7158 - accuracy: 0.5286 - val_loss: 0.7163 - val_accuracy: 0.5444\n",
            "Epoch 45/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.7212 - accuracy: 0.5237 - val_loss: 0.7085 - val_accuracy: 0.5444\n",
            "Epoch 46/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.7184 - accuracy: 0.5279 - val_loss: 0.6656 - val_accuracy: 0.5444\n",
            "Epoch 47/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.7171 - accuracy: 0.5260 - val_loss: 0.7142 - val_accuracy: 0.5076\n",
            "Epoch 48/50\n",
            "2541/2541 [==============================] - 32s 13ms/step - loss: 0.7192 - accuracy: 0.5306 - val_loss: 0.7097 - val_accuracy: 0.5076\n",
            "Epoch 49/50\n",
            "2541/2541 [==============================] - 32s 12ms/step - loss: 0.7238 - accuracy: 0.5269 - val_loss: 0.6747 - val_accuracy: 0.5444\n",
            "Epoch 50/50\n",
            "2541/2541 [==============================] - 32s 12ms/step - loss: 0.7201 - accuracy: 0.5296 - val_loss: 0.6687 - val_accuracy: 0.5076\n",
            "397/397 [==============================] - 2s 4ms/step - loss: 0.6687 - accuracy: 0.5076\n",
            "[0.6686978936195374, 0.5076354146003723]\n",
            "[[   0 6255]\n",
            " [   0 6449]]\n",
            "0.5076353904282116\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      6255\n",
            "           1       0.51      1.00      0.67      6449\n",
            "\n",
            "    accuracy                           0.51     12704\n",
            "   macro avg       0.25      0.50      0.34     12704\n",
            "weighted avg       0.26      0.51      0.34     12704\n",
            "\n",
            "Training time: 4.315376281738281e-05\n",
            "Test time: 1.5735626220703125e-05\n",
            "\n",
            "TIME: 0.0006926059722900391seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "###############LSTM###################################\n",
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda\n",
        "\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, Dense, Dropout, Flatten, MaxPooling1D\n",
        "\n",
        "from keras.layers import LSTM, GRU, SimpleRNN\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "lstm_output_size = 20\n",
        "epochs = 10\n",
        "model = Sequential()\n",
        "model.add(Conv1D(32, 2, activation='relu', input_shape = X_train[0].shape))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(SimpleRNN(lstm_output_size))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "#model.add(Dense(1, activation='sigmoid'))\n",
        "    #])\n",
        "model.compile(optimizer=Adam(lr=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_train, y_train, epochs=50, batch_size = 20, validation_data=(X_test, y_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_test, y_preds_cnn))\n",
        "print(accuracy_score(y_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_preds_cnn))\n",
        "\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ0fCskRGW7Z"
      },
      "source": [
        "# **CENTRALIZED ICU-PAITIENT DATASET PREPROCESSING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3Xre7RgGgV5"
      },
      "outputs": [],
      "source": [
        "import numpy as np  \n",
        "import pandas as pd\n",
        "import os \n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISpFc6qgGjqp",
        "outputId": "cd4663b0-59ae-4f3d-fd4e-323e49a8c40d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (26,28,35) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Index(['frame.time_delta', 'frame.time_relative', 'frame.len', 'ip.src',\n",
              "       'ip.dst', 'tcp.srcport', 'tcp.dstport', 'tcp.flags', 'tcp.time_delta',\n",
              "       'tcp.len', 'tcp.ack', 'tcp.connection.fin', 'tcp.connection.rst',\n",
              "       'tcp.connection.sack', 'tcp.connection.syn', 'tcp.flags.ack',\n",
              "       'tcp.flags.fin', 'tcp.flags.push', 'tcp.flags.reset', 'tcp.flags.syn',\n",
              "       'tcp.flags.urg', 'tcp.hdr_len', 'tcp.payload', 'tcp.pdu.size',\n",
              "       'tcp.window_size_value', 'tcp.checksum', 'mqtt.clientid',\n",
              "       'mqtt.clientid_len', 'mqtt.conack.flags', 'mqtt.conack.val',\n",
              "       'mqtt.conflag.passwd', 'mqtt.conflag.qos', 'mqtt.conflag.reserved',\n",
              "       'mqtt.conflag.retain', 'mqtt.conflag.willflag', 'mqtt.conflags',\n",
              "       'mqtt.dupflag', 'mqtt.hdrflags', 'mqtt.kalive', 'mqtt.len', 'mqtt.msg',\n",
              "       'mqtt.msgtype', 'mqtt.qos', 'mqtt.retain', 'mqtt.topic',\n",
              "       'mqtt.topic_len', 'mqtt.ver', 'mqtt.willmsg_len', 'ip.proto', 'ip.ttl',\n",
              "       'class', 'label'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2 = pd.read_csv('/content/drive/MyDrive/ICU-Patient/patientMonitoring.csv')\n",
        "df2.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyqNO0SfGtq6",
        "outputId": "7e33be8d-8716-4312-fe42-8735c4dda85a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['patientMonitoring.csv', 'Attack.csv']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "path = '/content/drive/MyDrive/ICU-Patient/'\n",
        "csvs = os.listdir(path)\n",
        "csvs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gf-zuZ5zG1eI"
      },
      "outputs": [],
      "source": [
        "df2 = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFc05FDeG5sD",
        "outputId": "6cd78f20-582d-41fb-93c2-c0bfa0029e0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---- Reading patientMonitoring.csv ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (26,28,35) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "df.shape: (76810, 52)\n",
            "empty_cols: 0\n",
            "[]\n",
            "df2.shape: (76810, 52)\n",
            "---- Reading Attack.csv ----\n",
            "df.shape: (80126, 52)\n",
            "empty_cols: 0\n",
            "[]\n",
            "df2.shape: (156936, 52)\n"
          ]
        }
      ],
      "source": [
        "for csv in csvs:\n",
        "  print(f'---- Reading {csv} ----')\n",
        "  df = pd.read_csv(path+csv)\n",
        "  print(f'df.shape: {df.shape}')\n",
        "  empty_cols = [col for col in df.columns if df[col].isnull().all()]\n",
        "  print(f'empty_cols: {len(empty_cols)}')\n",
        "  print(empty_cols)\n",
        "  df.fillna(0, inplace=True)\n",
        "  df2 = df2.append(df, ignore_index=True)\n",
        "  print(f'df2.shape: {df2.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "KUUROopLIL0e",
        "outputId": "2ed152c2-6dc0-4424-9217-3afdc724df05"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-95947d7f-3914-439c-b679-da24d4c8598d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frame.time_delta</th>\n",
              "      <th>frame.time_relative</th>\n",
              "      <th>frame.len</th>\n",
              "      <th>ip.src</th>\n",
              "      <th>ip.dst</th>\n",
              "      <th>tcp.srcport</th>\n",
              "      <th>tcp.dstport</th>\n",
              "      <th>tcp.flags</th>\n",
              "      <th>tcp.time_delta</th>\n",
              "      <th>tcp.len</th>\n",
              "      <th>...</th>\n",
              "      <th>mqtt.qos</th>\n",
              "      <th>mqtt.retain</th>\n",
              "      <th>mqtt.topic</th>\n",
              "      <th>mqtt.topic_len</th>\n",
              "      <th>mqtt.ver</th>\n",
              "      <th>mqtt.willmsg_len</th>\n",
              "      <th>ip.proto</th>\n",
              "      <th>ip.ttl</th>\n",
              "      <th>class</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>105</td>\n",
              "      <td>10.5.126.141</td>\n",
              "      <td>10.5.126.56</td>\n",
              "      <td>35161</td>\n",
              "      <td>1883</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>64</td>\n",
              "      <td>patientMonitoring</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000249</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>105</td>\n",
              "      <td>10.5.126.143</td>\n",
              "      <td>10.5.126.56</td>\n",
              "      <td>34237</td>\n",
              "      <td>1883</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>64</td>\n",
              "      <td>patientMonitoring</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000037</td>\n",
              "      <td>0.000286</td>\n",
              "      <td>105</td>\n",
              "      <td>10.5.126.145</td>\n",
              "      <td>10.5.126.56</td>\n",
              "      <td>46623</td>\n",
              "      <td>1883</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>64</td>\n",
              "      <td>patientMonitoring</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000320</td>\n",
              "      <td>105</td>\n",
              "      <td>10.5.126.147</td>\n",
              "      <td>10.5.126.56</td>\n",
              "      <td>45663</td>\n",
              "      <td>1883</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>64</td>\n",
              "      <td>patientMonitoring</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000337</td>\n",
              "      <td>105</td>\n",
              "      <td>10.5.126.141</td>\n",
              "      <td>10.5.126.56</td>\n",
              "      <td>38901</td>\n",
              "      <td>1883</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>64</td>\n",
              "      <td>patientMonitoring</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  52 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95947d7f-3914-439c-b679-da24d4c8598d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-95947d7f-3914-439c-b679-da24d4c8598d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-95947d7f-3914-439c-b679-da24d4c8598d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   frame.time_delta  frame.time_relative  frame.len        ip.src  \\\n",
              "0          0.000000             0.000000        105  10.5.126.141   \n",
              "1          0.000249             0.000249        105  10.5.126.143   \n",
              "2          0.000037             0.000286        105  10.5.126.145   \n",
              "3          0.000034             0.000320        105  10.5.126.147   \n",
              "4          0.000017             0.000337        105  10.5.126.141   \n",
              "\n",
              "        ip.dst  tcp.srcport  tcp.dstport   tcp.flags  tcp.time_delta  tcp.len  \\\n",
              "0  10.5.126.56        35161         1883  0x00000018             0.0       37   \n",
              "1  10.5.126.56        34237         1883  0x00000018             0.0       37   \n",
              "2  10.5.126.56        46623         1883  0x00000018             0.0       37   \n",
              "3  10.5.126.56        45663         1883  0x00000018             0.0       37   \n",
              "4  10.5.126.56        38901         1883  0x00000018             0.0       37   \n",
              "\n",
              "   ...  mqtt.qos  mqtt.retain  mqtt.topic  mqtt.topic_len  mqtt.ver  \\\n",
              "0  ...       0.0          0.0           0             0.0       4.0   \n",
              "1  ...       0.0          0.0           0             0.0       4.0   \n",
              "2  ...       0.0          0.0           0             0.0       4.0   \n",
              "3  ...       0.0          0.0           0             0.0       4.0   \n",
              "4  ...       0.0          0.0           0             0.0       4.0   \n",
              "\n",
              "   mqtt.willmsg_len  ip.proto  ip.ttl              class  label  \n",
              "0               0.0         6      64  patientMonitoring      0  \n",
              "1               0.0         6      64  patientMonitoring      0  \n",
              "2               0.0         6      64  patientMonitoring      0  \n",
              "3               0.0         6      64  patientMonitoring      0  \n",
              "4               0.0         6      64  patientMonitoring      0  \n",
              "\n",
              "[5 rows x 52 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TLtWfbrIghR"
      },
      "outputs": [],
      "source": [
        "feats = ['ip.src', 'ip.dst', 'tcp.srcport', 'tcp.dstport','mqtt.topic', 'mqtt.msg', 'tcp.payload','mqtt.clientid', 'mqtt.conflags', 'mqtt.conack.flags', 'class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0yp8I5BIkl1",
        "outputId": "933477af-f319-460c-ec8c-7bb3499f6f6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(156936, 41)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.drop(labels=feats, axis=1, inplace=True)\n",
        "df2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ttRxWlvIuk4",
        "outputId": "0cb18d58-8968-4bcc-fb98-5b3b65cd7129"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    80126\n",
              "0    76810\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqpiSO3yI1Vq",
        "outputId": "a4c98bf4-7767-48c5-b9ca-35bb9d0e2149"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "frame.time_delta         0\n",
              "frame.time_relative      0\n",
              "frame.len                0\n",
              "tcp.flags                0\n",
              "tcp.time_delta           0\n",
              "tcp.len                  0\n",
              "tcp.ack                  0\n",
              "tcp.connection.fin       0\n",
              "tcp.connection.rst       0\n",
              "tcp.connection.sack      0\n",
              "tcp.connection.syn       0\n",
              "tcp.flags.ack            0\n",
              "tcp.flags.fin            0\n",
              "tcp.flags.push           0\n",
              "tcp.flags.reset          0\n",
              "tcp.flags.syn            0\n",
              "tcp.flags.urg            0\n",
              "tcp.hdr_len              0\n",
              "tcp.pdu.size             0\n",
              "tcp.window_size_value    0\n",
              "tcp.checksum             0\n",
              "mqtt.clientid_len        0\n",
              "mqtt.conack.val          0\n",
              "mqtt.conflag.passwd      0\n",
              "mqtt.conflag.qos         0\n",
              "mqtt.conflag.reserved    0\n",
              "mqtt.conflag.retain      0\n",
              "mqtt.conflag.willflag    0\n",
              "mqtt.dupflag             0\n",
              "mqtt.hdrflags            0\n",
              "mqtt.kalive              0\n",
              "mqtt.len                 0\n",
              "mqtt.msgtype             0\n",
              "mqtt.qos                 0\n",
              "mqtt.retain              0\n",
              "mqtt.topic_len           0\n",
              "mqtt.ver                 0\n",
              "mqtt.willmsg_len         0\n",
              "ip.proto                 0\n",
              "ip.ttl                   0\n",
              "label                    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPIXON8jI7Ru",
        "outputId": "162b6933-0d84-4145-cc55-ca643426dc2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3, 41)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2[df2.duplicated()].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czUTH_-2JBm4"
      },
      "outputs": [],
      "source": [
        "df2 = df2.drop(df2[df2.duplicated()].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNk9OPjZJIGy",
        "outputId": "4fba16c5-6b17-4076-ce57-3998623d24bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0, 41)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2[df2.duplicated()].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYVgnupSJKWT",
        "outputId": "7f29f83e-2b8d-4202-a496-d33acd0a2d91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 156933 entries, 0 to 156935\n",
            "Data columns (total 41 columns):\n",
            " #   Column                 Non-Null Count   Dtype  \n",
            "---  ------                 --------------   -----  \n",
            " 0   frame.time_delta       156933 non-null  float64\n",
            " 1   frame.time_relative    156933 non-null  float64\n",
            " 2   frame.len              156933 non-null  int64  \n",
            " 3   tcp.flags              156933 non-null  object \n",
            " 4   tcp.time_delta         156933 non-null  float64\n",
            " 5   tcp.len                156933 non-null  int64  \n",
            " 6   tcp.ack                156933 non-null  int64  \n",
            " 7   tcp.connection.fin     156933 non-null  float64\n",
            " 8   tcp.connection.rst     156933 non-null  float64\n",
            " 9   tcp.connection.sack    156933 non-null  float64\n",
            " 10  tcp.connection.syn     156933 non-null  float64\n",
            " 11  tcp.flags.ack          156933 non-null  int64  \n",
            " 12  tcp.flags.fin          156933 non-null  int64  \n",
            " 13  tcp.flags.push         156933 non-null  int64  \n",
            " 14  tcp.flags.reset        156933 non-null  int64  \n",
            " 15  tcp.flags.syn          156933 non-null  int64  \n",
            " 16  tcp.flags.urg          156933 non-null  int64  \n",
            " 17  tcp.hdr_len            156933 non-null  int64  \n",
            " 18  tcp.pdu.size           156933 non-null  float64\n",
            " 19  tcp.window_size_value  156933 non-null  int64  \n",
            " 20  tcp.checksum           156933 non-null  object \n",
            " 21  mqtt.clientid_len      156933 non-null  float64\n",
            " 22  mqtt.conack.val        156933 non-null  float64\n",
            " 23  mqtt.conflag.passwd    156933 non-null  float64\n",
            " 24  mqtt.conflag.qos       156933 non-null  float64\n",
            " 25  mqtt.conflag.reserved  156933 non-null  float64\n",
            " 26  mqtt.conflag.retain    156933 non-null  float64\n",
            " 27  mqtt.conflag.willflag  156933 non-null  float64\n",
            " 28  mqtt.dupflag           156933 non-null  float64\n",
            " 29  mqtt.hdrflags          156933 non-null  object \n",
            " 30  mqtt.kalive            156933 non-null  float64\n",
            " 31  mqtt.len               156933 non-null  float64\n",
            " 32  mqtt.msgtype           156933 non-null  float64\n",
            " 33  mqtt.qos               156933 non-null  float64\n",
            " 34  mqtt.retain            156933 non-null  float64\n",
            " 35  mqtt.topic_len         156933 non-null  float64\n",
            " 36  mqtt.ver               156933 non-null  float64\n",
            " 37  mqtt.willmsg_len       156933 non-null  float64\n",
            " 38  ip.proto               156933 non-null  int64  \n",
            " 39  ip.ttl                 156933 non-null  int64  \n",
            " 40  label                  156933 non-null  int64  \n",
            "dtypes: float64(24), int64(14), object(3)\n",
            "memory usage: 50.3+ MB\n"
          ]
        }
      ],
      "source": [
        "df2.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv12ZCckJ-Q_",
        "outputId": "3c89bc57-c3f9-43ba-ccf2-e23956570b83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 156933 entries, 0 to 156935\n",
            "Data columns (total 43 columns):\n",
            " #   Column                 Non-Null Count   Dtype  \n",
            "---  ------                 --------------   -----  \n",
            " 0   frame.time_delta       156933 non-null  float64\n",
            " 1   frame.time_relative    156933 non-null  float64\n",
            " 2   frame.len              156933 non-null  float64\n",
            " 3   tcp.flags              156933 non-null  object \n",
            " 4   tcp.time_delta         156933 non-null  float64\n",
            " 5   tcp.len                156933 non-null  float64\n",
            " 6   tcp.ack                156933 non-null  float64\n",
            " 7   tcp.connection.fin     156933 non-null  float64\n",
            " 8   tcp.connection.rst     156933 non-null  float64\n",
            " 9   tcp.connection.sack    156933 non-null  float64\n",
            " 10  tcp.connection.syn     156933 non-null  float64\n",
            " 11  tcp.flags.ack          156933 non-null  int64  \n",
            " 12  tcp.flags.fin          156933 non-null  int64  \n",
            " 13  tcp.flags.push         156933 non-null  float64\n",
            " 14  tcp.flags.reset        156933 non-null  float64\n",
            " 15  tcp.flags.syn          156933 non-null  float64\n",
            " 16  tcp.flags.urg          156933 non-null  float64\n",
            " 17  tcp.hdr_len            156933 non-null  float64\n",
            " 18  tcp.pdu.size           156933 non-null  float64\n",
            " 19  tcp.window_size_value  156933 non-null  float64\n",
            " 20  tcp.checksum           156933 non-null  object \n",
            " 21  mqtt.clientid_len      156933 non-null  float64\n",
            " 22  mqtt.conack.val        156933 non-null  float64\n",
            " 23  mqtt.conflag.passwd    156933 non-null  float64\n",
            " 24  mqtt.conflag.qos       156933 non-null  float64\n",
            " 25  mqtt.conflag.reserved  156933 non-null  float64\n",
            " 26  mqtt.conflag.retain    156933 non-null  float64\n",
            " 27  mqtt.conflag.willflag  156933 non-null  float64\n",
            " 28  mqtt.dupflag           156933 non-null  float64\n",
            " 29  mqtt.hdrflags          156933 non-null  object \n",
            " 30  mqtt.kalive            156933 non-null  float64\n",
            " 31  mqtt.len               156933 non-null  float64\n",
            " 32  mqtt.msgtype           156933 non-null  float64\n",
            " 33  mqtt.qos               156933 non-null  float64\n",
            " 34  mqtt.retain            156933 non-null  float64\n",
            " 35  mqtt.topic_len         156933 non-null  float64\n",
            " 36  mqtt.ver               156933 non-null  float64\n",
            " 37  mqtt.willmsg_len       156933 non-null  float64\n",
            " 38  ip.proto               156933 non-null  float64\n",
            " 39  ip.ttl                 156933 non-null  float64\n",
            " 40  label                  156933 non-null  int64  \n",
            " 41  tcp.flags.ack          156933 non-null  float64\n",
            " 42  tcp.flags.fin          156933 non-null  float64\n",
            "dtypes: float64(37), int64(3), object(3)\n",
            "memory usage: 52.7+ MB\n"
          ]
        }
      ],
      "source": [
        "df2['frame.len'] = df2['frame.len'].astype(float)\n",
        "#df1['tcp.flags'] = df1['tcp.flags'].astype(float)\n",
        "df2['tcp.len'] = df2['tcp.len'].astype(float)\n",
        "df2['tcp.ack'] = df2['tcp.ack'].astype(float)\n",
        "df2['tcp.flags.ack '] = df2['tcp.flags.ack'].astype(float)\n",
        "df2['tcp.flags.fin '] = df2['tcp.flags.fin'].astype(float)\n",
        "df2['tcp.flags.push'] = df2['tcp.flags.push'].astype(float)\n",
        "df2['tcp.flags.reset'] = df2['tcp.flags.reset'].astype(float)\n",
        "df2['tcp.flags.syn'] = df2['tcp.flags.syn'].astype(float)\n",
        "df2['tcp.flags.urg'] = df2['tcp.flags.urg'].astype(float)\n",
        "df2['tcp.hdr_len'] = df2['tcp.hdr_len'].astype(float)\n",
        "df2['tcp.window_size_value'] = df2['tcp.window_size_value'].astype(float)\n",
        "#df1['tcp.checksum'] = df1['tcp.checksum'].astype(float)\n",
        "\n",
        "#df1['mqtt.hdrflags'] = df1['mqtt.hdrflags'].astype(float)\n",
        "df2['ip.proto'] = df2['ip.proto'].astype(float)\n",
        "df2['ip.ttl'] = df2['ip.ttl'].astype(float)\n",
        "\n",
        "df2.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vROX_rs4Kjos"
      },
      "outputs": [],
      "source": [
        "col = ['tcp.flags', 'tcp.checksum', 'mqtt.hdrflags', 'tcp.flags.ack', 'tcp.flags.fin']\n",
        "df2 = df2.drop(columns=col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJ70czFNKuAE"
      },
      "outputs": [],
      "source": [
        "df2.to_csv('/content/drive/MyDrive/ICU-Patient/clean_ICU-PAI.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1HUISTyLsMV"
      },
      "outputs": [],
      "source": [
        "df_ICU_PAI1 = pd.read_csv('/content/drive/MyDrive/ICU-Patient/clean_ICU-PAI.csv')\n",
        "df_ICU_PAI= df_ICU_PAI1.sample(frac=1, random_state = 13).reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzssUUH2L64w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "for i, df in enumerate(np.array_split(df_ICU_PAI, 5)):\n",
        "    df.to_csv('/content/drive/MyDrive/ICU-Patient/'+f\"ICU-Pai{i+1}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Federated ICU-Patient**"
      ],
      "metadata": {
        "id": "cjq7JjuUtC_f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nC5PQk_5MT1K"
      },
      "outputs": [],
      "source": [
        "ICU_Pai1 = pd.read_csv('/content/drive/MyDrive/ICU-Patient/ICU-Pai1.csv')\n",
        "ICU_shuffled_Pai1 = ICU_Pai1.sample(frac=1, random_state = 13).reset_index(drop = True)\n",
        "\n",
        "ICU_Pai2 = pd.read_csv('/content/drive/MyDrive/ICU-Patient/ICU-Pai2.csv')\n",
        "ICU_shuffled_Pai2 = ICU_Pai2.sample(frac=1, random_state = 13).reset_index(drop = True)\n",
        "\n",
        "ICU_Pai3 = pd.read_csv('/content/drive/MyDrive/ICU-Patient/ICU-Pai3.csv')\n",
        "ICU_shuffled_Pai3 = ICU_Pai3.sample(frac=1, random_state = 13).reset_index(drop = True)\n",
        "\n",
        "ICU_Pai4 = pd.read_csv('/content/drive/MyDrive/ICU-Patient/ICU-Pai4.csv')\n",
        "ICU_shuffled_Pai4 =ICU_Pai4.sample(frac=1, random_state = 13).reset_index(drop = True)\n",
        "\n",
        "ICU_Pai5 = pd.read_csv('/content/drive/MyDrive/ICU-Patient/ICU-Pai5.csv')\n",
        "ICU_shuffled_Pai5 = ICU_Pai5.sample(frac=1, random_state = 13).reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpEHMUKmNoog"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "#BATCH_SIZE = 512\n",
        "BATCH_SIZE = 1024 #ECU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7BiDHawNru6"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def make_tf_dataset(dataframe1, batch_size=None):\n",
        "    \n",
        "    dataset = dataframe1.drop(['Unnamed: 0'], axis=1)\n",
        "    count_ICU_0, count_ICU_1 = dataset.label.value_counts()\n",
        "\n",
        "    df_ICU_0 = dataset[dataset['label'] == 0]\n",
        "    df_ICU_1 = dataset[dataset['label'] == 1]\n",
        "\n",
        "    df_ICU_0_under = df_ICU_0.sample(count_ICU_1)\n",
        "    df_ICU_under = pd.concat([df_ICU_0_under, df_ICU_1], axis = 0)\n",
        "    y = df_ICU_under.pop('label')\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((df_ICU_under.values, y.to_frame().values))\n",
        "    dataset = dataset.shuffle(4048, seed=SEED) #2048\n",
        "    if batch_size:\n",
        "        dataset = dataset.batch(batch_size)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBHXNpvpNvtc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "train_data, val_data = [], []\n",
        "\n",
        "for client_data in [ICU_shuffled_Pai1, ICU_shuffled_Pai2, ICU_shuffled_Pai3, ICU_shuffled_Pai4, ICU_shuffled_Pai5]:\n",
        "                     \n",
        "                   \n",
        "    train_df, val_df = train_test_split(client_data, test_size=0.2, random_state=1337)\n",
        "\n",
        "    # Scaling (Standardization actually hurts performance) \n",
        "    encoder = LabelEncoder()\n",
        "    scaler = StandardScaler() \n",
        "    train_features = scaler.fit_transform(train_df.drop(['label'], axis=1))\n",
        "    val_features = scaler.transform(val_df.drop(['label'], axis=1))\n",
        "  \n",
        "    #encoder = LabelEncoder()\n",
        "    #y1 = encoder.fit_transform(y)\n",
        "    #Y= pd.get_dummies(y1).values\n",
        "    train_df[train_df.columns.difference(['label'])] = train_features\n",
        "    val_df[val_df.columns.difference(['label'])] = val_features\n",
        "\n",
        "    # TF Datasets\n",
        "    train_data.append(make_tf_dataset(train_df, batch_size=BATCH_SIZE)) #negative_ratio=2\n",
        "    val_data.append(make_tf_dataset(val_df, batch_size=16))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqWEl4TTPADJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import CategoricalAccuracy, Precision, Recall, BinaryAccuracy\n",
        "def input_spec():\n",
        "    return (\n",
        "        tf.TensorSpec([None, 37], tf.float64),\n",
        "        tf.TensorSpec([None, 1], tf.int64)\n",
        "    )\n",
        "\n",
        "def model_fn():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(37,)),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "    ])\n",
        "\n",
        "    return tff.learning.from_keras_model(\n",
        "        model,\n",
        "        input_spec=input_spec(),\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.BinaryAccuracy(), Precision(), Recall()]\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QF2QB-VPPEJ1"
      },
      "outputs": [],
      "source": [
        "trainer = tff.learning.build_federated_averaging_process(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.05)#learning_rate=0.01\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "JUzFX7TOPIKO",
        "outputId": "498c6469-e736-4dda-e4ac-cab0b06b2b37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'( -> <model=<trainable=<float32[37,32],float32[32],float32[32,64],float32[64],float32[64,32],float32[32],float32[32,1],float32[1]>,non_trainable=<>>,optimizer_state=<int64,float32[37,32],float32[32],float32[32,64],float32[64],float32[64,32],float32[32],float32[32,1],float32[1],float32[37,32],float32[32],float32[32,64],float32[64],float32[64,32],float32[32],float32[32,1],float32[1]>,delta_aggregate_state=<value_sum_process=<>,weight_sum_process=<>>,model_broadcast_state=<>>@SERVER)'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "str(trainer.initialize.type_signature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0JoMtXMPKn4"
      },
      "outputs": [],
      "source": [
        "state = trainer.initialize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m82QjxhIPPxY",
        "outputId": "cf22f6f6-6a1e-4273-988b-930520fa7205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 50/50Training time: 3.314018249511719e-05\n",
            "Test time: 1.4543533325195312e-05\n",
            "\n",
            "TIME: 128.60884046554565seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "#state = trainer.initialize()\n",
        "train_hist = []\n",
        "for i in range(EPOCHS):\n",
        "    state, metrics = trainer.next(state, train_data)\n",
        "    train_hist.append(metrics)\n",
        "\n",
        "    print(f\"\\rRun {i+1}/{EPOCHS}\", end=\"\")\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BXYXaVhr4-s",
        "outputId": "b2d92ffc-a477-449e-f4a1-2f7cf5825303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('binary_accuracy', 0.9980405), ('precision', 0.9997029), ('recall', 0.99646145), ('loss', 0.007047065), ('num_examples', 125543), ('num_batches', 125)]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_hist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDeydQrar9LH",
        "outputId": "7dcf51ba-2ee8-4822-fa8e-17a69c6dcb05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.7455374),\n",
              "                            ('precision', 0.909931),\n",
              "                            ('recall', 0.5571698),\n",
              "                            ('loss', 0.9037049),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.95278907),\n",
              "                            ('precision', 0.98026925),\n",
              "                            ('recall', 0.9262521),\n",
              "                            ('loss', 0.21218374),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9905132),\n",
              "                            ('precision', 0.99838513),\n",
              "                            ('recall', 0.9830244),\n",
              "                            ('loss', 0.08794081),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9928949),\n",
              "                            ('precision', 0.9964216),\n",
              "                            ('recall', 0.9896494),\n",
              "                            ('loss', 0.03766592),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9942808),\n",
              "                            ('precision', 0.99658674),\n",
              "                            ('recall', 0.9922059),\n",
              "                            ('loss', 0.023907682),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9943844),\n",
              "                            ('precision', 0.99633884),\n",
              "                            ('recall', 0.99265796),\n",
              "                            ('loss', 0.022459371),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9918355),\n",
              "                            ('precision', 0.99080986),\n",
              "                            ('recall', 0.9932347),\n",
              "                            ('loss', 0.027408214),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99116635),\n",
              "                            ('precision', 0.992762),\n",
              "                            ('recall', 0.98993003),\n",
              "                            ('loss', 0.027833428),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9954438),\n",
              "                            ('precision', 0.9973715),\n",
              "                            ('recall', 0.99370235),\n",
              "                            ('loss', 0.014037331),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99735546),\n",
              "                            ('precision', 0.9995147),\n",
              "                            ('recall', 0.9953079),\n",
              "                            ('loss', 0.009924103),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9977856),\n",
              "                            ('precision', 0.99943703),\n",
              "                            ('recall', 0.9962276),\n",
              "                            ('loss', 0.008178852),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99798477),\n",
              "                            ('precision', 0.9995466),\n",
              "                            ('recall', 0.99650824),\n",
              "                            ('loss', 0.006655586),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99769),\n",
              "                            ('precision', 0.99948376),\n",
              "                            ('recall', 0.99599385),\n",
              "                            ('loss', 0.0070222183),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9980166),\n",
              "                            ('precision', 0.99940604),\n",
              "                            ('recall', 0.9967109),\n",
              "                            ('loss', 0.0054969382),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99832726),\n",
              "                            ('precision', 0.99950004),\n",
              "                            ('recall', 0.9972253),\n",
              "                            ('loss', 0.0049813846),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9980963),\n",
              "                            ('precision', 0.9993125),\n",
              "                            ('recall', 0.9969603),\n",
              "                            ('loss', 0.004698886),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9981998),\n",
              "                            ('precision', 0.9991723),\n",
              "                            ('recall', 0.99730325),\n",
              "                            ('loss', 0.004594282),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99823964),\n",
              "                            ('precision', 0.9992035),\n",
              "                            ('recall', 0.99735),\n",
              "                            ('loss', 0.0039597275),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9986698),\n",
              "                            ('precision', 0.9990796),\n",
              "                            ('recall', 0.99831647),\n",
              "                            ('loss', 0.0037985954),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9990203),\n",
              "                            ('precision', 0.99914247),\n",
              "                            ('recall', 0.99894),\n",
              "                            ('loss', 0.0033654063),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9991079),\n",
              "                            ('precision', 0.99908036),\n",
              "                            ('recall', 0.9991738),\n",
              "                            ('loss', 0.0031034772),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99925923),\n",
              "                            ('precision', 0.9990029),\n",
              "                            ('recall', 0.99954796),\n",
              "                            ('loss', 0.0036407402),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9993787),\n",
              "                            ('precision', 0.9989876),\n",
              "                            ('recall', 0.99979734),\n",
              "                            ('loss', 0.0039082184),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99937075),\n",
              "                            ('precision', 0.9989565),\n",
              "                            ('recall', 0.99981296),\n",
              "                            ('loss', 0.003964676),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9994345),\n",
              "                            ('precision', 0.9989566),\n",
              "                            ('recall', 0.99993765),\n",
              "                            ('loss', 0.0031229632),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9994584),\n",
              "                            ('precision', 0.9989567),\n",
              "                            ('recall', 0.9999844),\n",
              "                            ('loss', 0.002766094),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9994584),\n",
              "                            ('precision', 0.9989567),\n",
              "                            ('recall', 0.9999844),\n",
              "                            ('loss', 0.0030039246),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9994584),\n",
              "                            ('precision', 0.9989567),\n",
              "                            ('recall', 0.9999844),\n",
              "                            ('loss', 0.00315974),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9994584),\n",
              "                            ('precision', 0.9989567),\n",
              "                            ('recall', 0.9999844),\n",
              "                            ('loss', 0.003006452),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99937075),\n",
              "                            ('precision', 0.99898756),\n",
              "                            ('recall', 0.9997818),\n",
              "                            ('loss', 0.002941638),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99928313),\n",
              "                            ('precision', 0.99917406),\n",
              "                            ('recall', 0.99942327),\n",
              "                            ('loss', 0.0032506147),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9990521),\n",
              "                            ('precision', 0.9992048),\n",
              "                            ('recall', 0.99894),\n",
              "                            ('loss', 0.0042731804),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99920344),\n",
              "                            ('precision', 0.9990961),\n",
              "                            ('recall', 0.9993453),\n",
              "                            ('loss', 0.003387396),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99933887),\n",
              "                            ('precision', 0.99903417),\n",
              "                            ('recall', 0.99967265),\n",
              "                            ('loss', 0.0024879805),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99929905),\n",
              "                            ('precision', 0.99898744),\n",
              "                            ('recall', 0.9996415),\n",
              "                            ('loss', 0.0032597485),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9994504),\n",
              "                            ('precision', 0.9989566),\n",
              "                            ('recall', 0.9999688),\n",
              "                            ('loss', 0.0022101933),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9994185),\n",
              "                            ('precision', 0.99895656),\n",
              "                            ('recall', 0.9999065),\n",
              "                            ('loss', 0.0022319986),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99934685),\n",
              "                            ('precision', 0.99895644),\n",
              "                            ('recall', 0.9997662),\n",
              "                            ('loss', 0.002669691),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9994663),\n",
              "                            ('precision', 0.9989567),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.0024276841),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9993787),\n",
              "                            ('precision', 0.9990342),\n",
              "                            ('recall', 0.9997506),\n",
              "                            ('loss', 0.002477518),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99931496),\n",
              "                            ('precision', 0.9990808),\n",
              "                            ('recall', 0.99957913),\n",
              "                            ('loss', 0.0028177425),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9993787),\n",
              "                            ('precision', 0.99897206),\n",
              "                            ('recall', 0.99981296),\n",
              "                            ('loss', 0.0021685776),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99938667),\n",
              "                            ('precision', 0.99897206),\n",
              "                            ('recall', 0.9998285),\n",
              "                            ('loss', 0.0025002623),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9989406),\n",
              "                            ('precision', 0.99934477),\n",
              "                            ('recall', 0.99858147),\n",
              "                            ('loss', 0.0036351415),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9985105),\n",
              "                            ('precision', 0.999391),\n",
              "                            ('recall', 0.99769294),\n",
              "                            ('loss', 0.00449936),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99736345),\n",
              "                            ('precision', 0.9984691),\n",
              "                            ('recall', 0.99636793),\n",
              "                            ('loss', 0.01166241),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9554097),\n",
              "                            ('precision', 0.9197408),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.09495608),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.96566117),\n",
              "                            ('precision', 0.93703073),\n",
              "                            ('recall', 1.0),\n",
              "                            ('loss', 0.050324727),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.99740326),\n",
              "                            ('precision', 0.99956167),\n",
              "                            ('recall', 0.9953547),\n",
              "                            ('loss', 0.007965069),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))]),\n",
              " OrderedDict([('broadcast', ()),\n",
              "              ('aggregation',\n",
              "               OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "              ('train',\n",
              "               OrderedDict([('binary_accuracy', 0.9980405),\n",
              "                            ('precision', 0.9997029),\n",
              "                            ('recall', 0.99646145),\n",
              "                            ('loss', 0.007047065),\n",
              "                            ('num_examples', 125543),\n",
              "                            ('num_batches', 125)]))])]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhXS4_TpPSYW"
      },
      "outputs": [],
      "source": [
        "evaluator = tff.learning.build_federated_evaluation(model_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STdyoNgvPWVd",
        "outputId": "c9882ebc-3fc0-4d57-a110-483ebaa0146f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('eval',\n",
              "              OrderedDict([('binary_accuracy', 0.99958587),\n",
              "                           ('precision', 0.9991868),\n",
              "                           ('recall', 1.0),\n",
              "                           ('loss', 0.002661492),\n",
              "                           ('num_examples', 31390),\n",
              "                           ('num_batches', 1965)]))])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "federated_metrics = evaluator(state.model, val_data)\n",
        "federated_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9o50lmOO_EId"
      },
      "source": [
        "# **Centralized ICU-Patient**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIWNaAKP_T8X",
        "outputId": "c7aff505-8517-46cf-db74-a97a77211e8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156933, 39)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df_ICU_PAI = pd.read_csv('/content/drive/MyDrive/ICU-Patient/clean_ICU-PAI.csv')\n",
        "df_ICU_PAI.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "_S7azDwC_soc",
        "outputId": "3b883452-14ab-48e3-ed2f-e14e2a9ab132"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-90e76739-346f-45bf-bd27-237ff6bfd320\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>frame.time_delta</th>\n",
              "      <th>frame.time_relative</th>\n",
              "      <th>frame.len</th>\n",
              "      <th>tcp.time_delta</th>\n",
              "      <th>tcp.len</th>\n",
              "      <th>tcp.ack</th>\n",
              "      <th>tcp.connection.fin</th>\n",
              "      <th>tcp.connection.rst</th>\n",
              "      <th>tcp.connection.sack</th>\n",
              "      <th>...</th>\n",
              "      <th>mqtt.qos</th>\n",
              "      <th>mqtt.retain</th>\n",
              "      <th>mqtt.topic_len</th>\n",
              "      <th>mqtt.ver</th>\n",
              "      <th>mqtt.willmsg_len</th>\n",
              "      <th>ip.proto</th>\n",
              "      <th>ip.ttl</th>\n",
              "      <th>label</th>\n",
              "      <th>tcp.flags.ack</th>\n",
              "      <th>tcp.flags.fin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>105.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>105.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000037</td>\n",
              "      <td>0.000286</td>\n",
              "      <td>105.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000320</td>\n",
              "      <td>105.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000337</td>\n",
              "      <td>105.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  39 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90e76739-346f-45bf-bd27-237ff6bfd320')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90e76739-346f-45bf-bd27-237ff6bfd320 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90e76739-346f-45bf-bd27-237ff6bfd320');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  frame.time_delta  frame.time_relative  frame.len  \\\n",
              "0           0          0.000000             0.000000      105.0   \n",
              "1           1          0.000249             0.000249      105.0   \n",
              "2           2          0.000037             0.000286      105.0   \n",
              "3           3          0.000034             0.000320      105.0   \n",
              "4           4          0.000017             0.000337      105.0   \n",
              "\n",
              "   tcp.time_delta  tcp.len  tcp.ack  tcp.connection.fin  tcp.connection.rst  \\\n",
              "0             0.0     37.0      1.0                 0.0                 0.0   \n",
              "1             0.0     37.0      1.0                 0.0                 0.0   \n",
              "2             0.0     37.0      1.0                 0.0                 0.0   \n",
              "3             0.0     37.0      1.0                 0.0                 0.0   \n",
              "4             0.0     37.0      1.0                 0.0                 0.0   \n",
              "\n",
              "   tcp.connection.sack  ...  mqtt.qos  mqtt.retain  mqtt.topic_len  mqtt.ver  \\\n",
              "0                  0.0  ...       0.0          0.0             0.0       4.0   \n",
              "1                  0.0  ...       0.0          0.0             0.0       4.0   \n",
              "2                  0.0  ...       0.0          0.0             0.0       4.0   \n",
              "3                  0.0  ...       0.0          0.0             0.0       4.0   \n",
              "4                  0.0  ...       0.0          0.0             0.0       4.0   \n",
              "\n",
              "   mqtt.willmsg_len  ip.proto  ip.ttl  label  tcp.flags.ack   tcp.flags.fin   \n",
              "0               0.0       6.0    64.0      0             1.0             0.0  \n",
              "1               0.0       6.0    64.0      0             1.0             0.0  \n",
              "2               0.0       6.0    64.0      0             1.0             0.0  \n",
              "3               0.0       6.0    64.0      0             1.0             0.0  \n",
              "4               0.0       6.0    64.0      0             1.0             0.0  \n",
              "\n",
              "[5 rows x 39 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_ICU_PAI.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icEFOyHx_0io",
        "outputId": "457f7ff4-c2cd-43bd-d3e7-c98cd63045a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156933, 38)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "col = ['Unnamed: 0']\n",
        "df_ICU_PAI = df_ICU_PAI.drop(columns=col, axis=1)\n",
        "df_ICU_PAI.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzfqFYo0AFYq",
        "outputId": "51948f89-d1e6-49ff-88d2-30822d03265f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((156933, 37), (156933,))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "X = df_ICU_PAI.drop('label', axis = 1)\n",
        "y = df_ICU_PAI['label']\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import NearMiss\n",
        "# define the undersampling method\n",
        "undersample = NearMiss(version=1, n_neighbors=2)\n",
        "# transform the dataset\n",
        "X, y = undersample.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "WK8q4aZYu9CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Htr962y4ANTX"
      },
      "outputs": [],
      "source": [
        "#from sklearn.preprocessing import LabelEncoder\n",
        "#encoder = LabelEncoder()\n",
        "#y1 = encoder.fit_transform(y)\n",
        "#Y= pd.get_dummies(y1).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "402UwOY9ARmO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1337)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYQkQanjAVQ8"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaling = StandardScaler()\n",
        "X_train = scaling.fit_transform(X_train)\n",
        "X_test = scaling.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdI8xuoKAX-T"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0Bc6maNAZdx"
      },
      "source": [
        "**LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oxJVRR2AcSi",
        "outputId": "2e3f7bd6-e5c7-42ad-9411-0b9fd259160d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6145/6145 [==============================] - 96s 15ms/step - loss: 0.2393 - accuracy: 0.9053 - val_loss: 0.0733 - val_accuracy: 0.9925\n",
            "Epoch 2/50\n",
            "6145/6145 [==============================] - 91s 15ms/step - loss: 0.1240 - accuracy: 0.9569 - val_loss: 0.0452 - val_accuracy: 0.9931\n",
            "Epoch 3/50\n",
            "6145/6145 [==============================] - 83s 13ms/step - loss: 0.1394 - accuracy: 0.9527 - val_loss: 0.0606 - val_accuracy: 0.9850\n",
            "Epoch 4/50\n",
            "6145/6145 [==============================] - 83s 13ms/step - loss: 0.2262 - accuracy: 0.9176 - val_loss: 0.3159 - val_accuracy: 0.8828\n",
            "Epoch 5/50\n",
            "6145/6145 [==============================] - 88s 14ms/step - loss: 0.2150 - accuracy: 0.9165 - val_loss: 0.0717 - val_accuracy: 0.9870\n",
            "Epoch 6/50\n",
            "6145/6145 [==============================] - 84s 14ms/step - loss: 0.2073 - accuracy: 0.9259 - val_loss: 0.3273 - val_accuracy: 0.8828\n",
            "Epoch 7/50\n",
            "6145/6145 [==============================] - 84s 14ms/step - loss: 0.1974 - accuracy: 0.9378 - val_loss: 0.0660 - val_accuracy: 0.9925\n",
            "Epoch 8/50\n",
            "6145/6145 [==============================] - 85s 14ms/step - loss: 0.1763 - accuracy: 0.9366 - val_loss: 0.0903 - val_accuracy: 0.9870\n",
            "Epoch 9/50\n",
            "6145/6145 [==============================] - 82s 13ms/step - loss: 0.2239 - accuracy: 0.9078 - val_loss: 0.0100 - val_accuracy: 0.9990\n",
            "Epoch 10/50\n",
            "6145/6145 [==============================] - 84s 14ms/step - loss: 0.1266 - accuracy: 0.9406 - val_loss: 0.0132 - val_accuracy: 0.9977\n",
            "Epoch 11/50\n",
            "6145/6145 [==============================] - 85s 14ms/step - loss: 0.1396 - accuracy: 0.9382 - val_loss: 0.0039 - val_accuracy: 0.9990\n",
            "Epoch 12/50\n",
            "6145/6145 [==============================] - 84s 14ms/step - loss: 0.5268 - accuracy: 0.8956 - val_loss: 0.1048 - val_accuracy: 0.9574\n",
            "Epoch 13/50\n",
            "6145/6145 [==============================] - 84s 14ms/step - loss: 0.4728 - accuracy: 0.7743 - val_loss: 0.3148 - val_accuracy: 0.8294\n",
            "Epoch 14/50\n",
            "6145/6145 [==============================] - 84s 14ms/step - loss: 0.2996 - accuracy: 0.8554 - val_loss: 0.0611 - val_accuracy: 0.9695\n",
            "Epoch 15/50\n",
            "6145/6145 [==============================] - 84s 14ms/step - loss: 0.5343 - accuracy: 0.6931 - val_loss: 0.6416 - val_accuracy: 0.4939\n",
            "Epoch 16/50\n",
            "6145/6145 [==============================] - 84s 14ms/step - loss: 0.6438 - accuracy: 0.6029 - val_loss: 0.5039 - val_accuracy: 0.7959\n",
            "Epoch 17/50\n",
            "6145/6145 [==============================] - 83s 13ms/step - loss: 0.6067 - accuracy: 0.6478 - val_loss: 0.4979 - val_accuracy: 0.8302\n",
            "Epoch 18/50\n",
            "6145/6145 [==============================] - 83s 14ms/step - loss: 0.6572 - accuracy: 0.5770 - val_loss: 0.6193 - val_accuracy: 0.6590\n",
            "Epoch 19/50\n",
            "6145/6145 [==============================] - 82s 13ms/step - loss: 0.6199 - accuracy: 0.5983 - val_loss: 0.5034 - val_accuracy: 0.7660\n",
            "Epoch 20/50\n",
            "6145/6145 [==============================] - 77s 12ms/step - loss: 0.5017 - accuracy: 0.6878 - val_loss: 0.1693 - val_accuracy: 0.9596\n",
            "Epoch 21/50\n",
            "6145/6145 [==============================] - 80s 13ms/step - loss: 0.4169 - accuracy: 0.7676 - val_loss: 0.3024 - val_accuracy: 0.7877\n",
            "Epoch 22/50\n",
            "6145/6145 [==============================] - 87s 14ms/step - loss: 0.5985 - accuracy: 0.6400 - val_loss: 0.5591 - val_accuracy: 0.7586\n",
            "Epoch 23/50\n",
            "6145/6145 [==============================] - 85s 14ms/step - loss: 0.5736 - accuracy: 0.6744 - val_loss: 0.5186 - val_accuracy: 0.8515\n",
            "Epoch 24/50\n",
            "6145/6145 [==============================] - 85s 14ms/step - loss: 0.6153 - accuracy: 0.6106 - val_loss: 0.5154 - val_accuracy: 0.7609\n",
            "Epoch 25/50\n",
            "6145/6145 [==============================] - 82s 13ms/step - loss: 0.6070 - accuracy: 0.6248 - val_loss: 0.5887 - val_accuracy: 0.8534\n",
            "Epoch 26/50\n",
            "6145/6145 [==============================] - 87s 14ms/step - loss: 0.6528 - accuracy: 0.6067 - val_loss: 0.4508 - val_accuracy: 0.8935\n",
            "Epoch 27/50\n",
            "6145/6145 [==============================] - 82s 13ms/step - loss: 0.5302 - accuracy: 0.6978 - val_loss: 0.4239 - val_accuracy: 0.8607\n",
            "Epoch 28/50\n",
            "6145/6145 [==============================] - 82s 13ms/step - loss: 0.4976 - accuracy: 0.7458 - val_loss: 0.4588 - val_accuracy: 0.8076\n",
            "Epoch 29/50\n",
            "6145/6145 [==============================] - 84s 14ms/step - loss: 0.6368 - accuracy: 0.6162 - val_loss: 0.6211 - val_accuracy: 0.7095\n",
            "Epoch 30/50\n",
            "6145/6145 [==============================] - 86s 14ms/step - loss: 0.6205 - accuracy: 0.6290 - val_loss: 0.5679 - val_accuracy: 0.6469\n",
            "Epoch 31/50\n",
            "6145/6145 [==============================] - 81s 13ms/step - loss: 0.5873 - accuracy: 0.6333 - val_loss: 0.5691 - val_accuracy: 0.6116\n",
            "Epoch 32/50\n",
            "6145/6145 [==============================] - 78s 13ms/step - loss: 0.6090 - accuracy: 0.6249 - val_loss: 0.4809 - val_accuracy: 0.7813\n",
            "Epoch 33/50\n",
            "6145/6145 [==============================] - 86s 14ms/step - loss: 0.5560 - accuracy: 0.6839 - val_loss: 0.5346 - val_accuracy: 0.7817\n",
            "Epoch 34/50\n",
            "6145/6145 [==============================] - 95s 16ms/step - loss: 0.4399 - accuracy: 0.7477 - val_loss: 0.1794 - val_accuracy: 0.9433\n",
            "Epoch 35/50\n",
            "6145/6145 [==============================] - 93s 15ms/step - loss: 0.4113 - accuracy: 0.7718 - val_loss: 0.1426 - val_accuracy: 0.9430\n",
            "Epoch 36/50\n",
            "6145/6145 [==============================] - 92s 15ms/step - loss: 0.5283 - accuracy: 0.7083 - val_loss: 0.4100 - val_accuracy: 0.8299\n",
            "Epoch 37/50\n",
            "6145/6145 [==============================] - 97s 16ms/step - loss: 0.5126 - accuracy: 0.7145 - val_loss: 0.3945 - val_accuracy: 0.8409\n",
            "Epoch 38/50\n",
            "6145/6145 [==============================] - 92s 15ms/step - loss: 0.6510 - accuracy: 0.5600 - val_loss: 0.6740 - val_accuracy: 0.5342\n",
            "Epoch 39/50\n",
            "6145/6145 [==============================] - 97s 16ms/step - loss: 0.9593 - accuracy: 0.5384 - val_loss: 0.6539 - val_accuracy: 0.6448\n",
            "Epoch 40/50\n",
            "6145/6145 [==============================] - 92s 15ms/step - loss: 0.6338 - accuracy: 0.6283 - val_loss: 0.4977 - val_accuracy: 0.6928\n",
            "Epoch 41/50\n",
            "6145/6145 [==============================] - 94s 15ms/step - loss: 0.6106 - accuracy: 0.6462 - val_loss: 0.5341 - val_accuracy: 0.6740\n",
            "Epoch 42/50\n",
            "6145/6145 [==============================] - 90s 15ms/step - loss: 0.6805 - accuracy: 0.5513 - val_loss: 0.6750 - val_accuracy: 0.4890\n",
            "Epoch 43/50\n",
            "6145/6145 [==============================] - 94s 15ms/step - loss: 0.6502 - accuracy: 0.6083 - val_loss: 0.3810 - val_accuracy: 0.8983\n",
            "Epoch 44/50\n",
            "6145/6145 [==============================] - 90s 15ms/step - loss: 0.6384 - accuracy: 0.5971 - val_loss: 0.5461 - val_accuracy: 0.7025\n",
            "Epoch 45/50\n",
            "6145/6145 [==============================] - 94s 15ms/step - loss: 0.5987 - accuracy: 0.6213 - val_loss: 0.5091 - val_accuracy: 0.7808\n",
            "Epoch 46/50\n",
            "6145/6145 [==============================] - 88s 14ms/step - loss: 0.6381 - accuracy: 0.5910 - val_loss: 0.6654 - val_accuracy: 0.5925\n",
            "Epoch 47/50\n",
            "6145/6145 [==============================] - 79s 13ms/step - loss: 0.6466 - accuracy: 0.5953 - val_loss: 0.7069 - val_accuracy: 0.5109\n",
            "Epoch 48/50\n",
            "6145/6145 [==============================] - 78s 13ms/step - loss: 0.5902 - accuracy: 0.6445 - val_loss: 0.4398 - val_accuracy: 0.8456\n",
            "Epoch 49/50\n",
            "6145/6145 [==============================] - 91s 15ms/step - loss: 0.6239 - accuracy: 0.6429 - val_loss: 0.6674 - val_accuracy: 0.6006\n",
            "Epoch 50/50\n",
            "6145/6145 [==============================] - 92s 15ms/step - loss: 0.6412 - accuracy: 0.5885 - val_loss: 0.6437 - val_accuracy: 0.6298\n",
            "961/961 [==============================] - 4s 4ms/step - loss: 0.6437 - accuracy: 0.6298\n",
            "[0.6437476277351379, 0.6297682523727417]\n",
            "[[13677  1678]\n",
            " [ 9697  5672]]\n",
            "0.6297682593412316\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.89      0.71     15355\n",
            "           1       0.77      0.37      0.50     15369\n",
            "\n",
            "    accuracy                           0.63     30724\n",
            "   macro avg       0.68      0.63      0.60     30724\n",
            "weighted avg       0.68      0.63      0.60     30724\n",
            "\n",
            "Training time: 4.291534423828125e-05\n",
            "Test time: 1.6689300537109375e-05\n",
            "\n",
            "TIME: 0.0007200241088867188seconds\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "#from keras.optimizers import SGD\n",
        "#opt = SGD(lr=0.0001)\n",
        "#batch_size = 64\n",
        "\n",
        "# 1. define the network\n",
        "model = Sequential()\n",
        "model.add(LSTM(4,input_shape = X_train[0].shape))  \n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2))\n",
        "\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "#model.add(Dense(1, activation='sigmoid'))\n",
        " \n",
        "model.compile(optimizer=Adam(lr=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_train, y_train, epochs=50, batch_size = 20, validation_data=(X_test, y_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_test, y_preds_cnn))\n",
        "print(accuracy_score(y_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_preds_cnn))\n",
        "\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1gXRuO8AyKi"
      },
      "source": [
        "**DNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHA_bPIIA05d",
        "outputId": "56b05c28-6771-47bc-f8ff-7f07ba8f5d6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6145/6145 [==============================] - 15s 2ms/step - loss: 0.3543 - accuracy: 0.8482 - val_loss: 0.4768 - val_accuracy: 0.7642\n",
            "Epoch 2/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4618 - accuracy: 0.7659 - val_loss: 0.4614 - val_accuracy: 0.7642\n",
            "Epoch 3/50\n",
            "6145/6145 [==============================] - 13s 2ms/step - loss: 0.4618 - accuracy: 0.7659 - val_loss: 0.4636 - val_accuracy: 0.7642\n",
            "Epoch 4/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4620 - accuracy: 0.7659 - val_loss: 0.4638 - val_accuracy: 0.7642\n",
            "Epoch 5/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4617 - accuracy: 0.7659 - val_loss: 0.4619 - val_accuracy: 0.7642\n",
            "Epoch 6/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4617 - accuracy: 0.7659 - val_loss: 0.4652 - val_accuracy: 0.7642\n",
            "Epoch 7/50\n",
            "6145/6145 [==============================] - 13s 2ms/step - loss: 0.4615 - accuracy: 0.7659 - val_loss: 0.4624 - val_accuracy: 0.7642\n",
            "Epoch 8/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4616 - accuracy: 0.7659 - val_loss: 0.4634 - val_accuracy: 0.7642\n",
            "Epoch 9/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4617 - accuracy: 0.7659 - val_loss: 0.4620 - val_accuracy: 0.7642\n",
            "Epoch 10/50\n",
            "6145/6145 [==============================] - 13s 2ms/step - loss: 0.4615 - accuracy: 0.7659 - val_loss: 0.4616 - val_accuracy: 0.7642\n",
            "Epoch 11/50\n",
            "6145/6145 [==============================] - 13s 2ms/step - loss: 0.4617 - accuracy: 0.7659 - val_loss: 0.4639 - val_accuracy: 0.7642\n",
            "Epoch 12/50\n",
            "6145/6145 [==============================] - 13s 2ms/step - loss: 0.4617 - accuracy: 0.7659 - val_loss: 0.4617 - val_accuracy: 0.7642\n",
            "Epoch 13/50\n",
            "6145/6145 [==============================] - 15s 2ms/step - loss: 0.4616 - accuracy: 0.7659 - val_loss: 0.4615 - val_accuracy: 0.7642\n",
            "Epoch 14/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4616 - accuracy: 0.7659 - val_loss: 0.4620 - val_accuracy: 0.7642\n",
            "Epoch 15/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4619 - accuracy: 0.7659 - val_loss: 0.4630 - val_accuracy: 0.7642\n",
            "Epoch 16/50\n",
            "6145/6145 [==============================] - 15s 2ms/step - loss: 0.4618 - accuracy: 0.7659 - val_loss: 0.4625 - val_accuracy: 0.7642\n",
            "Epoch 17/50\n",
            "6145/6145 [==============================] - 15s 2ms/step - loss: 0.4619 - accuracy: 0.7659 - val_loss: 0.4661 - val_accuracy: 0.7642\n",
            "Epoch 18/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4621 - accuracy: 0.7659 - val_loss: 0.4684 - val_accuracy: 0.7642\n",
            "Epoch 19/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4617 - accuracy: 0.7659 - val_loss: 0.4652 - val_accuracy: 0.7642\n",
            "Epoch 20/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4618 - accuracy: 0.7659 - val_loss: 0.4615 - val_accuracy: 0.7642\n",
            "Epoch 21/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4618 - accuracy: 0.7659 - val_loss: 0.4615 - val_accuracy: 0.7642\n",
            "Epoch 22/50\n",
            "6145/6145 [==============================] - 13s 2ms/step - loss: 0.4618 - accuracy: 0.7659 - val_loss: 0.4633 - val_accuracy: 0.7642\n",
            "Epoch 23/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4618 - accuracy: 0.7659 - val_loss: 0.4624 - val_accuracy: 0.7642\n",
            "Epoch 24/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4618 - accuracy: 0.7659 - val_loss: 0.4617 - val_accuracy: 0.7642\n",
            "Epoch 25/50\n",
            "6145/6145 [==============================] - 13s 2ms/step - loss: 0.4618 - accuracy: 0.7659 - val_loss: 0.4621 - val_accuracy: 0.7642\n",
            "Epoch 26/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4616 - accuracy: 0.7659 - val_loss: 0.4660 - val_accuracy: 0.7642\n",
            "Epoch 27/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4616 - accuracy: 0.7659 - val_loss: 0.4623 - val_accuracy: 0.7642\n",
            "Epoch 28/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4615 - accuracy: 0.7659 - val_loss: 0.4636 - val_accuracy: 0.7642\n",
            "Epoch 29/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4616 - accuracy: 0.7659 - val_loss: 0.4620 - val_accuracy: 0.7642\n",
            "Epoch 30/50\n",
            "6145/6145 [==============================] - 15s 2ms/step - loss: 0.4615 - accuracy: 0.7659 - val_loss: 0.4647 - val_accuracy: 0.7642\n",
            "Epoch 31/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4620 - accuracy: 0.7659 - val_loss: 0.4615 - val_accuracy: 0.7642\n",
            "Epoch 32/50\n",
            "6145/6145 [==============================] - 13s 2ms/step - loss: 0.4617 - accuracy: 0.7659 - val_loss: 0.4618 - val_accuracy: 0.7642\n",
            "Epoch 33/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4618 - accuracy: 0.7659 - val_loss: 0.4614 - val_accuracy: 0.7642\n",
            "Epoch 34/50\n",
            "6145/6145 [==============================] - 13s 2ms/step - loss: 0.4618 - accuracy: 0.7659 - val_loss: 0.4614 - val_accuracy: 0.7642\n",
            "Epoch 35/50\n",
            "6145/6145 [==============================] - 13s 2ms/step - loss: 0.4616 - accuracy: 0.7659 - val_loss: 0.4615 - val_accuracy: 0.7642\n",
            "Epoch 36/50\n",
            "6145/6145 [==============================] - 13s 2ms/step - loss: 0.4617 - accuracy: 0.7659 - val_loss: 0.4619 - val_accuracy: 0.7642\n",
            "Epoch 37/50\n",
            "6145/6145 [==============================] - 13s 2ms/step - loss: 0.4618 - accuracy: 0.7659 - val_loss: 0.4626 - val_accuracy: 0.7642\n",
            "Epoch 38/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4618 - accuracy: 0.7659 - val_loss: 0.4615 - val_accuracy: 0.7642\n",
            "Epoch 39/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4616 - accuracy: 0.7659 - val_loss: 0.4649 - val_accuracy: 0.7642\n",
            "Epoch 40/50\n",
            "6145/6145 [==============================] - 13s 2ms/step - loss: 0.4618 - accuracy: 0.7659 - val_loss: 0.4688 - val_accuracy: 0.7642\n",
            "Epoch 41/50\n",
            "6145/6145 [==============================] - 13s 2ms/step - loss: 0.4615 - accuracy: 0.7659 - val_loss: 0.4725 - val_accuracy: 0.7642\n",
            "Epoch 42/50\n",
            "6145/6145 [==============================] - 13s 2ms/step - loss: 0.4614 - accuracy: 0.7659 - val_loss: 0.4614 - val_accuracy: 0.7642\n",
            "Epoch 43/50\n",
            "6145/6145 [==============================] - 13s 2ms/step - loss: 0.4618 - accuracy: 0.7659 - val_loss: 0.4659 - val_accuracy: 0.7642\n",
            "Epoch 44/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4618 - accuracy: 0.7659 - val_loss: 0.4626 - val_accuracy: 0.7642\n",
            "Epoch 45/50\n",
            "6145/6145 [==============================] - 13s 2ms/step - loss: 0.4618 - accuracy: 0.7659 - val_loss: 0.4615 - val_accuracy: 0.7642\n",
            "Epoch 46/50\n",
            "6145/6145 [==============================] - 13s 2ms/step - loss: 0.4616 - accuracy: 0.7659 - val_loss: 0.4708 - val_accuracy: 0.7642\n",
            "Epoch 47/50\n",
            "6145/6145 [==============================] - 13s 2ms/step - loss: 0.4615 - accuracy: 0.7659 - val_loss: 0.4631 - val_accuracy: 0.7642\n",
            "Epoch 48/50\n",
            "6145/6145 [==============================] - 13s 2ms/step - loss: 0.4618 - accuracy: 0.7659 - val_loss: 0.4632 - val_accuracy: 0.7642\n",
            "Epoch 49/50\n",
            "6145/6145 [==============================] - 14s 2ms/step - loss: 0.4618 - accuracy: 0.7659 - val_loss: 0.4615 - val_accuracy: 0.7642\n",
            "Epoch 50/50\n",
            "6145/6145 [==============================] - 13s 2ms/step - loss: 0.4615 - accuracy: 0.7659 - val_loss: 0.4616 - val_accuracy: 0.7642\n",
            "961/961 [==============================] - 1s 1ms/step - loss: 0.4616 - accuracy: 0.7642\n",
            "[0.4616399109363556, 0.7642233967781067]\n",
            "[[15355     0]\n",
            " [ 7244  8125]]\n",
            "0.7642234084103632\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      1.00      0.81     15355\n",
            "           1       1.00      0.53      0.69     15369\n",
            "\n",
            "    accuracy                           0.76     30724\n",
            "   macro avg       0.84      0.76      0.75     30724\n",
            "weighted avg       0.84      0.76      0.75     30724\n",
            "\n",
            "Training time: 6.175041198730469e-05\n",
            "Test time: 1.5974044799804688e-05\n",
            "\n",
            "TIME: 0.0006747245788574219seconds\n"
          ]
        }
      ],
      "source": [
        "#from keras.layers import LSTM, SimpleRNN, GRU\n",
        "#from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import time\n",
        "start = time.time()\n",
        "#from keras.optimizers import SGD\n",
        "#opt = SGD(lr=0.0001)\n",
        "#batch_size = 64\n",
        "\n",
        "# 1. define the network\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(37,)),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer=Adam(lr=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_train, y_train, epochs=50, batch_size = 20, validation_data=(X_test, y_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_test, y_preds_cnn))\n",
        "print(accuracy_score(y_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_preds_cnn))\n",
        "\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6SJBOzJA2q0"
      },
      "source": [
        "**CNN-LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_CWx-zpA8cX",
        "outputId": "64417430-9453-42ec-8586-58de2e7b937c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6145/6145 [==============================] - 76s 12ms/step - loss: 0.6570 - accuracy: 0.6124 - val_loss: 0.6328 - val_accuracy: 0.5002\n",
            "Epoch 2/10\n",
            "6145/6145 [==============================] - 70s 11ms/step - loss: 0.6513 - accuracy: 0.6128 - val_loss: 0.6632 - val_accuracy: 0.6683\n",
            "Epoch 3/10\n",
            "6145/6145 [==============================] - 69s 11ms/step - loss: 0.7132 - accuracy: 0.5449 - val_loss: 0.6828 - val_accuracy: 0.5338\n",
            "Epoch 4/10\n",
            "6145/6145 [==============================] - 72s 12ms/step - loss: 0.7346 - accuracy: 0.5165 - val_loss: 0.6786 - val_accuracy: 0.5338\n",
            "Epoch 5/10\n",
            "6145/6145 [==============================] - 74s 12ms/step - loss: 0.7345 - accuracy: 0.5145 - val_loss: 0.7404 - val_accuracy: 0.5226\n",
            "Epoch 6/10\n",
            "6145/6145 [==============================] - 75s 12ms/step - loss: 0.7362 - accuracy: 0.5156 - val_loss: 0.6853 - val_accuracy: 0.5338\n",
            "Epoch 7/10\n",
            "6145/6145 [==============================] - 74s 12ms/step - loss: 0.7346 - accuracy: 0.5114 - val_loss: 0.6922 - val_accuracy: 0.5338\n",
            "Epoch 8/10\n",
            "6145/6145 [==============================] - 75s 12ms/step - loss: 0.7345 - accuracy: 0.5176 - val_loss: 0.6792 - val_accuracy: 0.5002\n",
            "Epoch 9/10\n",
            "6145/6145 [==============================] - 75s 12ms/step - loss: 0.7348 - accuracy: 0.5138 - val_loss: 0.6799 - val_accuracy: 0.5338\n",
            "Epoch 10/10\n",
            "6145/6145 [==============================] - 73s 12ms/step - loss: 0.7328 - accuracy: 0.5169 - val_loss: 0.6785 - val_accuracy: 0.5002\n",
            "961/961 [==============================] - 3s 3ms/step - loss: 0.6785 - accuracy: 0.5002\n",
            "[0.6785208582878113, 0.5002278089523315]\n",
            "[[    0 15355]\n",
            " [    0 15369]]\n",
            "0.5002278349173285\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00     15355\n",
            "           1       0.50      1.00      0.67     15369\n",
            "\n",
            "    accuracy                           0.50     30724\n",
            "   macro avg       0.25      0.50      0.33     30724\n",
            "weighted avg       0.25      0.50      0.33     30724\n",
            "\n",
            "Training time: 4.172325134277344e-05\n",
            "Test time: 1.621246337890625e-05\n",
            "\n",
            "TIME: 0.00031876564025878906seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda\n",
        "\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, Dense, Dropout, Flatten, MaxPooling1D\n",
        "\n",
        "from keras.layers import LSTM, GRU, SimpleRNN\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "lstm_output_size = 20\n",
        "model = Sequential()\n",
        "model.add(Conv1D(32, 2, activation='relu', input_shape = X_train[0].shape))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(SimpleRNN(lstm_output_size))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "#model.add(Dense(1, activation='sigmoid'))\n",
        "    #])\n",
        "model.compile(optimizer=Adam(lr=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_train, y_train, epochs=10, batch_size = 20, validation_data=(X_test, y_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_test, y_preds_cnn))\n",
        "print(accuracy_score(y_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_preds_cnn))\n",
        "\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Wustl**"
      ],
      "metadata": {
        "id": "CfvVRjnuAiTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client1 = pd.read_csv('/content/drive/MyDrive/GlobeCom/client_df1.csv')\n",
        "client1_shuffled = client1.sample(frac=1, random_state = 13).reset_index(drop = True)\n",
        "\n",
        "client2 = pd.read_csv('/content/drive/MyDrive/GlobeCom/client_df2.csv')\n",
        "client2_shuffled = client2.sample(frac=1, random_state = 13).reset_index(drop = True)\n",
        "\n",
        "client3 = pd.read_csv('/content/drive/MyDrive/GlobeCom/client_df3.csv')\n",
        "client3_shuffled = client3.sample(frac=1, random_state = 13).reset_index(drop = True)\n",
        "\n",
        "client4 = pd.read_csv('/content/drive/MyDrive/GlobeCom/client_df4.csv')\n",
        "client4_shuffled = client4.sample(frac=1, random_state = 13).reset_index(drop = True)\n",
        "\n",
        "client5 = pd.read_csv('/content/drive/MyDrive/GlobeCom/client_df5.csv')\n",
        "client5_shuffled = client5.sample(frac=1, random_state = 13).reset_index(drop = True)"
      ],
      "metadata": {
        "id": "jADGYIHDAmmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "BATCH_SIZE = 1024\n",
        "#BATCH_SIZE = 64 #ECU"
      ],
      "metadata": {
        "id": "QYKHjV7FArcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def make_tf_dataset(dataframe, negative_ratio=None, batch_size=None):\n",
        "  \n",
        "    dataset = dataframe.drop(['Unnamed: 0'], axis=1)#, 'SrcGap', 'DstGap', 'DIntPktAct','sMinPktSz', 'Trans'\n",
        "    # Class balancing\n",
        "    pos_df = dataset[dataset['Label'] == 1]\n",
        "    neg_df = dataset[dataset['Label'] == 0]\n",
        "    if negative_ratio:\n",
        "        neg_df = neg_df.iloc[random.sample(range(0, len(neg_df)), len(pos_df)*negative_ratio), :]\n",
        "    balanced_df = pd.concat([pos_df, neg_df], ignore_index=True, sort=False)\n",
        "\n",
        "    y = balanced_df.pop('Label')\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((balanced_df.values, y.to_frame().values))\n",
        "    dataset = dataset.shuffle(4048, seed=SEED) #2048\n",
        "    if batch_size:\n",
        "        dataset = dataset.batch(batch_size)\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "rFjtOUzmAuXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "train_data, val_data = [], []\n",
        "\n",
        "for client_data in [client1_shuffled, client2_shuffled, client3_shuffled, client4_shuffled, client5_shuffled]:\n",
        "                     \n",
        "                   \n",
        "    train_df, val_df = train_test_split(client_data, test_size=0.1, random_state=1337)\n",
        "\n",
        "    # Scaling (Standardization actually hurts performance) \n",
        "    encoder = LabelEncoder()\n",
        "    scaler = StandardScaler() \n",
        "    train_features = scaler.fit_transform(train_df.drop(['Label'], axis=1))\n",
        "    val_features = scaler.transform(val_df.drop(['Label'], axis=1))\n",
        "  \n",
        "    #encoder = LabelEncoder()\n",
        "    #y1 = encoder.fit_transform(y)\n",
        "    #Y= pd.get_dummies(y1).values\n",
        "    train_df[train_df.columns.difference(['Label'])] = train_features\n",
        "    val_df[val_df.columns.difference(['Label'])] = val_features\n",
        "\n",
        "    # TF Datasets\n",
        "    train_data.append(make_tf_dataset(train_df,negative_ratio=2, batch_size=BATCH_SIZE)) #negative_ratio=2\n",
        "    val_data.append(make_tf_dataset(val_df, batch_size=16))   "
      ],
      "metadata": {
        "id": "CWuo8bjUAzDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.metrics import CategoricalAccuracy, Precision, Recall, BinaryAccuracy\n",
        "def input_spec():\n",
        "    return (\n",
        "        tf.TensorSpec([None, 35], tf.float64),\n",
        "        tf.TensorSpec([None, 1], tf.int64)\n",
        "    )\n",
        "\n",
        "def model_fn():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(35,)),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "    ])\n",
        "\n",
        "    return tff.learning.from_keras_model(\n",
        "        model,\n",
        "        input_spec=input_spec(),\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.BinaryAccuracy(), Precision(), Recall()]\n",
        "        )"
      ],
      "metadata": {
        "id": "X3bsVtlkA5Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = tff.learning.build_federated_averaging_process(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.05)#learning_rate=0.01\n",
        ")\n"
      ],
      "metadata": {
        "id": "Ozyb0aP3BC0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str(trainer.initialize.type_signature)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "vxGm5pOdBPTM",
        "outputId": "4146eca3-bccc-480c-be9f-c3771c34429d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'( -> <model=<trainable=<float32[35,32],float32[32],float32[32,64],float32[64],float32[64,32],float32[32],float32[32,1],float32[1]>,non_trainable=<>>,optimizer_state=<int64,float32[35,32],float32[32],float32[32,64],float32[64],float32[64,32],float32[32],float32[32,1],float32[1],float32[35,32],float32[32],float32[32,64],float32[64],float32[64,32],float32[32],float32[32,1],float32[1]>,delta_aggregate_state=<value_sum_process=<>,weight_sum_process=<>>,model_broadcast_state=<>>@SERVER)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state = trainer.initialize()"
      ],
      "metadata": {
        "id": "8w3cZscoBU0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "#state = trainer.initialize()\n",
        "train_hist = []\n",
        "for i in range(EPOCHS):\n",
        "    state, metrics = trainer.next(state, train_data)\n",
        "    train_hist.append(metrics)\n",
        "\n",
        "    print(f\"\\rRun {i+1}/{EPOCHS}\", end=\"\")\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k25r_ydYBXsZ",
        "outputId": "70d817c4-08da-4f8e-a2f5-693539913db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 50/50Training time: 7.581710815429688e-05\n",
            "Test time: 2.8371810913085938e-05\n",
            "\n",
            "TIME: 117.146555185318seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = tff.learning.build_federated_evaluation(model_fn)"
      ],
      "metadata": {
        "id": "q82pTAnmBcAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "federated_metrics = evaluator(state.model, val_data)\n",
        "federated_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z15ivG8TBk94",
        "outputId": "9c2d5ab3-1220-4469-8f37-9ccc74e1d2b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('eval',\n",
              "              OrderedDict([('binary_accuracy', 0.90519875),\n",
              "                           ('precision', 0.60714287),\n",
              "                           ('recall', 0.6699507),\n",
              "                           ('loss', 0.33771968),\n",
              "                           ('num_examples', 1635),\n",
              "                           ('num_batches', 105)]))])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1-RdU_A7CeDurhzMIi6P7sPRA-rqE_tOk",
      "authorship_tag": "ABX9TyPB5Pnh98tTWnHphqM1si7B",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}