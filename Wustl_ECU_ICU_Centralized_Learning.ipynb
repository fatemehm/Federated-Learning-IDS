{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatemehm/Federated-Learning-IDS/blob/main/Wustl_ECU_ICU_Centralized_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Centralized-WUSTL-EHMS-2020***"
      ],
      "metadata": {
        "id": "cu2ypkwsdlXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import missingno as msno"
      ],
      "metadata": {
        "id": "zDTU21tkdvHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_uni = pd.read_csv('/content/drive/MyDrive/GlobeCom/clean_wustl.csv')\n",
        "shape = df_uni.shape\n",
        "print('Dataframe shape: ', shape)\n",
        "print('Number of rows: ', shape[0])\n",
        "print('Number of columns: ', shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Iop262ed5Xx",
        "outputId": "99d671a7-6675-4372-fe32-02f8d02625c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe shape:  (16315, 37)\n",
            "Number of rows:  16315\n",
            "Number of columns:  37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_uni.Label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdMMcghud-cI",
        "outputId": "7ab10f8a-0dd6-4955-c5ff-41727207f1a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    14269\n",
              "1     2046\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_columns = ['Unnamed: 0']#, 'Flgs','SrcAddr',\t'DstAddr', 'Dport', 'SrcMac',\t'DstMac',\t'Packet_num']\t\t\n",
        "df_uni= df_uni.drop(columns=drop_columns)\n",
        "df_uni.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAt0zg34eE-E",
        "outputId": "eb2ce6a3-3829-448a-994a-a4cae0e59ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16315 entries, 0 to 16314\n",
            "Data columns (total 36 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Sport       16315 non-null  float64\n",
            " 1   SrcBytes    16315 non-null  float64\n",
            " 2   DstBytes    16315 non-null  float64\n",
            " 3   SrcLoad     16315 non-null  float64\n",
            " 4   DstLoad     16315 non-null  float64\n",
            " 5   SrcGap      16315 non-null  float64\n",
            " 6   DstGap      16315 non-null  float64\n",
            " 7   SIntPkt     16315 non-null  float64\n",
            " 8   DIntPkt     16315 non-null  float64\n",
            " 9   SIntPktAct  16315 non-null  float64\n",
            " 10  DIntPktAct  16315 non-null  float64\n",
            " 11  SrcJitter   16315 non-null  float64\n",
            " 12  DstJitter   16315 non-null  float64\n",
            " 13  sMaxPktSz   16315 non-null  float64\n",
            " 14  dMaxPktSz   16315 non-null  float64\n",
            " 15  sMinPktSz   16315 non-null  float64\n",
            " 16  dMinPktSz   16315 non-null  float64\n",
            " 17  Dur         16315 non-null  float64\n",
            " 18  Trans       16315 non-null  float64\n",
            " 19  TotPkts     16315 non-null  float64\n",
            " 20  TotBytes    16315 non-null  float64\n",
            " 21  Load        16315 non-null  float64\n",
            " 22  Loss        16315 non-null  float64\n",
            " 23  pLoss       16315 non-null  float64\n",
            " 24  pSrcLoss    16315 non-null  float64\n",
            " 25  pDstLoss    16315 non-null  float64\n",
            " 26  Rate        16315 non-null  float64\n",
            " 27  Temp        16315 non-null  float64\n",
            " 28  SpO2        16315 non-null  float64\n",
            " 29  Pulse_Rate  16315 non-null  float64\n",
            " 30  SYS         16315 non-null  float64\n",
            " 31  DIA         16315 non-null  float64\n",
            " 32  Heart_rate  16315 non-null  float64\n",
            " 33  Resp_Rate   16315 non-null  float64\n",
            " 34  ST          16315 non-null  float64\n",
            " 35  Label       16315 non-null  int64  \n",
            "dtypes: float64(35), int64(1)\n",
            "memory usage: 4.5 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_uni = df_uni.drop('Label', axis = 1)\n",
        "y_uni = df_uni['Label']\n",
        "X_uni.shape, y_uni.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu-oqo1FeVIu",
        "outputId": "465a2ae6-911c-40f1-dd75-39c888160137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16315, 35), (16315,))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "X_uni_smote, y_uni_smote = SMOTE().fit_resample(X_uni, y_uni)"
      ],
      "metadata": {
        "id": "SjKyHLDtebMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7P09p8XmeguV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "#from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_uni_train, X_uni_test, y_uni_train, y_uni_test = train_test_split(X_uni_smote, y_uni_smote, test_size=0.2, random_state = 1337)"
      ],
      "metadata": {
        "id": "ZdJKxBSFekHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaling = StandardScaler()\n",
        "X_uni_train = scaling.fit_transform(X_uni_train)\n",
        "X_uni_test = scaling.transform(X_uni_test)"
      ],
      "metadata": {
        "id": "RJSDjAwyer9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For CNN and CNN-LSTM\n",
        "X_uni_train = X_uni_train.reshape(X_uni_train.shape[0], X_uni_train.shape[1], 1)\n",
        "X_uni_test = X_uni_test.reshape(X_uni_test.shape[0], X_uni_test.shape[1], 1)"
      ],
      "metadata": {
        "id": "And5IMQX0QpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM**"
      ],
      "metadata": {
        "id": "cpx6MJl_zKOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import time\n",
        "import time\n",
        "start = time.time()\n",
        "#from keras.optimizers import SGD\n",
        "#opt = SGD(lr=0.0001)\n",
        "#batch_size = 64\n",
        "\n",
        "# 1. define the network\n",
        "model = Sequential()\n",
        "model.add(LSTM(4,input_shape = X_uni_train[0].shape))  \n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_uni_train, y_uni_train, epochs=100, batch_size = 1024, validation_data=(X_uni_test, y_uni_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_uni_test, y_uni_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_uni_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_uni_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_uni_test, y_preds_cnn))\n",
        "print(accuracy_score(y_uni_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_uni_test, y_preds_cnn))\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8jKHuA0zNO0",
        "outputId": "2408b8b0-f101-43cf-f673-ecf47f8150a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 3s 46ms/step - loss: 0.6995 - accuracy: 0.4734 - val_loss: 0.6923 - val_accuracy: 0.5012\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.6928 - accuracy: 0.4994 - val_loss: 0.6905 - val_accuracy: 0.4963\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.6855 - accuracy: 0.5328 - val_loss: 0.6555 - val_accuracy: 0.6507\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 35ms/step - loss: 0.6493 - accuracy: 0.6163 - val_loss: 0.6077 - val_accuracy: 0.6936\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.6090 - accuracy: 0.6497 - val_loss: 0.5613 - val_accuracy: 0.7020\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5783 - accuracy: 0.6622 - val_loss: 0.5287 - val_accuracy: 0.7209\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.5664 - accuracy: 0.6781 - val_loss: 0.5321 - val_accuracy: 0.7150\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.5526 - accuracy: 0.6803 - val_loss: 0.5159 - val_accuracy: 0.7157\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5469 - accuracy: 0.6811 - val_loss: 0.5150 - val_accuracy: 0.7130\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5440 - accuracy: 0.6906 - val_loss: 0.5113 - val_accuracy: 0.7183\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5406 - accuracy: 0.6929 - val_loss: 0.5086 - val_accuracy: 0.7158\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5443 - accuracy: 0.6917 - val_loss: 0.5087 - val_accuracy: 0.7169\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 22ms/step - loss: 0.5716 - accuracy: 0.6820 - val_loss: 0.5220 - val_accuracy: 0.7174\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5452 - accuracy: 0.6989 - val_loss: 0.5122 - val_accuracy: 0.7158\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5356 - accuracy: 0.6972 - val_loss: 0.5076 - val_accuracy: 0.7174\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5745 - accuracy: 0.6877 - val_loss: 0.6149 - val_accuracy: 0.6797\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5749 - accuracy: 0.6921 - val_loss: 0.5274 - val_accuracy: 0.7193\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5459 - accuracy: 0.7053 - val_loss: 0.5181 - val_accuracy: 0.7169\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.5399 - accuracy: 0.7031 - val_loss: 0.5111 - val_accuracy: 0.7183\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5362 - accuracy: 0.7021 - val_loss: 0.5100 - val_accuracy: 0.7169\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5320 - accuracy: 0.7047 - val_loss: 0.5069 - val_accuracy: 0.7186\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5351 - accuracy: 0.7004 - val_loss: 0.5080 - val_accuracy: 0.7179\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.5360 - accuracy: 0.7019 - val_loss: 0.5056 - val_accuracy: 0.7195\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5507 - accuracy: 0.7018 - val_loss: 0.5080 - val_accuracy: 0.7197\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5355 - accuracy: 0.7014 - val_loss: 0.5074 - val_accuracy: 0.7192\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5337 - accuracy: 0.7047 - val_loss: 0.5058 - val_accuracy: 0.7197\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5324 - accuracy: 0.7060 - val_loss: 0.5048 - val_accuracy: 0.7199\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.5304 - accuracy: 0.7078 - val_loss: 0.5055 - val_accuracy: 0.7193\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5298 - accuracy: 0.7060 - val_loss: 0.5050 - val_accuracy: 0.7193\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5447 - accuracy: 0.7011 - val_loss: 0.5402 - val_accuracy: 0.6896\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5385 - accuracy: 0.7035 - val_loss: 0.5077 - val_accuracy: 0.7209\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 1s 22ms/step - loss: 0.5331 - accuracy: 0.7045 - val_loss: 0.5053 - val_accuracy: 0.7197\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5303 - accuracy: 0.7074 - val_loss: 0.5030 - val_accuracy: 0.7204\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5289 - accuracy: 0.7095 - val_loss: 0.5029 - val_accuracy: 0.7204\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.5292 - accuracy: 0.7098 - val_loss: 0.5228 - val_accuracy: 0.7060\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5287 - accuracy: 0.7042 - val_loss: 0.5043 - val_accuracy: 0.7193\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.5279 - accuracy: 0.7073 - val_loss: 0.5023 - val_accuracy: 0.7190\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5361 - accuracy: 0.7082 - val_loss: 0.5454 - val_accuracy: 0.7123\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5348 - accuracy: 0.7058 - val_loss: 0.5023 - val_accuracy: 0.7220\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5335 - accuracy: 0.7086 - val_loss: 0.5028 - val_accuracy: 0.7206\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.5347 - accuracy: 0.7050 - val_loss: 0.5036 - val_accuracy: 0.7200\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5299 - accuracy: 0.7082 - val_loss: 0.5031 - val_accuracy: 0.7197\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5308 - accuracy: 0.7064 - val_loss: 0.5046 - val_accuracy: 0.7200\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5317 - accuracy: 0.7046 - val_loss: 0.5096 - val_accuracy: 0.7195\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5366 - accuracy: 0.7042 - val_loss: 0.5156 - val_accuracy: 0.7206\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5279 - accuracy: 0.7119 - val_loss: 0.5029 - val_accuracy: 0.7209\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5272 - accuracy: 0.7073 - val_loss: 0.5018 - val_accuracy: 0.7214\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.5271 - accuracy: 0.7076 - val_loss: 0.5005 - val_accuracy: 0.7221\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5280 - accuracy: 0.7108 - val_loss: 0.5010 - val_accuracy: 0.7214\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5285 - accuracy: 0.7081 - val_loss: 0.5123 - val_accuracy: 0.7218\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5290 - accuracy: 0.7100 - val_loss: 0.5019 - val_accuracy: 0.7207\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5288 - accuracy: 0.7073 - val_loss: 0.5038 - val_accuracy: 0.7213\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5253 - accuracy: 0.7097 - val_loss: 0.5025 - val_accuracy: 0.7211\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.5236 - accuracy: 0.7064 - val_loss: 0.5257 - val_accuracy: 0.7027\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5333 - accuracy: 0.7069 - val_loss: 0.5007 - val_accuracy: 0.7214\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5226 - accuracy: 0.7100 - val_loss: 0.5000 - val_accuracy: 0.7230\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5218 - accuracy: 0.7115 - val_loss: 0.4996 - val_accuracy: 0.7228\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5377 - accuracy: 0.7031 - val_loss: 0.5457 - val_accuracy: 0.7148\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5562 - accuracy: 0.6982 - val_loss: 0.5073 - val_accuracy: 0.7204\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.5295 - accuracy: 0.7059 - val_loss: 0.5043 - val_accuracy: 0.7207\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5268 - accuracy: 0.7066 - val_loss: 0.5022 - val_accuracy: 0.7223\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5256 - accuracy: 0.7094 - val_loss: 0.5023 - val_accuracy: 0.7227\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5247 - accuracy: 0.7101 - val_loss: 0.5009 - val_accuracy: 0.7227\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.5247 - accuracy: 0.7099 - val_loss: 0.5003 - val_accuracy: 0.7220\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5212 - accuracy: 0.7129 - val_loss: 0.4999 - val_accuracy: 0.7232\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5230 - accuracy: 0.7081 - val_loss: 0.4993 - val_accuracy: 0.7228\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5217 - accuracy: 0.7099 - val_loss: 0.4993 - val_accuracy: 0.7225\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5235 - accuracy: 0.7108 - val_loss: 0.5033 - val_accuracy: 0.7185\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5184 - accuracy: 0.7122 - val_loss: 0.4985 - val_accuracy: 0.7223\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5180 - accuracy: 0.7118 - val_loss: 0.4982 - val_accuracy: 0.7220\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5183 - accuracy: 0.7109 - val_loss: 0.4963 - val_accuracy: 0.7183\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5177 - accuracy: 0.7098 - val_loss: 0.4935 - val_accuracy: 0.7183\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.5152 - accuracy: 0.7118 - val_loss: 0.4934 - val_accuracy: 0.7204\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5182 - accuracy: 0.7104 - val_loss: 0.4896 - val_accuracy: 0.7316\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5117 - accuracy: 0.7135 - val_loss: 0.4872 - val_accuracy: 0.7304\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.5115 - accuracy: 0.7139 - val_loss: 0.4861 - val_accuracy: 0.7244\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5175 - accuracy: 0.7138 - val_loss: 0.4985 - val_accuracy: 0.7213\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5278 - accuracy: 0.7119 - val_loss: 0.4965 - val_accuracy: 0.7348\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5165 - accuracy: 0.7203 - val_loss: 0.4843 - val_accuracy: 0.7379\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5099 - accuracy: 0.7193 - val_loss: 0.4848 - val_accuracy: 0.7302\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5061 - accuracy: 0.7219 - val_loss: 0.4810 - val_accuracy: 0.7372\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5058 - accuracy: 0.7230 - val_loss: 0.4783 - val_accuracy: 0.7400\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.5019 - accuracy: 0.7257 - val_loss: 0.4761 - val_accuracy: 0.7379\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5050 - accuracy: 0.7277 - val_loss: 0.4830 - val_accuracy: 0.7351\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5021 - accuracy: 0.7297 - val_loss: 0.4802 - val_accuracy: 0.7460\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5001 - accuracy: 0.7268 - val_loss: 0.4742 - val_accuracy: 0.7521\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.5021 - accuracy: 0.7308 - val_loss: 0.4732 - val_accuracy: 0.7500\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.4976 - accuracy: 0.7330 - val_loss: 0.4728 - val_accuracy: 0.7442\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.4975 - accuracy: 0.7319 - val_loss: 0.4676 - val_accuracy: 0.7505\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4998 - accuracy: 0.7331 - val_loss: 0.4656 - val_accuracy: 0.7512\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5000 - accuracy: 0.7311 - val_loss: 0.4726 - val_accuracy: 0.7496\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.5008 - accuracy: 0.7318 - val_loss: 0.4666 - val_accuracy: 0.7518\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.4958 - accuracy: 0.7351 - val_loss: 0.4673 - val_accuracy: 0.7514\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4994 - accuracy: 0.7317 - val_loss: 0.4686 - val_accuracy: 0.7458\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.4985 - accuracy: 0.7283 - val_loss: 0.4815 - val_accuracy: 0.7437\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.5027 - accuracy: 0.7288 - val_loss: 0.4675 - val_accuracy: 0.7493\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.4982 - accuracy: 0.7356 - val_loss: 0.4664 - val_accuracy: 0.7603\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4936 - accuracy: 0.7390 - val_loss: 0.4614 - val_accuracy: 0.7525\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.4955 - accuracy: 0.7327 - val_loss: 0.4761 - val_accuracy: 0.7451\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4982 - accuracy: 0.7331 - val_loss: 0.4707 - val_accuracy: 0.7670\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.4707 - accuracy: 0.7670\n",
            "[0.47067680954933167, 0.7669937014579773]\n",
            "179/179 [==============================] - 1s 3ms/step\n",
            "[[2287  544]\n",
            " [ 786 2091]]\n",
            "0.7669936930623686\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.81      0.77      2831\n",
            "           1       0.79      0.73      0.76      2877\n",
            "\n",
            "    accuracy                           0.77      5708\n",
            "   macro avg       0.77      0.77      0.77      5708\n",
            "weighted avg       0.77      0.77      0.77      5708\n",
            "\n",
            "Training time: 6.771087646484375e-05\n",
            "Test time: 2.3365020751953125e-05\n",
            "\n",
            "TIME: 0.0011417865753173828seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***CNN-LSTM***"
      ],
      "metadata": {
        "id": "QTlJDvNRl5fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###############LSTM###################################\n",
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda\n",
        "\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, Dense, Dropout, Flatten, MaxPooling1D\n",
        "\n",
        "from keras.layers import LSTM, GRU, SimpleRNN\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "lstm_output_size = 20\n",
        "epochs = 10\n",
        "model = Sequential()\n",
        "model.add(Conv1D(32, 2, activation='relu', input_shape = X_uni_train[0].shape))\n",
        "\n",
        "model.add(SimpleRNN(lstm_output_size))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_uni_train, y_uni_train, epochs=100, batch_size = 1024, validation_data=(X_uni_test, y_uni_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_uni_test, y_uni_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_uni_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_uni_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_uni_test, y_preds_cnn))\n",
        "print(accuracy_score(y_uni_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_uni_test, y_preds_cnn))\n",
        "\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2e3haxgl5DM",
        "outputId": "6315e199-c3e0-4438-ffdb-b223cd788331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 2s 48ms/step - loss: 0.5842 - accuracy: 0.6783 - val_loss: 0.4921 - val_accuracy: 0.7560\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.4849 - accuracy: 0.7519 - val_loss: 0.4530 - val_accuracy: 0.7715\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.4644 - accuracy: 0.7664 - val_loss: 0.4327 - val_accuracy: 0.7763\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.4367 - accuracy: 0.7842 - val_loss: 0.4112 - val_accuracy: 0.7954\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.4206 - accuracy: 0.7929 - val_loss: 0.4145 - val_accuracy: 0.7970\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.4130 - accuracy: 0.7968 - val_loss: 0.3940 - val_accuracy: 0.8108\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.4104 - accuracy: 0.8005 - val_loss: 0.3893 - val_accuracy: 0.8164\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.3907 - accuracy: 0.8139 - val_loss: 0.3791 - val_accuracy: 0.8292\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.3721 - accuracy: 0.8272 - val_loss: 0.3610 - val_accuracy: 0.8365\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 46ms/step - loss: 0.3723 - accuracy: 0.8259 - val_loss: 0.3842 - val_accuracy: 0.8204\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 61ms/step - loss: 0.3732 - accuracy: 0.8263 - val_loss: 0.3792 - val_accuracy: 0.8181\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 64ms/step - loss: 0.3692 - accuracy: 0.8274 - val_loss: 0.3640 - val_accuracy: 0.8329\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 0.3679 - accuracy: 0.8305 - val_loss: 0.3706 - val_accuracy: 0.8250\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.3775 - accuracy: 0.8254 - val_loss: 0.3605 - val_accuracy: 0.8343\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 0.3638 - accuracy: 0.8313 - val_loss: 0.3466 - val_accuracy: 0.8425\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 0.3506 - accuracy: 0.8389 - val_loss: 0.3542 - val_accuracy: 0.8369\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.3430 - accuracy: 0.8451 - val_loss: 0.3298 - val_accuracy: 0.8555\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.3352 - accuracy: 0.8452 - val_loss: 0.3663 - val_accuracy: 0.8299\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.3406 - accuracy: 0.8431 - val_loss: 0.3264 - val_accuracy: 0.8506\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.3234 - accuracy: 0.8504 - val_loss: 0.3815 - val_accuracy: 0.8252\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.3540 - accuracy: 0.8385 - val_loss: 0.3374 - val_accuracy: 0.8488\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.3328 - accuracy: 0.8475 - val_loss: 0.3255 - val_accuracy: 0.8544\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.3206 - accuracy: 0.8542 - val_loss: 0.3132 - val_accuracy: 0.8581\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.3136 - accuracy: 0.8585 - val_loss: 0.3216 - val_accuracy: 0.8551\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.3168 - accuracy: 0.8530 - val_loss: 0.3105 - val_accuracy: 0.8648\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.3191 - accuracy: 0.8541 - val_loss: 0.3083 - val_accuracy: 0.8630\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.3113 - accuracy: 0.8583 - val_loss: 0.3182 - val_accuracy: 0.8576\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.3102 - accuracy: 0.8590 - val_loss: 0.3237 - val_accuracy: 0.8506\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.3124 - accuracy: 0.8587 - val_loss: 0.2961 - val_accuracy: 0.8672\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.3172 - accuracy: 0.8574 - val_loss: 0.3203 - val_accuracy: 0.8518\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.3009 - accuracy: 0.8659 - val_loss: 0.3420 - val_accuracy: 0.8399\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.3092 - accuracy: 0.8608 - val_loss: 0.2869 - val_accuracy: 0.8688\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 1s 56ms/step - loss: 0.2833 - accuracy: 0.8730 - val_loss: 0.2941 - val_accuracy: 0.8704\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 1s 62ms/step - loss: 0.3067 - accuracy: 0.8623 - val_loss: 0.2911 - val_accuracy: 0.8749\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 1s 61ms/step - loss: 0.2902 - accuracy: 0.8698 - val_loss: 0.2910 - val_accuracy: 0.8684\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2990 - accuracy: 0.8639 - val_loss: 0.2858 - val_accuracy: 0.8705\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2921 - accuracy: 0.8692 - val_loss: 0.2920 - val_accuracy: 0.8690\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2845 - accuracy: 0.8708 - val_loss: 0.2731 - val_accuracy: 0.8793\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2768 - accuracy: 0.8757 - val_loss: 0.2736 - val_accuracy: 0.8789\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.2784 - accuracy: 0.8760 - val_loss: 0.2746 - val_accuracy: 0.8795\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.3052 - accuracy: 0.8648 - val_loss: 0.2988 - val_accuracy: 0.8658\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.3089 - accuracy: 0.8626 - val_loss: 0.3189 - val_accuracy: 0.8562\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2890 - accuracy: 0.8717 - val_loss: 0.2710 - val_accuracy: 0.8800\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2686 - accuracy: 0.8812 - val_loss: 0.2642 - val_accuracy: 0.8896\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2695 - accuracy: 0.8821 - val_loss: 0.2748 - val_accuracy: 0.8823\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.2803 - accuracy: 0.8760 - val_loss: 0.3109 - val_accuracy: 0.8663\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2819 - accuracy: 0.8747 - val_loss: 0.2627 - val_accuracy: 0.8874\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2724 - accuracy: 0.8790 - val_loss: 0.2735 - val_accuracy: 0.8793\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2740 - accuracy: 0.8791 - val_loss: 0.3255 - val_accuracy: 0.8504\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2906 - accuracy: 0.8710 - val_loss: 0.3025 - val_accuracy: 0.8672\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2724 - accuracy: 0.8786 - val_loss: 0.2962 - val_accuracy: 0.8705\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2748 - accuracy: 0.8796 - val_loss: 0.2768 - val_accuracy: 0.8782\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2591 - accuracy: 0.8850 - val_loss: 0.2454 - val_accuracy: 0.8912\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.2587 - accuracy: 0.8846 - val_loss: 0.2486 - val_accuracy: 0.8900\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.2581 - accuracy: 0.8856 - val_loss: 0.2804 - val_accuracy: 0.8788\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2646 - accuracy: 0.8822 - val_loss: 0.3001 - val_accuracy: 0.8595\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2735 - accuracy: 0.8767 - val_loss: 0.3173 - val_accuracy: 0.8628\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2681 - accuracy: 0.8839 - val_loss: 0.2661 - val_accuracy: 0.8849\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.2575 - accuracy: 0.8855 - val_loss: 0.2740 - val_accuracy: 0.8859\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2496 - accuracy: 0.8910 - val_loss: 0.2528 - val_accuracy: 0.8965\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2554 - accuracy: 0.8883 - val_loss: 0.2561 - val_accuracy: 0.8889\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2520 - accuracy: 0.8884 - val_loss: 0.2530 - val_accuracy: 0.8877\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2492 - accuracy: 0.8901 - val_loss: 0.2650 - val_accuracy: 0.8828\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2719 - accuracy: 0.8805 - val_loss: 0.2564 - val_accuracy: 0.8840\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.2672 - accuracy: 0.8838 - val_loss: 0.2627 - val_accuracy: 0.8835\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2633 - accuracy: 0.8846 - val_loss: 0.2466 - val_accuracy: 0.8961\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2438 - accuracy: 0.8940 - val_loss: 0.2441 - val_accuracy: 0.8931\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2532 - accuracy: 0.8868 - val_loss: 0.2421 - val_accuracy: 0.8979\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2473 - accuracy: 0.8914 - val_loss: 0.2527 - val_accuracy: 0.8903\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2465 - accuracy: 0.8927 - val_loss: 0.2781 - val_accuracy: 0.8760\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.2428 - accuracy: 0.8928 - val_loss: 0.2612 - val_accuracy: 0.8889\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.2638 - accuracy: 0.8837 - val_loss: 0.2610 - val_accuracy: 0.8847\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2518 - accuracy: 0.8890 - val_loss: 0.2490 - val_accuracy: 0.8882\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.2446 - accuracy: 0.8939 - val_loss: 0.2519 - val_accuracy: 0.8914\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2454 - accuracy: 0.8940 - val_loss: 0.2423 - val_accuracy: 0.8900\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.2764 - accuracy: 0.8793 - val_loss: 0.2544 - val_accuracy: 0.8849\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.2540 - accuracy: 0.8908 - val_loss: 0.2424 - val_accuracy: 0.8961\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.2384 - accuracy: 0.8982 - val_loss: 0.2443 - val_accuracy: 0.8963\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2623 - accuracy: 0.8864 - val_loss: 0.2520 - val_accuracy: 0.8910\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.2427 - accuracy: 0.8952 - val_loss: 0.2515 - val_accuracy: 0.8919\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2366 - accuracy: 0.8978 - val_loss: 0.2556 - val_accuracy: 0.8917\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.2428 - accuracy: 0.8959 - val_loss: 0.2384 - val_accuracy: 0.8959\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2410 - accuracy: 0.8939 - val_loss: 0.2409 - val_accuracy: 0.8949\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2435 - accuracy: 0.8926 - val_loss: 0.2610 - val_accuracy: 0.8793\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2534 - accuracy: 0.8905 - val_loss: 0.2553 - val_accuracy: 0.8914\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2407 - accuracy: 0.8965 - val_loss: 0.2515 - val_accuracy: 0.8877\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2415 - accuracy: 0.8939 - val_loss: 0.2452 - val_accuracy: 0.8954\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2431 - accuracy: 0.8943 - val_loss: 0.2402 - val_accuracy: 0.8973\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.2391 - accuracy: 0.8958 - val_loss: 0.2373 - val_accuracy: 0.9001\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.2514 - accuracy: 0.8892 - val_loss: 0.2792 - val_accuracy: 0.8770\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.2510 - accuracy: 0.8903 - val_loss: 0.2459 - val_accuracy: 0.8952\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.2358 - accuracy: 0.8983 - val_loss: 0.2600 - val_accuracy: 0.8886\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2323 - accuracy: 0.8996 - val_loss: 0.2472 - val_accuracy: 0.8931\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.2225 - accuracy: 0.9031 - val_loss: 0.2286 - val_accuracy: 0.9043\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2303 - accuracy: 0.9012 - val_loss: 0.2732 - val_accuracy: 0.8847\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2538 - accuracy: 0.8923 - val_loss: 0.2489 - val_accuracy: 0.8970\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2390 - accuracy: 0.8971 - val_loss: 0.2352 - val_accuracy: 0.8973\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2362 - accuracy: 0.8978 - val_loss: 0.2368 - val_accuracy: 0.8991\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2297 - accuracy: 0.9021 - val_loss: 0.2452 - val_accuracy: 0.8912\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2314 - accuracy: 0.8984 - val_loss: 0.2519 - val_accuracy: 0.8909\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.2519 - accuracy: 0.8909\n",
            "[0.25191545486450195, 0.8908549547195435]\n",
            "179/179 [==============================] - 1s 3ms/step\n",
            "[[2397  434]\n",
            " [ 189 2688]]\n",
            "0.8908549404344779\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.85      0.88      2831\n",
            "           1       0.86      0.93      0.90      2877\n",
            "\n",
            "    accuracy                           0.89      5708\n",
            "   macro avg       0.89      0.89      0.89      5708\n",
            "weighted avg       0.89      0.89      0.89      5708\n",
            "\n",
            "Training time: 6.413459777832031e-05\n",
            "Test time: 2.4318695068359375e-05\n",
            "\n",
            "TIME: 0.0003495216369628906seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DNN**"
      ],
      "metadata": {
        "id": "dtnVOjPWzG0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from keras.layers import LSTM, SimpleRNN, GRU\n",
        "#from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "# 1. define the network\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(35,)),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_uni_train, y_uni_train, epochs=100, batch_size = 1024, validation_data=(X_uni_test, y_uni_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_uni_test, y_uni_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_uni_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_uni_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_uni_test, y_preds_cnn))\n",
        "print(accuracy_score(y_uni_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_uni_test, y_preds_cnn))\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY0mMlNxfFU-",
        "outputId": "b4c938c8-8c8b-4d17-ec74-83defa4d6502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 1s 14ms/step - loss: 0.9566 - accuracy: 0.5187 - val_loss: 0.6426 - val_accuracy: 0.6820\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5720 - accuracy: 0.6921 - val_loss: 0.5253 - val_accuracy: 0.7169\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5041 - accuracy: 0.7247 - val_loss: 0.4728 - val_accuracy: 0.7314\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4616 - accuracy: 0.7575 - val_loss: 0.4226 - val_accuracy: 0.7906\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.8003 - val_loss: 0.3693 - val_accuracy: 0.8245\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3774 - accuracy: 0.8240 - val_loss: 0.3691 - val_accuracy: 0.8178\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3532 - accuracy: 0.8333 - val_loss: 0.3538 - val_accuracy: 0.8337\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3328 - accuracy: 0.8463 - val_loss: 0.3720 - val_accuracy: 0.8099\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3265 - accuracy: 0.8475 - val_loss: 0.3187 - val_accuracy: 0.8514\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3156 - accuracy: 0.8560 - val_loss: 0.3185 - val_accuracy: 0.8481\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3025 - accuracy: 0.8615 - val_loss: 0.3131 - val_accuracy: 0.8604\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2921 - accuracy: 0.8655 - val_loss: 0.3129 - val_accuracy: 0.8553\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3080 - accuracy: 0.8605 - val_loss: 0.2991 - val_accuracy: 0.8635\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2849 - accuracy: 0.8716 - val_loss: 0.3001 - val_accuracy: 0.8658\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2784 - accuracy: 0.8752 - val_loss: 0.2870 - val_accuracy: 0.8697\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2694 - accuracy: 0.8803 - val_loss: 0.2798 - val_accuracy: 0.8770\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2683 - accuracy: 0.8795 - val_loss: 0.2862 - val_accuracy: 0.8747\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2658 - accuracy: 0.8800 - val_loss: 0.2731 - val_accuracy: 0.8809\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2700 - accuracy: 0.8767 - val_loss: 0.2820 - val_accuracy: 0.8765\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2695 - accuracy: 0.8778 - val_loss: 0.2771 - val_accuracy: 0.8767\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2749 - accuracy: 0.8791 - val_loss: 0.2934 - val_accuracy: 0.8809\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2660 - accuracy: 0.8830 - val_loss: 0.2777 - val_accuracy: 0.8760\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2607 - accuracy: 0.8865 - val_loss: 0.2832 - val_accuracy: 0.8737\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2724 - accuracy: 0.8801 - val_loss: 0.2801 - val_accuracy: 0.8754\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2591 - accuracy: 0.8830 - val_loss: 0.2610 - val_accuracy: 0.8816\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2557 - accuracy: 0.8851 - val_loss: 0.2614 - val_accuracy: 0.8859\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2458 - accuracy: 0.8912 - val_loss: 0.2578 - val_accuracy: 0.8874\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.2416 - accuracy: 0.8932 - val_loss: 0.2784 - val_accuracy: 0.8802\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.2585 - accuracy: 0.8866 - val_loss: 0.2575 - val_accuracy: 0.8837\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2403 - accuracy: 0.8939 - val_loss: 0.2599 - val_accuracy: 0.8833\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2422 - accuracy: 0.8927 - val_loss: 0.2435 - val_accuracy: 0.8879\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2422 - accuracy: 0.8914 - val_loss: 0.2671 - val_accuracy: 0.8837\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.2775 - accuracy: 0.8867 - val_loss: 0.2986 - val_accuracy: 0.8810\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.2575 - accuracy: 0.8867 - val_loss: 0.2536 - val_accuracy: 0.8888\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2449 - accuracy: 0.8932 - val_loss: 0.2633 - val_accuracy: 0.8902\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2371 - accuracy: 0.8969 - val_loss: 0.2604 - val_accuracy: 0.8817\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2404 - accuracy: 0.8924 - val_loss: 0.2620 - val_accuracy: 0.8868\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2345 - accuracy: 0.8981 - val_loss: 0.2824 - val_accuracy: 0.8674\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2348 - accuracy: 0.8952 - val_loss: 0.2512 - val_accuracy: 0.8938\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2292 - accuracy: 0.8977 - val_loss: 0.2593 - val_accuracy: 0.8865\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2308 - accuracy: 0.8998 - val_loss: 0.2420 - val_accuracy: 0.8961\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2313 - accuracy: 0.8987 - val_loss: 0.2565 - val_accuracy: 0.8886\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2286 - accuracy: 0.9005 - val_loss: 0.2619 - val_accuracy: 0.8938\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2274 - accuracy: 0.8989 - val_loss: 0.2551 - val_accuracy: 0.8870\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2303 - accuracy: 0.8990 - val_loss: 0.2505 - val_accuracy: 0.8919\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2273 - accuracy: 0.8983 - val_loss: 0.2774 - val_accuracy: 0.8670\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2308 - accuracy: 0.8978 - val_loss: 0.2442 - val_accuracy: 0.8954\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2272 - accuracy: 0.9010 - val_loss: 0.2424 - val_accuracy: 0.8942\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2206 - accuracy: 0.9028 - val_loss: 0.3405 - val_accuracy: 0.8732\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2761 - accuracy: 0.8784 - val_loss: 0.2557 - val_accuracy: 0.8877\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2373 - accuracy: 0.8930 - val_loss: 0.2798 - val_accuracy: 0.8576\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2360 - accuracy: 0.8951 - val_loss: 0.2376 - val_accuracy: 0.8893\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2178 - accuracy: 0.9029 - val_loss: 0.2396 - val_accuracy: 0.8921\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2169 - accuracy: 0.9028 - val_loss: 0.2450 - val_accuracy: 0.8921\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2196 - accuracy: 0.9003 - val_loss: 0.2485 - val_accuracy: 0.8900\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2211 - accuracy: 0.9028 - val_loss: 0.2341 - val_accuracy: 0.8963\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2153 - accuracy: 0.9051 - val_loss: 0.2387 - val_accuracy: 0.8933\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2189 - accuracy: 0.9014 - val_loss: 0.2648 - val_accuracy: 0.8895\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2221 - accuracy: 0.9018 - val_loss: 0.2469 - val_accuracy: 0.8966\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2166 - accuracy: 0.9045 - val_loss: 0.2375 - val_accuracy: 0.8947\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2106 - accuracy: 0.9060 - val_loss: 0.2435 - val_accuracy: 0.8937\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2256 - accuracy: 0.8975 - val_loss: 0.2486 - val_accuracy: 0.8868\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2155 - accuracy: 0.9063 - val_loss: 0.2275 - val_accuracy: 0.9017\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2140 - accuracy: 0.9081 - val_loss: 0.2518 - val_accuracy: 0.8835\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2125 - accuracy: 0.9070 - val_loss: 0.2712 - val_accuracy: 0.8898\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2186 - accuracy: 0.9042 - val_loss: 0.2591 - val_accuracy: 0.8909\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2192 - accuracy: 0.9044 - val_loss: 0.2330 - val_accuracy: 0.8982\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2111 - accuracy: 0.9062 - val_loss: 0.2496 - val_accuracy: 0.8935\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2046 - accuracy: 0.9094 - val_loss: 0.2282 - val_accuracy: 0.9012\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2195 - accuracy: 0.9034 - val_loss: 0.2364 - val_accuracy: 0.8980\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2080 - accuracy: 0.9087 - val_loss: 0.2426 - val_accuracy: 0.8938\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2043 - accuracy: 0.9092 - val_loss: 0.2355 - val_accuracy: 0.9019\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2088 - accuracy: 0.9095 - val_loss: 0.2419 - val_accuracy: 0.8912\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2120 - accuracy: 0.9046 - val_loss: 0.2725 - val_accuracy: 0.8824\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2098 - accuracy: 0.9075 - val_loss: 0.2304 - val_accuracy: 0.9026\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1958 - accuracy: 0.9146 - val_loss: 0.2306 - val_accuracy: 0.9015\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2008 - accuracy: 0.9127 - val_loss: 0.2358 - val_accuracy: 0.8970\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2110 - accuracy: 0.9063 - val_loss: 0.2406 - val_accuracy: 0.8928\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2029 - accuracy: 0.9094 - val_loss: 0.2375 - val_accuracy: 0.8980\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1959 - accuracy: 0.9138 - val_loss: 0.2299 - val_accuracy: 0.9024\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1942 - accuracy: 0.9143 - val_loss: 0.2393 - val_accuracy: 0.9026\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1974 - accuracy: 0.9124 - val_loss: 0.2588 - val_accuracy: 0.8833\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2137 - accuracy: 0.9061 - val_loss: 0.2355 - val_accuracy: 0.9003\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1960 - accuracy: 0.9145 - val_loss: 0.2338 - val_accuracy: 0.8979\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2024 - accuracy: 0.9108 - val_loss: 0.2372 - val_accuracy: 0.8924\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2044 - accuracy: 0.9121 - val_loss: 0.2476 - val_accuracy: 0.8958\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2027 - accuracy: 0.9113 - val_loss: 0.2226 - val_accuracy: 0.9036\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1981 - accuracy: 0.9120 - val_loss: 0.2458 - val_accuracy: 0.8942\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2108 - accuracy: 0.9081 - val_loss: 0.2503 - val_accuracy: 0.9026\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2134 - accuracy: 0.9112 - val_loss: 0.2408 - val_accuracy: 0.8986\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2560 - accuracy: 0.8964 - val_loss: 0.2901 - val_accuracy: 0.8830\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2824 - accuracy: 0.8813 - val_loss: 0.2626 - val_accuracy: 0.8870\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2552 - accuracy: 0.8929 - val_loss: 0.2731 - val_accuracy: 0.8807\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2422 - accuracy: 0.8954 - val_loss: 0.2476 - val_accuracy: 0.8940\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2284 - accuracy: 0.9024 - val_loss: 0.2376 - val_accuracy: 0.9001\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2141 - accuracy: 0.9087 - val_loss: 0.2447 - val_accuracy: 0.8959\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2262 - accuracy: 0.9014 - val_loss: 0.2384 - val_accuracy: 0.8961\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2257 - accuracy: 0.9013 - val_loss: 0.2669 - val_accuracy: 0.8931\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2293 - accuracy: 0.9006 - val_loss: 0.2399 - val_accuracy: 0.8966\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2137 - accuracy: 0.9077 - val_loss: 0.2390 - val_accuracy: 0.9052\n",
            "179/179 [==============================] - 0s 2ms/step - loss: 0.2390 - accuracy: 0.9052\n",
            "[0.23898965120315552, 0.9052207469940186]\n",
            "179/179 [==============================] - 0s 1ms/step\n",
            "[[2627  204]\n",
            " [ 337 2540]]\n",
            "0.9052207428170989\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.93      0.91      2831\n",
            "           1       0.93      0.88      0.90      2877\n",
            "\n",
            "    accuracy                           0.91      5708\n",
            "   macro avg       0.91      0.91      0.91      5708\n",
            "weighted avg       0.91      0.91      0.91      5708\n",
            "\n",
            "Training time: 5.817413330078125e-05\n",
            "Test time: 2.09808349609375e-05\n",
            "\n",
            "TIME: 0.00034332275390625seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeWtgGS7kC6K"
      },
      "source": [
        "# **Centralized ECU-IOHT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WG0t8mAma_Y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZnHAwXykHCF"
      },
      "outputs": [],
      "source": [
        "df_FL1 = pd.read_csv('/content/drive/MyDrive/GlobeCom/clean_ECU.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kreWI_jDLGEw",
        "outputId": "86f9594b-5954-472d-b85f-6b972d834d3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  Time  Source  Destination  Protocol  Length  Type  \\\n",
              "0           0   0.0    67.0         69.0       0.0     0.0     0   \n",
              "1           1   1.0    64.0         68.0       0.0     0.0     0   \n",
              "2           2   2.0    67.0         69.0       0.0     0.0     0   \n",
              "3           3   3.0    45.0         44.0       2.0    23.0     1   \n",
              "4           4   4.0    64.0         68.0       0.0     0.0     0   \n",
              "\n",
              "   Type of attack  \n",
              "0             0.0  \n",
              "1             0.0  \n",
              "2             0.0  \n",
              "3             3.0  \n",
              "4             0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72fa81c3-f40a-4343-9e86-1099f689fdb5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Time</th>\n",
              "      <th>Source</th>\n",
              "      <th>Destination</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Length</th>\n",
              "      <th>Type</th>\n",
              "      <th>Type of attack</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72fa81c3-f40a-4343-9e86-1099f689fdb5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72fa81c3-f40a-4343-9e86-1099f689fdb5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72fa81c3-f40a-4343-9e86-1099f689fdb5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df_FL1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ziim_ysskXUa"
      },
      "outputs": [],
      "source": [
        "drop_columns = ['Unnamed: 0']#, 'Type of attack']\t\t\n",
        "df_FL= df_FL1.drop(columns=drop_columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VT4zw5FyRsB1"
      },
      "outputs": [],
      "source": [
        "count_FL_0, count_FL_1 = df_FL.Type.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NpvtA1uSEYw",
        "outputId": "cf19f406-c87d-4ab6-c2ae-06f464477001"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(87754, 23453)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "count_FL_0, count_FL_1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SFLm9mgO5yV"
      },
      "outputs": [],
      "source": [
        "df_FL_0 = df_FL[df_FL['Type'] == 0]\n",
        "df_FL_1 = df_FL[df_FL['Type'] == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3Eour_7RPF_",
        "outputId": "12cf8f24-b746-4cc6-c14e-b77c94dce74a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(87754, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_FL_0.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBW0fsEhRUnq",
        "outputId": "b4d2f018-717c-4e62-a023-f11cfcee3b61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23453, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df_FL_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k9J37JWT2Yh",
        "outputId": "763e2c28-ec20-48ac-99c3-923649cab4dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random under-sampling:\n",
            "0    23453\n",
            "1    23453\n",
            "Name: Type, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df_FL_0_under = df_FL_0.sample(count_FL_1)\n",
        "df_FL_under = pd.concat([df_FL_0_under, df_FL_1], axis = 0)\n",
        "print('Random under-sampling:')\n",
        "print(df_FL_under.Type.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99F1B_2oc7Lx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWWNuQXkUzwb"
      },
      "outputs": [],
      "source": [
        "X = df_FL_under.drop('Type', axis = 'columns')\n",
        "y = df_FL_under['Type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgUe2_5b_hbA"
      },
      "outputs": [],
      "source": [
        "#X = df_FL.drop('Type', axis = 'columns')\n",
        "#y= df_FL['Type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyhn1zHN6jSu"
      },
      "outputs": [],
      "source": [
        "#from imblearn.over_sampling import SMOTE\n",
        "#X_smote, y_smote = SMOTE().fit_resample(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EruXudWedGLA"
      },
      "outputs": [],
      "source": [
        "#from sklearn.preprocessing import LabelEncoder\n",
        "#encoder = LabelEncoder()\n",
        "#y1 = encoder.fit_transform(y)\n",
        "#Y= pd.get_dummies(y1).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z6XjJn8dMgy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNmNOZQgVJar"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split( X , y, test_size = 0.2, random_state = 1337)#, stratify = Y)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWOvuXQQ6r6g"
      },
      "outputs": [],
      "source": [
        "#from sklearn.model_selection import train_test_split\n",
        "#X_train, X_test, y_train, y_test = train_test_split( X_smote , y_smote, test_size = 0.1, random_state = 1337)#, stratify = Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YFgja4mVsyS"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaling = StandardScaler()\n",
        "X_train = scaling.fit_transform(X_train)\n",
        "X_test = scaling.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtRD4QDr5Ea8"
      },
      "outputs": [],
      "source": [
        "#For CNN and CNN-LSTM\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***LSTM***"
      ],
      "metadata": {
        "id": "wYgcF037uTy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import time\n",
        "import time\n",
        "start = time.time()\n",
        "#from keras.optimizers import SGD\n",
        "#opt = SGD(lr=0.0001)\n",
        "#batch_size = 64\n",
        "\n",
        "# 1. define the network\n",
        "model = Sequential()\n",
        "model.add(LSTM(2,input_shape = X_train[0].shape))  \n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_train, y_train, epochs=100, batch_size = 20, validation_data=(X_test, y_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_test, y_preds_cnn))\n",
        "print(accuracy_score(y_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_preds_cnn))\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIvOARC-owYz",
        "outputId": "9f251a1d-a772-4a88-b766-47b06bf4e721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1877/1877 [==============================] - 11s 4ms/step - loss: 0.3936 - accuracy: 0.7833 - val_loss: 0.2103 - val_accuracy: 0.9341\n",
            "Epoch 2/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3296 - accuracy: 0.8315 - val_loss: 0.1777 - val_accuracy: 0.9449\n",
            "Epoch 3/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3262 - accuracy: 0.8301 - val_loss: 0.1745 - val_accuracy: 0.9449\n",
            "Epoch 4/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3204 - accuracy: 0.8337 - val_loss: 0.1693 - val_accuracy: 0.9449\n",
            "Epoch 5/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3272 - accuracy: 0.8298 - val_loss: 0.1899 - val_accuracy: 0.9450\n",
            "Epoch 6/100\n",
            "1877/1877 [==============================] - 9s 5ms/step - loss: 0.3242 - accuracy: 0.8309 - val_loss: 0.1767 - val_accuracy: 0.9449\n",
            "Epoch 7/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3238 - accuracy: 0.8278 - val_loss: 0.1724 - val_accuracy: 0.9449\n",
            "Epoch 8/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3194 - accuracy: 0.8309 - val_loss: 0.1744 - val_accuracy: 0.9440\n",
            "Epoch 9/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3331 - accuracy: 0.8305 - val_loss: 0.1729 - val_accuracy: 0.9449\n",
            "Epoch 10/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3222 - accuracy: 0.8305 - val_loss: 0.1694 - val_accuracy: 0.9444\n",
            "Epoch 11/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3389 - accuracy: 0.8303 - val_loss: 0.1987 - val_accuracy: 0.9461\n",
            "Epoch 12/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3443 - accuracy: 0.8259 - val_loss: 0.3339 - val_accuracy: 0.9061\n",
            "Epoch 13/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3769 - accuracy: 0.8186 - val_loss: 0.1837 - val_accuracy: 0.9449\n",
            "Epoch 14/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3375 - accuracy: 0.8299 - val_loss: 0.1831 - val_accuracy: 0.9450\n",
            "Epoch 15/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3323 - accuracy: 0.8330 - val_loss: 0.2000 - val_accuracy: 0.9461\n",
            "Epoch 16/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3516 - accuracy: 0.8309 - val_loss: 0.2017 - val_accuracy: 0.9461\n",
            "Epoch 17/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3330 - accuracy: 0.8294 - val_loss: 0.1821 - val_accuracy: 0.9449\n",
            "Epoch 18/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3265 - accuracy: 0.8303 - val_loss: 0.1729 - val_accuracy: 0.9449\n",
            "Epoch 19/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3274 - accuracy: 0.8318 - val_loss: 0.1965 - val_accuracy: 0.9450\n",
            "Epoch 20/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3339 - accuracy: 0.8311 - val_loss: 0.1760 - val_accuracy: 0.9449\n",
            "Epoch 21/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3192 - accuracy: 0.8319 - val_loss: 0.1799 - val_accuracy: 0.9449\n",
            "Epoch 22/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3196 - accuracy: 0.8278 - val_loss: 0.1735 - val_accuracy: 0.9449\n",
            "Epoch 23/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3309 - accuracy: 0.8305 - val_loss: 0.1959 - val_accuracy: 0.9450\n",
            "Epoch 24/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3396 - accuracy: 0.8296 - val_loss: 0.1981 - val_accuracy: 0.9450\n",
            "Epoch 25/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3488 - accuracy: 0.8253 - val_loss: 0.1814 - val_accuracy: 0.9449\n",
            "Epoch 26/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3210 - accuracy: 0.8292 - val_loss: 0.1729 - val_accuracy: 0.9449\n",
            "Epoch 27/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3352 - accuracy: 0.8271 - val_loss: 0.1794 - val_accuracy: 0.9449\n",
            "Epoch 28/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3199 - accuracy: 0.8317 - val_loss: 0.1726 - val_accuracy: 0.9449\n",
            "Epoch 29/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3538 - accuracy: 0.8224 - val_loss: 0.2372 - val_accuracy: 0.9341\n",
            "Epoch 30/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3286 - accuracy: 0.8286 - val_loss: 0.1736 - val_accuracy: 0.9449\n",
            "Epoch 31/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3340 - accuracy: 0.8254 - val_loss: 0.3121 - val_accuracy: 0.9172\n",
            "Epoch 32/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3391 - accuracy: 0.8285 - val_loss: 0.3278 - val_accuracy: 0.9099\n",
            "Epoch 33/100\n",
            "1877/1877 [==============================] - 9s 5ms/step - loss: 0.3286 - accuracy: 0.8270 - val_loss: 0.1688 - val_accuracy: 0.9449\n",
            "Epoch 34/100\n",
            "1877/1877 [==============================] - 9s 5ms/step - loss: 0.3104 - accuracy: 0.8336 - val_loss: 0.1682 - val_accuracy: 0.9449\n",
            "Epoch 35/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3160 - accuracy: 0.8311 - val_loss: 0.1763 - val_accuracy: 0.9449\n",
            "Epoch 36/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3181 - accuracy: 0.8331 - val_loss: 0.1958 - val_accuracy: 0.9450\n",
            "Epoch 37/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3399 - accuracy: 0.8301 - val_loss: 0.1962 - val_accuracy: 0.9450\n",
            "Epoch 38/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3399 - accuracy: 0.8291 - val_loss: 0.1978 - val_accuracy: 0.9451\n",
            "Epoch 39/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3396 - accuracy: 0.8300 - val_loss: 0.1985 - val_accuracy: 0.9450\n",
            "Epoch 40/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3383 - accuracy: 0.8325 - val_loss: 0.1933 - val_accuracy: 0.9461\n",
            "Epoch 41/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3370 - accuracy: 0.8309 - val_loss: 0.1825 - val_accuracy: 0.9450\n",
            "Epoch 42/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3385 - accuracy: 0.8277 - val_loss: 0.2350 - val_accuracy: 0.9341\n",
            "Epoch 43/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3382 - accuracy: 0.8294 - val_loss: 0.1795 - val_accuracy: 0.9450\n",
            "Epoch 44/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3158 - accuracy: 0.8316 - val_loss: 0.1717 - val_accuracy: 0.9449\n",
            "Epoch 45/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3238 - accuracy: 0.8302 - val_loss: 0.1794 - val_accuracy: 0.9449\n",
            "Epoch 46/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3173 - accuracy: 0.8323 - val_loss: 0.1728 - val_accuracy: 0.9449\n",
            "Epoch 47/100\n",
            "1877/1877 [==============================] - 9s 5ms/step - loss: 0.3360 - accuracy: 0.8286 - val_loss: 0.1689 - val_accuracy: 0.9449\n",
            "Epoch 48/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3195 - accuracy: 0.8320 - val_loss: 0.1815 - val_accuracy: 0.9450\n",
            "Epoch 49/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3137 - accuracy: 0.8355 - val_loss: 0.1763 - val_accuracy: 0.9449\n",
            "Epoch 50/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3157 - accuracy: 0.8295 - val_loss: 0.1780 - val_accuracy: 0.9449\n",
            "Epoch 51/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3217 - accuracy: 0.8306 - val_loss: 0.1743 - val_accuracy: 0.9449\n",
            "Epoch 52/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3204 - accuracy: 0.8280 - val_loss: 0.1729 - val_accuracy: 0.9449\n",
            "Epoch 53/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3150 - accuracy: 0.8301 - val_loss: 0.1709 - val_accuracy: 0.9449\n",
            "Epoch 54/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3555 - accuracy: 0.8257 - val_loss: 0.2078 - val_accuracy: 0.9461\n",
            "Epoch 55/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3387 - accuracy: 0.8316 - val_loss: 0.1849 - val_accuracy: 0.9461\n",
            "Epoch 56/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3375 - accuracy: 0.8307 - val_loss: 0.1827 - val_accuracy: 0.9461\n",
            "Epoch 57/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3204 - accuracy: 0.8316 - val_loss: 0.1735 - val_accuracy: 0.9449\n",
            "Epoch 58/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3233 - accuracy: 0.8322 - val_loss: 0.1861 - val_accuracy: 0.9450\n",
            "Epoch 59/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3219 - accuracy: 0.8315 - val_loss: 0.1756 - val_accuracy: 0.9449\n",
            "Epoch 60/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3148 - accuracy: 0.8307 - val_loss: 0.1719 - val_accuracy: 0.9449\n",
            "Epoch 61/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3122 - accuracy: 0.8319 - val_loss: 0.1800 - val_accuracy: 0.9449\n",
            "Epoch 62/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3270 - accuracy: 0.8281 - val_loss: 0.1993 - val_accuracy: 0.9450\n",
            "Epoch 63/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3360 - accuracy: 0.8278 - val_loss: 0.1806 - val_accuracy: 0.9449\n",
            "Epoch 64/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3142 - accuracy: 0.8319 - val_loss: 0.1726 - val_accuracy: 0.9449\n",
            "Epoch 65/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3200 - accuracy: 0.8313 - val_loss: 0.1756 - val_accuracy: 0.9449\n",
            "Epoch 66/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3206 - accuracy: 0.8298 - val_loss: 0.1819 - val_accuracy: 0.9449\n",
            "Epoch 67/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3222 - accuracy: 0.8290 - val_loss: 0.1828 - val_accuracy: 0.9450\n",
            "Epoch 68/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3195 - accuracy: 0.8273 - val_loss: 0.1746 - val_accuracy: 0.9449\n",
            "Epoch 69/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3114 - accuracy: 0.8324 - val_loss: 0.1729 - val_accuracy: 0.9449\n",
            "Epoch 70/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3201 - accuracy: 0.8307 - val_loss: 0.2080 - val_accuracy: 0.9379\n",
            "Epoch 71/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3271 - accuracy: 0.8278 - val_loss: 0.1772 - val_accuracy: 0.9449\n",
            "Epoch 72/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3230 - accuracy: 0.8282 - val_loss: 0.1806 - val_accuracy: 0.9449\n",
            "Epoch 73/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3188 - accuracy: 0.8302 - val_loss: 0.1826 - val_accuracy: 0.9449\n",
            "Epoch 74/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3350 - accuracy: 0.8327 - val_loss: 0.1878 - val_accuracy: 0.9461\n",
            "Epoch 75/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3376 - accuracy: 0.8301 - val_loss: 0.1904 - val_accuracy: 0.9462\n",
            "Epoch 76/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3353 - accuracy: 0.8329 - val_loss: 0.1874 - val_accuracy: 0.9461\n",
            "Epoch 77/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3372 - accuracy: 0.8293 - val_loss: 0.1709 - val_accuracy: 0.9449\n",
            "Epoch 78/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3146 - accuracy: 0.8307 - val_loss: 0.1708 - val_accuracy: 0.9449\n",
            "Epoch 79/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3112 - accuracy: 0.8334 - val_loss: 0.2392 - val_accuracy: 0.9332\n",
            "Epoch 80/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3266 - accuracy: 0.8286 - val_loss: 0.1810 - val_accuracy: 0.9449\n",
            "Epoch 81/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3187 - accuracy: 0.8307 - val_loss: 0.1758 - val_accuracy: 0.9449\n",
            "Epoch 82/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3191 - accuracy: 0.8314 - val_loss: 0.1696 - val_accuracy: 0.9449\n",
            "Epoch 83/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3089 - accuracy: 0.8310 - val_loss: 0.1658 - val_accuracy: 0.9449\n",
            "Epoch 84/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3066 - accuracy: 0.8333 - val_loss: 0.1663 - val_accuracy: 0.9449\n",
            "Epoch 85/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3090 - accuracy: 0.8308 - val_loss: 0.1811 - val_accuracy: 0.9449\n",
            "Epoch 86/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3067 - accuracy: 0.8315 - val_loss: 0.1689 - val_accuracy: 0.9449\n",
            "Epoch 87/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3076 - accuracy: 0.8276 - val_loss: 0.1639 - val_accuracy: 0.9449\n",
            "Epoch 88/100\n",
            "1877/1877 [==============================] - 9s 5ms/step - loss: 0.3136 - accuracy: 0.8302 - val_loss: 0.1682 - val_accuracy: 0.9449\n",
            "Epoch 89/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3090 - accuracy: 0.8305 - val_loss: 0.1648 - val_accuracy: 0.9449\n",
            "Epoch 90/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3060 - accuracy: 0.8302 - val_loss: 0.1614 - val_accuracy: 0.9449\n",
            "Epoch 91/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3090 - accuracy: 0.8306 - val_loss: 0.1679 - val_accuracy: 0.9449\n",
            "Epoch 92/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3045 - accuracy: 0.8314 - val_loss: 0.1633 - val_accuracy: 0.9449\n",
            "Epoch 93/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3114 - accuracy: 0.8320 - val_loss: 0.1666 - val_accuracy: 0.9449\n",
            "Epoch 94/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3062 - accuracy: 0.8309 - val_loss: 0.1596 - val_accuracy: 0.9449\n",
            "Epoch 95/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3051 - accuracy: 0.8303 - val_loss: 0.1627 - val_accuracy: 0.9449\n",
            "Epoch 96/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3067 - accuracy: 0.8282 - val_loss: 0.1688 - val_accuracy: 0.9449\n",
            "Epoch 97/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3084 - accuracy: 0.8297 - val_loss: 0.1666 - val_accuracy: 0.9449\n",
            "Epoch 98/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.3063 - accuracy: 0.8300 - val_loss: 0.1591 - val_accuracy: 0.9449\n",
            "Epoch 99/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3119 - accuracy: 0.8286 - val_loss: 0.1617 - val_accuracy: 0.9449\n",
            "Epoch 100/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.3035 - accuracy: 0.8325 - val_loss: 0.1581 - val_accuracy: 0.9449\n",
            "294/294 [==============================] - 1s 2ms/step - loss: 0.1581 - accuracy: 0.9449\n",
            "[0.15810884535312653, 0.9448944926261902]\n",
            "294/294 [==============================] - 1s 2ms/step\n",
            "[[4108  517]\n",
            " [   0 4757]]\n",
            "0.9448944787891708\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      4625\n",
            "           1       0.90      1.00      0.95      4757\n",
            "\n",
            "    accuracy                           0.94      9382\n",
            "   macro avg       0.95      0.94      0.94      9382\n",
            "weighted avg       0.95      0.94      0.94      9382\n",
            "\n",
            "Training time: 6.4849853515625e-05\n",
            "Test time: 2.384185791015625e-05\n",
            "\n",
            "TIME: 0.001161336898803711seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***CNN-LSTM***"
      ],
      "metadata": {
        "id": "TBo7SeafEmtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###############LSTM###################################\n",
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda\n",
        "\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, Dense, Dropout, Flatten, MaxPooling1D\n",
        "\n",
        "from keras.layers import LSTM, GRU, SimpleRNN\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "lstm_output_size = 20\n",
        "model = Sequential()\n",
        "model.add(Conv1D(32, 2, activation='relu', input_shape = X_train[0].shape))\n",
        "\n",
        "model.add(SimpleRNN(lstm_output_size))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_train, y_train, epochs=100, batch_size = 1024, validation_data=(X_test, y_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_test, y_preds_cnn))\n",
        "print(accuracy_score(y_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_preds_cnn))\n",
        "\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl371JwBEmAj",
        "outputId": "42307a79-5bc3-4fc6-f06d-ecedea1d8304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1877/1877 [==============================] - 9s 4ms/step - loss: 0.9214 - accuracy: 0.7041 - val_loss: 0.1800 - val_accuracy: 0.9472\n",
            "Epoch 2/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.3850 - accuracy: 0.8930 - val_loss: 0.4562 - val_accuracy: 0.5875\n",
            "Epoch 3/100\n",
            "1877/1877 [==============================] - 7s 3ms/step - loss: 0.4968 - accuracy: 0.8921 - val_loss: 0.5126 - val_accuracy: 0.9472\n",
            "Epoch 4/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5201 - accuracy: 0.8925 - val_loss: 1.6174 - val_accuracy: 0.6251\n",
            "Epoch 5/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5856 - accuracy: 0.8912 - val_loss: 0.3306 - val_accuracy: 0.9472\n",
            "Epoch 6/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5799 - accuracy: 0.8914 - val_loss: 0.4243 - val_accuracy: 0.9472\n",
            "Epoch 7/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.4972 - accuracy: 0.8940 - val_loss: 1.1143 - val_accuracy: 0.6251\n",
            "Epoch 8/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.6348 - accuracy: 0.8897 - val_loss: 0.1791 - val_accuracy: 0.9472\n",
            "Epoch 9/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.6374 - accuracy: 0.8895 - val_loss: 0.5920 - val_accuracy: 0.9472\n",
            "Epoch 10/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5736 - accuracy: 0.8929 - val_loss: 0.9762 - val_accuracy: 0.5070\n",
            "Epoch 11/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5533 - accuracy: 0.8922 - val_loss: 0.2943 - val_accuracy: 0.9472\n",
            "Epoch 12/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.6207 - accuracy: 0.8912 - val_loss: 0.5657 - val_accuracy: 0.9472\n",
            "Epoch 13/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5647 - accuracy: 0.8926 - val_loss: 0.3422 - val_accuracy: 0.6251\n",
            "Epoch 14/100\n",
            "1877/1877 [==============================] - 7s 3ms/step - loss: 0.5506 - accuracy: 0.8921 - val_loss: 0.1924 - val_accuracy: 0.9472\n",
            "Epoch 15/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5193 - accuracy: 0.8929 - val_loss: 0.1953 - val_accuracy: 0.9472\n",
            "Epoch 16/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5271 - accuracy: 0.8945 - val_loss: 0.5515 - val_accuracy: 0.6251\n",
            "Epoch 17/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5321 - accuracy: 0.8924 - val_loss: 0.3886 - val_accuracy: 0.9472\n",
            "Epoch 18/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5851 - accuracy: 0.8905 - val_loss: 0.1710 - val_accuracy: 0.9472\n",
            "Epoch 19/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5449 - accuracy: 0.8920 - val_loss: 0.4039 - val_accuracy: 0.9472\n",
            "Epoch 20/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5772 - accuracy: 0.8911 - val_loss: 0.2776 - val_accuracy: 0.9472\n",
            "Epoch 21/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5377 - accuracy: 0.8940 - val_loss: 0.1997 - val_accuracy: 0.9472\n",
            "Epoch 22/100\n",
            "1877/1877 [==============================] - 7s 3ms/step - loss: 0.6105 - accuracy: 0.8893 - val_loss: 0.6115 - val_accuracy: 0.9472\n",
            "Epoch 23/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5657 - accuracy: 0.8940 - val_loss: 0.1728 - val_accuracy: 0.9472\n",
            "Epoch 24/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5764 - accuracy: 0.8930 - val_loss: 0.1781 - val_accuracy: 0.9472\n",
            "Epoch 25/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5396 - accuracy: 0.8923 - val_loss: 0.6784 - val_accuracy: 0.6251\n",
            "Epoch 26/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5538 - accuracy: 0.8922 - val_loss: 0.1812 - val_accuracy: 0.9472\n",
            "Epoch 27/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5455 - accuracy: 0.8932 - val_loss: 0.2989 - val_accuracy: 0.9472\n",
            "Epoch 28/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5222 - accuracy: 0.8924 - val_loss: 0.1804 - val_accuracy: 0.9472\n",
            "Epoch 29/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.6045 - accuracy: 0.8908 - val_loss: 0.7250 - val_accuracy: 0.9472\n",
            "Epoch 30/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.6008 - accuracy: 0.8915 - val_loss: 0.2656 - val_accuracy: 0.9472\n",
            "Epoch 31/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5320 - accuracy: 0.8941 - val_loss: 1.4613 - val_accuracy: 0.9472\n",
            "Epoch 32/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.6074 - accuracy: 0.8921 - val_loss: 0.2768 - val_accuracy: 0.9472\n",
            "Epoch 33/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5492 - accuracy: 0.8934 - val_loss: 0.1808 - val_accuracy: 0.9472\n",
            "Epoch 34/100\n",
            "1877/1877 [==============================] - 7s 3ms/step - loss: 0.5848 - accuracy: 0.8924 - val_loss: 0.6233 - val_accuracy: 0.9472\n",
            "Epoch 35/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5522 - accuracy: 0.8920 - val_loss: 0.3049 - val_accuracy: 0.9472\n",
            "Epoch 36/100\n",
            "1877/1877 [==============================] - 7s 3ms/step - loss: 0.5063 - accuracy: 0.8949 - val_loss: 0.5667 - val_accuracy: 0.9472\n",
            "Epoch 37/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5639 - accuracy: 0.8934 - val_loss: 0.5676 - val_accuracy: 0.9472\n",
            "Epoch 38/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.6006 - accuracy: 0.8893 - val_loss: 0.5181 - val_accuracy: 0.6251\n",
            "Epoch 39/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5519 - accuracy: 0.8934 - val_loss: 0.1852 - val_accuracy: 0.9472\n",
            "Epoch 40/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.6108 - accuracy: 0.8903 - val_loss: 0.5503 - val_accuracy: 0.9472\n",
            "Epoch 41/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.6096 - accuracy: 0.8914 - val_loss: 0.2038 - val_accuracy: 0.9472\n",
            "Epoch 42/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5815 - accuracy: 0.8916 - val_loss: 0.1846 - val_accuracy: 0.9472\n",
            "Epoch 43/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5612 - accuracy: 0.8941 - val_loss: 0.4690 - val_accuracy: 0.6251\n",
            "Epoch 44/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5252 - accuracy: 0.8940 - val_loss: 0.2921 - val_accuracy: 0.9472\n",
            "Epoch 45/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5362 - accuracy: 0.8940 - val_loss: 0.2363 - val_accuracy: 0.9472\n",
            "Epoch 46/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5800 - accuracy: 0.8907 - val_loss: 1.8994 - val_accuracy: 0.5070\n",
            "Epoch 47/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5395 - accuracy: 0.8935 - val_loss: 0.2267 - val_accuracy: 0.9472\n",
            "Epoch 48/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.6093 - accuracy: 0.8899 - val_loss: 0.3901 - val_accuracy: 0.9472\n",
            "Epoch 49/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5604 - accuracy: 0.8939 - val_loss: 0.1753 - val_accuracy: 0.9472\n",
            "Epoch 50/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5976 - accuracy: 0.8905 - val_loss: 2.2669 - val_accuracy: 0.4930\n",
            "Epoch 51/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5694 - accuracy: 0.8920 - val_loss: 0.1822 - val_accuracy: 0.9472\n",
            "Epoch 52/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5584 - accuracy: 0.8935 - val_loss: 0.5648 - val_accuracy: 0.9472\n",
            "Epoch 53/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.6278 - accuracy: 0.8911 - val_loss: 0.3071 - val_accuracy: 0.9472\n",
            "Epoch 54/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5374 - accuracy: 0.8919 - val_loss: 0.6357 - val_accuracy: 0.9472\n",
            "Epoch 55/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5234 - accuracy: 0.8917 - val_loss: 0.1905 - val_accuracy: 0.9472\n",
            "Epoch 56/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5387 - accuracy: 0.8927 - val_loss: 0.1762 - val_accuracy: 0.9472\n",
            "Epoch 57/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.6128 - accuracy: 0.8907 - val_loss: 0.4096 - val_accuracy: 0.9472\n",
            "Epoch 58/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5875 - accuracy: 0.8933 - val_loss: 0.3662 - val_accuracy: 0.9472\n",
            "Epoch 59/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5811 - accuracy: 0.8921 - val_loss: 0.9318 - val_accuracy: 0.9472\n",
            "Epoch 60/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5553 - accuracy: 0.8909 - val_loss: 0.1706 - val_accuracy: 0.9472\n",
            "Epoch 61/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5461 - accuracy: 0.8923 - val_loss: 0.2484 - val_accuracy: 0.9472\n",
            "Epoch 62/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5403 - accuracy: 0.8934 - val_loss: 0.5622 - val_accuracy: 0.9472\n",
            "Epoch 63/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.6377 - accuracy: 0.8904 - val_loss: 0.9384 - val_accuracy: 0.9472\n",
            "Epoch 64/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5601 - accuracy: 0.8914 - val_loss: 0.1733 - val_accuracy: 0.9472\n",
            "Epoch 65/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5386 - accuracy: 0.8933 - val_loss: 0.3982 - val_accuracy: 0.9472\n",
            "Epoch 66/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5597 - accuracy: 0.8936 - val_loss: 0.4865 - val_accuracy: 0.9472\n",
            "Epoch 67/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5570 - accuracy: 0.8919 - val_loss: 0.5577 - val_accuracy: 0.6251\n",
            "Epoch 68/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.5556 - accuracy: 0.8926 - val_loss: 0.2798 - val_accuracy: 0.9472\n",
            "Epoch 69/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5506 - accuracy: 0.8914 - val_loss: 0.3181 - val_accuracy: 0.9472\n",
            "Epoch 70/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.6365 - accuracy: 0.8911 - val_loss: 0.1918 - val_accuracy: 0.9472\n",
            "Epoch 71/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5453 - accuracy: 0.8931 - val_loss: 0.4107 - val_accuracy: 0.9472\n",
            "Epoch 72/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5726 - accuracy: 0.8931 - val_loss: 0.2868 - val_accuracy: 0.9472\n",
            "Epoch 73/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5519 - accuracy: 0.8939 - val_loss: 0.4702 - val_accuracy: 0.9472\n",
            "Epoch 74/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.6234 - accuracy: 0.8902 - val_loss: 1.1849 - val_accuracy: 0.9472\n",
            "Epoch 75/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.6106 - accuracy: 0.8922 - val_loss: 0.5961 - val_accuracy: 0.9472\n",
            "Epoch 76/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5877 - accuracy: 0.8928 - val_loss: 0.2802 - val_accuracy: 0.9472\n",
            "Epoch 77/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5371 - accuracy: 0.8939 - val_loss: 0.5106 - val_accuracy: 0.6251\n",
            "Epoch 78/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5322 - accuracy: 0.8907 - val_loss: 0.3465 - val_accuracy: 0.9472\n",
            "Epoch 79/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5640 - accuracy: 0.8902 - val_loss: 0.4293 - val_accuracy: 0.9472\n",
            "Epoch 80/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5813 - accuracy: 0.8928 - val_loss: 1.0981 - val_accuracy: 0.9472\n",
            "Epoch 81/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5582 - accuracy: 0.8923 - val_loss: 0.3522 - val_accuracy: 0.9472\n",
            "Epoch 82/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.6288 - accuracy: 0.8910 - val_loss: 1.0019 - val_accuracy: 0.6251\n",
            "Epoch 83/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5337 - accuracy: 0.8904 - val_loss: 0.9176 - val_accuracy: 0.6251\n",
            "Epoch 84/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5665 - accuracy: 0.8909 - val_loss: 0.4195 - val_accuracy: 0.9472\n",
            "Epoch 85/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5308 - accuracy: 0.8927 - val_loss: 0.5545 - val_accuracy: 0.9472\n",
            "Epoch 86/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5660 - accuracy: 0.8929 - val_loss: 0.2443 - val_accuracy: 0.9472\n",
            "Epoch 87/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5902 - accuracy: 0.8928 - val_loss: 0.6120 - val_accuracy: 0.9472\n",
            "Epoch 88/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.4998 - accuracy: 0.8940 - val_loss: 0.5762 - val_accuracy: 0.9472\n",
            "Epoch 89/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5859 - accuracy: 0.8940 - val_loss: 0.3933 - val_accuracy: 0.9472\n",
            "Epoch 90/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.6188 - accuracy: 0.8911 - val_loss: 0.2786 - val_accuracy: 0.9472\n",
            "Epoch 91/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5728 - accuracy: 0.8904 - val_loss: 0.3666 - val_accuracy: 0.9472\n",
            "Epoch 92/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5619 - accuracy: 0.8911 - val_loss: 0.4574 - val_accuracy: 0.9472\n",
            "Epoch 93/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5595 - accuracy: 0.8928 - val_loss: 0.1868 - val_accuracy: 0.9472\n",
            "Epoch 94/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5943 - accuracy: 0.8931 - val_loss: 0.1892 - val_accuracy: 0.9472\n",
            "Epoch 95/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5597 - accuracy: 0.8925 - val_loss: 0.2448 - val_accuracy: 0.9472\n",
            "Epoch 96/100\n",
            "1877/1877 [==============================] - 8s 4ms/step - loss: 0.6219 - accuracy: 0.8898 - val_loss: 0.1696 - val_accuracy: 0.9472\n",
            "Epoch 97/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5847 - accuracy: 0.8907 - val_loss: 0.3454 - val_accuracy: 0.9472\n",
            "Epoch 98/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5589 - accuracy: 0.8914 - val_loss: 0.3205 - val_accuracy: 0.9472\n",
            "Epoch 99/100\n",
            "1877/1877 [==============================] - 6s 3ms/step - loss: 0.5540 - accuracy: 0.8920 - val_loss: 0.4914 - val_accuracy: 0.9472\n",
            "Epoch 100/100\n",
            "1877/1877 [==============================] - 7s 4ms/step - loss: 0.5345 - accuracy: 0.8928 - val_loss: 0.2706 - val_accuracy: 0.9472\n",
            "294/294 [==============================] - 1s 2ms/step - loss: 0.2706 - accuracy: 0.9472\n",
            "[0.2706160843372345, 0.9472393989562988]\n",
            "294/294 [==============================] - 1s 2ms/step\n",
            "[[4130  495]\n",
            " [   0 4757]]\n",
            "0.9472393945853762\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      4625\n",
            "           1       0.91      1.00      0.95      4757\n",
            "\n",
            "    accuracy                           0.95      9382\n",
            "   macro avg       0.95      0.95      0.95      9382\n",
            "weighted avg       0.95      0.95      0.95      9382\n",
            "\n",
            "Training time: 6.341934204101562e-05\n",
            "Test time: 2.3126602172851562e-05\n",
            "\n",
            "TIME: 0.0003581047058105469seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DNN**"
      ],
      "metadata": {
        "id": "oRjh2qoky5gN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1s8tki09nL8Q",
        "outputId": "d97d20d2-84c8-49c4-a158-d26f9bc6e9f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1877/1877 [==============================] - 8s 3ms/step - loss: 0.2229 - accuracy: 0.9926 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
            "Epoch 2/50\n",
            "1877/1877 [==============================] - 5s 3ms/step - loss: 0.0949 - accuracy: 0.9801 - val_loss: 0.1464 - val_accuracy: 0.9456\n",
            "Epoch 3/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1138 - accuracy: 0.9432 - val_loss: 0.1115 - val_accuracy: 0.9456\n",
            "Epoch 4/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1063 - accuracy: 0.9432 - val_loss: 0.1051 - val_accuracy: 0.9456\n",
            "Epoch 5/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1062 - accuracy: 0.9429 - val_loss: 0.1080 - val_accuracy: 0.9456\n",
            "Epoch 6/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1065 - accuracy: 0.9432 - val_loss: 0.1060 - val_accuracy: 0.9456\n",
            "Epoch 7/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1066 - accuracy: 0.9432 - val_loss: 0.1072 - val_accuracy: 0.9456\n",
            "Epoch 8/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1066 - accuracy: 0.9432 - val_loss: 0.1055 - val_accuracy: 0.9456\n",
            "Epoch 9/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1064 - accuracy: 0.9429 - val_loss: 0.1052 - val_accuracy: 0.9456\n",
            "Epoch 10/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1064 - accuracy: 0.9432 - val_loss: 0.1055 - val_accuracy: 0.9456\n",
            "Epoch 11/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1064 - accuracy: 0.9429 - val_loss: 0.1057 - val_accuracy: 0.9456\n",
            "Epoch 12/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1065 - accuracy: 0.9432 - val_loss: 0.1054 - val_accuracy: 0.9456\n",
            "Epoch 13/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1065 - accuracy: 0.9432 - val_loss: 0.1051 - val_accuracy: 0.9456\n",
            "Epoch 14/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1066 - accuracy: 0.9430 - val_loss: 0.1058 - val_accuracy: 0.9456\n",
            "Epoch 15/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1068 - accuracy: 0.9430 - val_loss: 0.1054 - val_accuracy: 0.9456\n",
            "Epoch 16/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1059 - accuracy: 0.9431 - val_loss: 13.4849 - val_accuracy: 0.9619\n",
            "Epoch 17/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.2851 - accuracy: 0.9427 - val_loss: 0.1790 - val_accuracy: 0.9456\n",
            "Epoch 18/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1845 - accuracy: 0.9432 - val_loss: 0.1792 - val_accuracy: 0.9456\n",
            "Epoch 19/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1845 - accuracy: 0.9432 - val_loss: 0.1806 - val_accuracy: 0.9456\n",
            "Epoch 20/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1847 - accuracy: 0.9432 - val_loss: 0.1787 - val_accuracy: 0.9456\n",
            "Epoch 21/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1847 - accuracy: 0.9432 - val_loss: 0.1786 - val_accuracy: 0.9456\n",
            "Epoch 22/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1845 - accuracy: 0.9432 - val_loss: 0.1818 - val_accuracy: 0.9456\n",
            "Epoch 23/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1844 - accuracy: 0.9432 - val_loss: 0.1787 - val_accuracy: 0.9456\n",
            "Epoch 24/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1848 - accuracy: 0.9432 - val_loss: 0.1790 - val_accuracy: 0.9456\n",
            "Epoch 25/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1846 - accuracy: 0.9432 - val_loss: 0.1786 - val_accuracy: 0.9456\n",
            "Epoch 26/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1852 - accuracy: 0.9432 - val_loss: 0.1793 - val_accuracy: 0.9456\n",
            "Epoch 27/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1846 - accuracy: 0.9432 - val_loss: 0.1788 - val_accuracy: 0.9456\n",
            "Epoch 28/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1843 - accuracy: 0.9432 - val_loss: 0.1841 - val_accuracy: 0.9456\n",
            "Epoch 29/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1850 - accuracy: 0.9432 - val_loss: 0.1800 - val_accuracy: 0.9456\n",
            "Epoch 30/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1846 - accuracy: 0.9432 - val_loss: 0.1792 - val_accuracy: 0.9456\n",
            "Epoch 31/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1848 - accuracy: 0.9432 - val_loss: 0.1793 - val_accuracy: 0.9456\n",
            "Epoch 32/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1845 - accuracy: 0.9432 - val_loss: 0.1815 - val_accuracy: 0.9456\n",
            "Epoch 33/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1846 - accuracy: 0.9432 - val_loss: 0.1786 - val_accuracy: 0.9456\n",
            "Epoch 34/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1847 - accuracy: 0.9432 - val_loss: 0.1787 - val_accuracy: 0.9456\n",
            "Epoch 35/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1846 - accuracy: 0.9432 - val_loss: 0.1795 - val_accuracy: 0.9456\n",
            "Epoch 36/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1845 - accuracy: 0.9432 - val_loss: 0.1787 - val_accuracy: 0.9456\n",
            "Epoch 37/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1847 - accuracy: 0.9432 - val_loss: 0.1799 - val_accuracy: 0.9456\n",
            "Epoch 38/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1847 - accuracy: 0.9432 - val_loss: 0.1794 - val_accuracy: 0.9456\n",
            "Epoch 39/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1846 - accuracy: 0.9432 - val_loss: 0.1801 - val_accuracy: 0.9456\n",
            "Epoch 40/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1851 - accuracy: 0.9432 - val_loss: 0.1798 - val_accuracy: 0.9456\n",
            "Epoch 41/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1846 - accuracy: 0.9432 - val_loss: 0.1787 - val_accuracy: 0.9456\n",
            "Epoch 42/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1845 - accuracy: 0.9432 - val_loss: 0.1791 - val_accuracy: 0.9456\n",
            "Epoch 43/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1845 - accuracy: 0.9432 - val_loss: 0.1786 - val_accuracy: 0.9456\n",
            "Epoch 44/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1847 - accuracy: 0.9432 - val_loss: 0.1786 - val_accuracy: 0.9456\n",
            "Epoch 45/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1846 - accuracy: 0.9432 - val_loss: 0.1790 - val_accuracy: 0.9456\n",
            "Epoch 46/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1844 - accuracy: 0.9432 - val_loss: 0.1824 - val_accuracy: 0.9456\n",
            "Epoch 47/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1845 - accuracy: 0.9432 - val_loss: 0.1797 - val_accuracy: 0.9456\n",
            "Epoch 48/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1846 - accuracy: 0.9432 - val_loss: 0.1803 - val_accuracy: 0.9456\n",
            "Epoch 49/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1848 - accuracy: 0.9432 - val_loss: 0.1789 - val_accuracy: 0.9456\n",
            "Epoch 50/50\n",
            "1877/1877 [==============================] - 4s 2ms/step - loss: 0.1847 - accuracy: 0.9432 - val_loss: 0.1788 - val_accuracy: 0.9456\n",
            "294/294 [==============================] - 0s 1ms/step - loss: 0.1788 - accuracy: 0.9456\n",
            "[0.17883165180683136, 0.9456405639648438]\n",
            "[[4115  510]\n",
            " [   0 4757]]\n",
            "0.9456405883606906\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      4625\n",
            "           1       0.90      1.00      0.95      4757\n",
            "\n",
            "    accuracy                           0.95      9382\n",
            "   macro avg       0.95      0.94      0.95      9382\n",
            "weighted avg       0.95      0.95      0.95      9382\n",
            "\n",
            "Training time: 4.172325134277344e-05\n",
            "Test time: 4.482269287109375e-05\n",
            "\n",
            "TIME: 0.0003063678741455078seconds\n"
          ]
        }
      ],
      "source": [
        "#from keras.layers import LSTM, SimpleRNN, GRU\n",
        "#from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "# 1. define the network\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(6,)),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_train, y_train, epochs=50, batch_size = 20, validation_data=(X_test, y_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_test, y_preds_cnn))\n",
        "print(accuracy_score(y_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_preds_cnn))\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***ICU-Dataset-2021 centralized***"
      ],
      "metadata": {
        "id": "sHDsXg7fZMe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_ICU_ENV = pd.read_csv('/content/drive/MyDrive/ICU-Patient/clean_ICU.csv')\n",
        "df_ICU_ENV.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Knz7n3UaeNU",
        "outputId": "0541b3a8-f469-41db-b4d3-3f227554bcca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(188694, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ICU_ENV.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "msRR8jhKamxA",
        "outputId": "719be0ea-a348-4478-fa62-567270363043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  frame.time_delta  tcp.time_delta  tcp.flags.ack  \\\n",
              "0           0          0.000000        0.000000              1   \n",
              "1           1          0.000053        0.000053              1   \n",
              "2           2          0.000043        0.000000              1   \n",
              "3           3          0.000020        0.000020              1   \n",
              "4           4          0.000016        0.000000              1   \n",
              "\n",
              "   tcp.flags.push  tcp.flags.reset  mqtt.hdrflags  mqtt.msgtype  mqtt.qos  \\\n",
              "0               1                0              1           1.0       0.0   \n",
              "1               1                0              2           2.0       0.0   \n",
              "2               1                0              1           1.0       0.0   \n",
              "3               1                0              2           2.0       0.0   \n",
              "4               1                0              1           1.0       0.0   \n",
              "\n",
              "   mqtt.retain  mqtt.ver  label  \n",
              "0          0.0       4.0      0  \n",
              "1          0.0       0.0      0  \n",
              "2          0.0       4.0      0  \n",
              "3          0.0       0.0      0  \n",
              "4          0.0       4.0      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f1e0ed6-44c3-41b5-848d-27b277f93941\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>frame.time_delta</th>\n",
              "      <th>tcp.time_delta</th>\n",
              "      <th>tcp.flags.ack</th>\n",
              "      <th>tcp.flags.push</th>\n",
              "      <th>tcp.flags.reset</th>\n",
              "      <th>mqtt.hdrflags</th>\n",
              "      <th>mqtt.msgtype</th>\n",
              "      <th>mqtt.qos</th>\n",
              "      <th>mqtt.retain</th>\n",
              "      <th>mqtt.ver</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f1e0ed6-44c3-41b5-848d-27b277f93941')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f1e0ed6-44c3-41b5-848d-27b277f93941 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f1e0ed6-44c3-41b5-848d-27b277f93941');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ICU_ENV.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBIoCKGRaxbY",
        "outputId": "a277645a-e4a7-4e56-ece3-b7429af1326e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 188694 entries, 0 to 188693\n",
            "Data columns (total 12 columns):\n",
            " #   Column            Non-Null Count   Dtype  \n",
            "---  ------            --------------   -----  \n",
            " 0   Unnamed: 0        188694 non-null  int64  \n",
            " 1   frame.time_delta  188694 non-null  float64\n",
            " 2   tcp.time_delta    188694 non-null  float64\n",
            " 3   tcp.flags.ack     188694 non-null  int64  \n",
            " 4   tcp.flags.push    188694 non-null  int64  \n",
            " 5   tcp.flags.reset   188694 non-null  int64  \n",
            " 6   mqtt.hdrflags     188694 non-null  int64  \n",
            " 7   mqtt.msgtype      188694 non-null  float64\n",
            " 8   mqtt.qos          188694 non-null  float64\n",
            " 9   mqtt.retain       188694 non-null  float64\n",
            " 10  mqtt.ver          188694 non-null  float64\n",
            " 11  label             188694 non-null  int64  \n",
            "dtypes: float64(6), int64(6)\n",
            "memory usage: 17.3 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_ICU_ENV.drop('label', axis = 1)\n",
        "y = df_ICU_ENV['label']\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTxq5RSaa7Rt",
        "outputId": "6eab828f-1544-4445-ec14-d865895205fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((188694, 11), (188694,))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(sampling_strategy = 'minority')\n",
        "X_smote, y_smote = smote.fit_resample(X,y)\n",
        "\n",
        "#oversample = SMOTE()\n",
        "#X, y = oversample.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "TcqDTJG6oJbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaling = StandardScaler()\n",
        "X_train = scaling.fit_transform(X_train)\n",
        "X_test = scaling.transform(X_test)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
      ],
      "metadata": {
        "id": "lYbths65oUC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import NearMiss\n",
        "# define the undersampling method\n",
        "undersample = NearMiss(version=1, n_neighbors=2)\n",
        "# transform the dataset\n",
        "X, y = undersample.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "RbdoxLNLbCeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaling = StandardScaler()\n",
        "X_train = scaling.fit_transform(X_train)\n",
        "X_test = scaling.transform(X_test)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
      ],
      "metadata": {
        "id": "0Eh_5nc1bRGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***LSTM***"
      ],
      "metadata": {
        "id": "Q5Obd_6ybbmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import time\n",
        "import time\n",
        "start = time.time()\n",
        "#from keras.optimizers import SGD\n",
        "#opt = SGD(lr=0.0001)\n",
        "#batch_size = 64\n",
        "\n",
        "# 1. define the network\n",
        "model = Sequential()\n",
        "model.add(LSTM(4,input_shape = X_train[0].shape))  \n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size = 1024, validation_data=(X_test, y_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_test)\n",
        "y_preds_cnn1 = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_test, y_preds_cnn1)\n",
        "print(confusion_matrix(y_test, y_preds_cnn1))\n",
        "print(accuracy_score(y_test, y_preds_cnn1))\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_preds_cnn1))\n",
        "\n",
        "print('Summary of the results after each epoch')\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Cross-Validation'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Cross-Validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B-0A3kWhbX0E",
        "outputId": "44588487-560f-45b0-bba9-b5139c972890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126/126 [==============================] - 7s 26ms/step - loss: 0.4093 - accuracy: 0.8055 - val_loss: 0.0585 - val_accuracy: 0.9962\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0967 - accuracy: 0.9631 - val_loss: 0.0068 - val_accuracy: 0.9990\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0673 - accuracy: 0.9681 - val_loss: 0.0029 - val_accuracy: 0.9993\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0618 - accuracy: 0.9688 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0598 - accuracy: 0.9682 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0580 - accuracy: 0.9682 - val_loss: 7.1593e-04 - val_accuracy: 0.9998\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0557 - accuracy: 0.9697 - val_loss: 2.3410e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0552 - accuracy: 0.9692 - val_loss: 1.0983e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 1s 12ms/step - loss: 0.0561 - accuracy: 0.9680 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0558 - accuracy: 0.9681 - val_loss: 7.4994e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0540 - accuracy: 0.9695 - val_loss: 4.8727e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0563 - accuracy: 0.9675 - val_loss: 6.8579e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0551 - accuracy: 0.9691 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
            "Epoch 14/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0498 - accuracy: 0.9681 - val_loss: 1.1502e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0500 - accuracy: 0.9680 - val_loss: 0.0029 - val_accuracy: 0.9993\n",
            "Epoch 16/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0488 - accuracy: 0.9676 - val_loss: 2.5776e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0462 - accuracy: 0.9697 - val_loss: 1.2152e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0476 - accuracy: 0.9683 - val_loss: 3.9874e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0479 - accuracy: 0.9674 - val_loss: 2.4422e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.0464 - accuracy: 0.9681 - val_loss: 2.4912e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0466 - accuracy: 0.9681 - val_loss: 2.5297e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0466 - accuracy: 0.9667 - val_loss: 1.4852e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0464 - accuracy: 0.9667 - val_loss: 3.7757e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0463 - accuracy: 0.9663 - val_loss: 7.1544e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "126/126 [==============================] - 2s 13ms/step - loss: 0.0462 - accuracy: 0.9664 - val_loss: 6.9675e-06 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 0.0453 - accuracy: 0.9679 - val_loss: 1.6646e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "126/126 [==============================] - 2s 15ms/step - loss: 0.0457 - accuracy: 0.9672 - val_loss: 4.8039e-06 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0442 - accuracy: 0.9686 - val_loss: 2.4135e-06 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0439 - accuracy: 0.9682 - val_loss: 2.4380e-06 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0454 - accuracy: 0.9672 - val_loss: 1.0095e-05 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0448 - accuracy: 0.9675 - val_loss: 9.9361e-05 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0442 - accuracy: 0.9682 - val_loss: 5.3090e-06 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0444 - accuracy: 0.9676 - val_loss: 2.2484e-06 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0438 - accuracy: 0.9690 - val_loss: 3.5718e-06 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0443 - accuracy: 0.9684 - val_loss: 7.6493e-04 - val_accuracy: 0.9999\n",
            "Epoch 36/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0444 - accuracy: 0.9677 - val_loss: 1.2961e-06 - val_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0442 - accuracy: 0.9685 - val_loss: 1.1086e-06 - val_accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "126/126 [==============================] - 1s 12ms/step - loss: 0.0436 - accuracy: 0.9686 - val_loss: 3.2463e-07 - val_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0438 - accuracy: 0.9690 - val_loss: 6.7521e-07 - val_accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0449 - accuracy: 0.9675 - val_loss: 2.0401e-04 - val_accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0441 - accuracy: 0.9691 - val_loss: 2.7153e-07 - val_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0445 - accuracy: 0.9677 - val_loss: 6.0853e-07 - val_accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0441 - accuracy: 0.9689 - val_loss: 5.8111e-04 - val_accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0440 - accuracy: 0.9683 - val_loss: 1.8275e-07 - val_accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0450 - accuracy: 0.9677 - val_loss: 1.6324e-07 - val_accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0443 - accuracy: 0.9681 - val_loss: 1.6821e-07 - val_accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0438 - accuracy: 0.9688 - val_loss: 1.6252e-07 - val_accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0441 - accuracy: 0.9683 - val_loss: 5.5123e-06 - val_accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "126/126 [==============================] - 1s 12ms/step - loss: 0.0439 - accuracy: 0.9686 - val_loss: 5.0117e-06 - val_accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0442 - accuracy: 0.9681 - val_loss: 1.7303e-07 - val_accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0447 - accuracy: 0.9681 - val_loss: 4.3537e-07 - val_accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0442 - accuracy: 0.9689 - val_loss: 8.4586e-08 - val_accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0434 - accuracy: 0.9688 - val_loss: 6.7176e-07 - val_accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "126/126 [==============================] - 1s 12ms/step - loss: 0.0458 - accuracy: 0.9676 - val_loss: 2.5175e-06 - val_accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0444 - accuracy: 0.9682 - val_loss: 1.4418e-07 - val_accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0447 - accuracy: 0.9681 - val_loss: 1.6594e-07 - val_accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "126/126 [==============================] - 2s 13ms/step - loss: 0.0436 - accuracy: 0.9684 - val_loss: 1.1245e-04 - val_accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 0.0437 - accuracy: 0.9691 - val_loss: 1.0035e-04 - val_accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "126/126 [==============================] - 2s 15ms/step - loss: 0.0436 - accuracy: 0.9683 - val_loss: 3.8781e-05 - val_accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "126/126 [==============================] - 1s 12ms/step - loss: 0.0438 - accuracy: 0.9685 - val_loss: 1.5374e-05 - val_accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0439 - accuracy: 0.9680 - val_loss: 7.9556e-05 - val_accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0441 - accuracy: 0.9681 - val_loss: 2.4068e-07 - val_accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0437 - accuracy: 0.9689 - val_loss: 1.9149e-06 - val_accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0454 - accuracy: 0.9680 - val_loss: 7.0417e-04 - val_accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0447 - accuracy: 0.9678 - val_loss: 1.9416e-07 - val_accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0435 - accuracy: 0.9686 - val_loss: 4.2100e-08 - val_accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0446 - accuracy: 0.9680 - val_loss: 2.8513e-08 - val_accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0439 - accuracy: 0.9681 - val_loss: 1.7345e-08 - val_accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0441 - accuracy: 0.9681 - val_loss: 1.0398e-08 - val_accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0434 - accuracy: 0.9691 - val_loss: 2.5573e-08 - val_accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0434 - accuracy: 0.9693 - val_loss: 2.1628e-08 - val_accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0439 - accuracy: 0.9691 - val_loss: 1.3186e-08 - val_accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0436 - accuracy: 0.9691 - val_loss: 8.7880e-09 - val_accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0439 - accuracy: 0.9689 - val_loss: 8.8164e-09 - val_accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "126/126 [==============================] - 2s 18ms/step - loss: 0.0442 - accuracy: 0.9681 - val_loss: 6.4821e-09 - val_accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0433 - accuracy: 0.9690 - val_loss: 4.7078e-09 - val_accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0432 - accuracy: 0.9683 - val_loss: 3.5652e-09 - val_accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "126/126 [==============================] - 1s 12ms/step - loss: 0.0438 - accuracy: 0.9683 - val_loss: 3.6188e-09 - val_accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0435 - accuracy: 0.9683 - val_loss: 2.9292e-09 - val_accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "126/126 [==============================] - 1s 12ms/step - loss: 0.0439 - accuracy: 0.9689 - val_loss: 2.3502e-09 - val_accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0440 - accuracy: 0.9682 - val_loss: 3.7387e-09 - val_accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "126/126 [==============================] - 1s 12ms/step - loss: 0.0430 - accuracy: 0.9685 - val_loss: 2.8422e-09 - val_accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0438 - accuracy: 0.9688 - val_loss: 2.2916e-09 - val_accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0433 - accuracy: 0.9689 - val_loss: 1.9683e-09 - val_accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "126/126 [==============================] - 1s 12ms/step - loss: 0.0444 - accuracy: 0.9682 - val_loss: 4.4604e-07 - val_accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0459 - accuracy: 0.9681 - val_loss: 7.1538e-04 - val_accuracy: 0.9999\n",
            "Epoch 87/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0446 - accuracy: 0.9676 - val_loss: 6.1901e-04 - val_accuracy: 0.9999\n",
            "Epoch 88/100\n",
            "126/126 [==============================] - 1s 12ms/step - loss: 0.0444 - accuracy: 0.9683 - val_loss: 5.8045e-04 - val_accuracy: 0.9999\n",
            "Epoch 89/100\n",
            "126/126 [==============================] - 2s 15ms/step - loss: 0.0451 - accuracy: 0.9677 - val_loss: 5.1464e-04 - val_accuracy: 0.9999\n",
            "Epoch 90/100\n",
            "126/126 [==============================] - 2s 17ms/step - loss: 0.0441 - accuracy: 0.9684 - val_loss: 6.2593e-04 - val_accuracy: 0.9999\n",
            "Epoch 91/100\n",
            "126/126 [==============================] - 2s 13ms/step - loss: 0.0451 - accuracy: 0.9674 - val_loss: 5.4932e-04 - val_accuracy: 0.9999\n",
            "Epoch 92/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0448 - accuracy: 0.9676 - val_loss: 1.1872e-04 - val_accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0446 - accuracy: 0.9678 - val_loss: 1.5294e-04 - val_accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0439 - accuracy: 0.9688 - val_loss: 1.4293e-04 - val_accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0436 - accuracy: 0.9690 - val_loss: 1.5289e-04 - val_accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0434 - accuracy: 0.9687 - val_loss: 1.6272e-04 - val_accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0446 - accuracy: 0.9679 - val_loss: 1.7399e-04 - val_accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0439 - accuracy: 0.9685 - val_loss: 1.8742e-04 - val_accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0440 - accuracy: 0.9694 - val_loss: 2.5263e-04 - val_accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.0436 - accuracy: 0.9683 - val_loss: 2.5013e-04 - val_accuracy: 1.0000\n",
            "1002/1002 [==============================] - 3s 3ms/step - loss: 2.5013e-04 - accuracy: 1.0000\n",
            "[0.0002501310664229095, 0.9999688267707825]\n",
            "1002/1002 [==============================] - 4s 3ms/step\n",
            "[[15960     0]\n",
            " [    1 16090]]\n",
            "0.9999687997254376\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     15960\n",
            "           1       1.00      1.00      1.00     16091\n",
            "\n",
            "    accuracy                           1.00     32051\n",
            "   macro avg       1.00      1.00      1.00     32051\n",
            "weighted avg       1.00      1.00      1.00     32051\n",
            "\n",
            "Summary of the results after each epoch\n",
            "Training time: 6.556510925292969e-05\n",
            "Test time: 2.7179718017578125e-05\n",
            "\n",
            "TIME: 0.0009367465972900391seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***CNN-LSTM***"
      ],
      "metadata": {
        "id": "s_Ze2y9wdxeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###############LSTM###################################\n",
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda\n",
        "\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, Dense, Dropout, Flatten, MaxPooling1D\n",
        "\n",
        "from keras.layers import LSTM, GRU, SimpleRNN\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "lstm_output_size = 20\n",
        "epochs = 10\n",
        "model = Sequential()\n",
        "model.add(Conv1D(32, 2, activation='relu', input_shape = X_train[0].shape))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(SimpleRNN(lstm_output_size))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "#model.add(Dense(1, activation='sigmoid'))\n",
        "    #])\n",
        "model.compile(optimizer=Adam(lr=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size = 512, validation_data=(X_test, y_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_test)\n",
        "y_preds_cnn1 = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_test, y_preds_cnn1)\n",
        "print(confusion_matrix(y_test, y_preds_cnn1))\n",
        "print(accuracy_score(y_test, y_preds_cnn1))\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_preds_cnn1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))\n",
        "\n",
        "\n",
        "print('Summary of the results after each epoch')\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Cross-Validation'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Cross-Validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4bQpb0YcuzZ",
        "outputId": "4108ee05-7ee7-44cf-f65c-84169661a7e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "340/340 [==============================] - 11s 24ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 2.0682e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 7.0982e-04 - accuracy: 0.9999 - val_loss: 1.0764e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 3.0238e-04 - accuracy: 1.0000 - val_loss: 3.7496e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 1.1736e-04 - accuracy: 1.0000 - val_loss: 1.2618e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 6.2130e-05 - accuracy: 1.0000 - val_loss: 5.2947e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 4.2778e-05 - accuracy: 1.0000 - val_loss: 3.6467e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 2.9504e-05 - accuracy: 1.0000 - val_loss: 4.0616e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 1.1126e-05 - accuracy: 1.0000 - val_loss: 1.8823e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 9.1316e-06 - accuracy: 1.0000 - val_loss: 1.2682e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 8.5039e-06 - accuracy: 1.0000 - val_loss: 1.0114e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 4.7717e-06 - accuracy: 1.0000 - val_loss: 6.6930e-07 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "340/340 [==============================] - 4s 11ms/step - loss: 4.5946e-06 - accuracy: 1.0000 - val_loss: 5.4482e-07 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "340/340 [==============================] - 6s 16ms/step - loss: 0.0205 - accuracy: 0.9953 - val_loss: 0.0012 - val_accuracy: 0.9999\n",
            "Epoch 14/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 7.3270e-04 - val_accuracy: 0.9999\n",
            "Epoch 15/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 8.8811e-04 - accuracy: 0.9999 - val_loss: 4.8722e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 3.6656e-04 - accuracy: 1.0000 - val_loss: 2.6600e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "340/340 [==============================] - 7s 22ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 9.6724e-04 - val_accuracy: 0.9996\n",
            "Epoch 18/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 4.4038e-04 - accuracy: 1.0000 - val_loss: 2.6861e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 1.3638e-04 - accuracy: 1.0000 - val_loss: 2.5477e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 4.8683e-05 - accuracy: 1.0000 - val_loss: 2.5523e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 4.0143e-05 - accuracy: 1.0000 - val_loss: 2.5533e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 2.7068e-05 - accuracy: 1.0000 - val_loss: 2.5489e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 3.0634e-05 - accuracy: 1.0000 - val_loss: 2.5867e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "340/340 [==============================] - 5s 16ms/step - loss: 4.8449e-04 - accuracy: 0.9999 - val_loss: 5.3338e-04 - val_accuracy: 0.9999\n",
            "Epoch 25/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 2.6838e-04 - accuracy: 1.0000 - val_loss: 1.8532e-04 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 4.1279e-04 - accuracy: 0.9999 - val_loss: 0.0020 - val_accuracy: 0.9998\n",
            "Epoch 27/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 2.5051e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 1.8830e-04 - accuracy: 1.0000 - val_loss: 1.5180e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 6.9788e-05 - accuracy: 1.0000 - val_loss: 2.0787e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 1.0186e-04 - accuracy: 1.0000 - val_loss: 1.4381e-04 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 2.6746e-04 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 2.9613e-04 - accuracy: 1.0000 - val_loss: 2.6854e-04 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 2.7519e-04 - accuracy: 1.0000 - val_loss: 1.3570e-04 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 2.0537e-04 - accuracy: 1.0000 - val_loss: 1.0169e-04 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "340/340 [==============================] - 6s 17ms/step - loss: 3.3343e-04 - accuracy: 1.0000 - val_loss: 1.0790e-04 - val_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 1.8287e-04 - accuracy: 1.0000 - val_loss: 7.2556e-05 - val_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 2.2814e-04 - accuracy: 1.0000 - val_loss: 1.6231e-04 - val_accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 2.0513e-04 - accuracy: 1.0000 - val_loss: 1.9153e-05 - val_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 2.1974e-04 - accuracy: 1.0000 - val_loss: 4.1727e-05 - val_accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 1.7799e-04 - accuracy: 1.0000 - val_loss: 2.4788e-05 - val_accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 1.5085e-04 - accuracy: 1.0000 - val_loss: 2.2226e-05 - val_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 1.9829e-04 - accuracy: 1.0000 - val_loss: 2.0686e-05 - val_accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 1.6466e-04 - accuracy: 1.0000 - val_loss: 9.7445e-06 - val_accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 1.6995e-04 - accuracy: 1.0000 - val_loss: 2.0353e-05 - val_accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 1.7746e-04 - accuracy: 1.0000 - val_loss: 2.7421e-05 - val_accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "340/340 [==============================] - 5s 14ms/step - loss: 1.8973e-04 - accuracy: 1.0000 - val_loss: 2.8680e-05 - val_accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0024 - val_accuracy: 0.9997\n",
            "Epoch 48/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 49/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0011 - val_accuracy: 0.9999\n",
            "Epoch 50/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
            "Epoch 51/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 9.4610e-04 - val_accuracy: 0.9999\n",
            "Epoch 52/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0015 - val_accuracy: 0.9999\n",
            "Epoch 53/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 3.8925e-04 - val_accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 6.4394e-04 - accuracy: 0.9998 - val_loss: 1.3909e-04 - val_accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 3.2694e-04 - val_accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 1.9761e-04 - accuracy: 1.0000 - val_loss: 3.0230e-04 - val_accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "340/340 [==============================] - 5s 13ms/step - loss: 2.2035e-04 - accuracy: 1.0000 - val_loss: 1.7249e-04 - val_accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "340/340 [==============================] - 6s 17ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 59/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0043 - val_accuracy: 0.9988\n",
            "Epoch 60/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 3.8096e-04 - val_accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 4.6171e-04 - accuracy: 0.9999 - val_loss: 1.6809e-04 - val_accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 6.4723e-04 - accuracy: 0.9998 - val_loss: 4.9181e-05 - val_accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 3.0710e-04 - accuracy: 0.9999 - val_loss: 1.5417e-05 - val_accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 2.0942e-04 - accuracy: 1.0000 - val_loss: 1.0370e-05 - val_accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0023 - val_accuracy: 0.9996\n",
            "Epoch 66/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 2.1079e-05 - val_accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "340/340 [==============================] - 5s 13ms/step - loss: 1.9821e-04 - accuracy: 0.9999 - val_loss: 1.3880e-05 - val_accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "340/340 [==============================] - 5s 14ms/step - loss: 1.2235e-04 - accuracy: 1.0000 - val_loss: 7.9687e-06 - val_accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "340/340 [==============================] - 5s 16ms/step - loss: 1.3647e-04 - accuracy: 0.9999 - val_loss: 4.5605e-06 - val_accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 1.7864e-04 - accuracy: 0.9999 - val_loss: 2.7064e-06 - val_accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 9.1110e-05 - accuracy: 1.0000 - val_loss: 2.5494e-06 - val_accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 3.7029e-05 - accuracy: 1.0000 - val_loss: 1.6429e-06 - val_accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 5.7261e-05 - accuracy: 1.0000 - val_loss: 1.3173e-06 - val_accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 5.7275e-05 - accuracy: 1.0000 - val_loss: 7.8580e-07 - val_accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 4.0630e-05 - accuracy: 1.0000 - val_loss: 1.8273e-06 - val_accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 4.1205e-05 - accuracy: 1.0000 - val_loss: 3.8832e-07 - val_accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "340/340 [==============================] - 7s 22ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 7.8769e-05 - val_accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "340/340 [==============================] - 6s 16ms/step - loss: 5.0367e-04 - accuracy: 0.9998 - val_loss: 5.5093e-05 - val_accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "340/340 [==============================] - 5s 15ms/step - loss: 2.4280e-04 - accuracy: 0.9999 - val_loss: 1.6170e-05 - val_accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 1.3362e-04 - accuracy: 1.0000 - val_loss: 2.0536e-05 - val_accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 1.5539e-04 - accuracy: 1.0000 - val_loss: 2.8600e-06 - val_accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 0.0093 - accuracy: 0.9984 - val_loss: 0.0062 - val_accuracy: 0.9985\n",
            "Epoch 83/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 8.5922e-04 - val_accuracy: 0.9991\n",
            "Epoch 84/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 1.9990e-04 - val_accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 9.8578e-04 - accuracy: 0.9998 - val_loss: 1.7932e-04 - val_accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 0.0164 - accuracy: 0.9968 - val_loss: 0.0011 - val_accuracy: 0.9999\n",
            "Epoch 87/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 2.9241e-04 - val_accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 9.6270e-04 - accuracy: 0.9997 - val_loss: 2.1148e-04 - val_accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "340/340 [==============================] - 5s 14ms/step - loss: 7.1429e-04 - accuracy: 0.9998 - val_loss: 1.9134e-04 - val_accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "340/340 [==============================] - 5s 14ms/step - loss: 5.7477e-04 - accuracy: 0.9998 - val_loss: 1.7092e-04 - val_accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 5.3078e-04 - accuracy: 0.9999 - val_loss: 1.3637e-04 - val_accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 4.3108e-04 - accuracy: 0.9999 - val_loss: 1.6820e-04 - val_accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 4.3804e-04 - accuracy: 0.9999 - val_loss: 1.3469e-04 - val_accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 3.7931e-04 - accuracy: 0.9999 - val_loss: 2.1114e-04 - val_accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 2.9835e-04 - accuracy: 0.9999 - val_loss: 1.5603e-04 - val_accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 2.5792e-04 - accuracy: 0.9999 - val_loss: 1.5532e-04 - val_accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 2.5155e-04 - accuracy: 0.9999 - val_loss: 1.5765e-04 - val_accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 2.0770e-04 - accuracy: 0.9999 - val_loss: 1.6480e-04 - val_accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "340/340 [==============================] - 4s 13ms/step - loss: 1.8114e-04 - accuracy: 1.0000 - val_loss: 1.3011e-04 - val_accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "340/340 [==============================] - 4s 12ms/step - loss: 1.3935e-04 - accuracy: 1.0000 - val_loss: 7.8208e-05 - val_accuracy: 1.0000\n",
            "1358/1358 [==============================] - 4s 3ms/step - loss: 7.8208e-05 - accuracy: 1.0000\n",
            "[7.820774771971628e-05, 0.9999769926071167]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***DNN***"
      ],
      "metadata": {
        "id": "WG8O5FuDdeCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from keras.layers import LSTM, SimpleRNN, GRU\n",
        "#from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "# 1. define the network\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(37,)),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer=Adam(lr=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_train, y_train, epochs=50, batch_size = 20, validation_data=(X_test, y_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_test, y_preds_cnn))\n",
        "print(accuracy_score(y_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_preds_cnn))\n",
        "\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))\n",
        "\n",
        "\n",
        "print('Summary of the results after each epoch')\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Cross-Validation'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Cross-Validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R1YyPfbFdi8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eIphgncAOed"
      },
      "source": [
        "# ***ICU-ENV centralized***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pkMNtrBAZpu",
        "outputId": "f284df6f-d708-4154-a450-ba5168633ea5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(111882, 44)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df_ICU_ENV = pd.read_csv('/content/drive/MyDrive/ICU/clean_ICU.csv')\n",
        "df_ICU_ENV.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "_TnT94sFCWYC",
        "outputId": "18a19c18-b178-4a15-ea24-6c0232de57f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  frame.time_delta  frame.time_relative  frame.len   tcp.flags  \\\n",
              "0           0          0.000000             0.000000      105.0  0x00000018   \n",
              "1           1          0.000053             0.000053       72.0  0x00000018   \n",
              "2           2          0.000043             0.000096      105.0  0x00000018   \n",
              "3           3          0.000020             0.000116       72.0  0x00000018   \n",
              "4           4          0.000016             0.000132      105.0  0x00000018   \n",
              "\n",
              "   tcp.time_delta  tcp.len  tcp.ack  tcp.connection.fin  tcp.connection.rst  \\\n",
              "0        0.000000     37.0      1.0                 0.0                 0.0   \n",
              "1        0.000053      4.0     38.0                 0.0                 0.0   \n",
              "2        0.000000     37.0      1.0                 0.0                 0.0   \n",
              "3        0.000020      4.0     38.0                 0.0                 0.0   \n",
              "4        0.000000     37.0      1.0                 0.0                 0.0   \n",
              "\n",
              "   ...  mqtt.qos  mqtt.retain  mqtt.topic_len  mqtt.ver  mqtt.willmsg_len  \\\n",
              "0  ...       0.0          0.0             0.0       4.0               0.0   \n",
              "1  ...       0.0          0.0             0.0       0.0               0.0   \n",
              "2  ...       0.0          0.0             0.0       4.0               0.0   \n",
              "3  ...       0.0          0.0             0.0       0.0               0.0   \n",
              "4  ...       0.0          0.0             0.0       4.0               0.0   \n",
              "\n",
              "   ip.proto  ip.ttl  label  tcp.flags.ack   tcp.flags.fin   \n",
              "0       6.0    64.0      0             1.0             0.0  \n",
              "1       6.0    64.0      0             1.0             0.0  \n",
              "2       6.0    64.0      0             1.0             0.0  \n",
              "3       6.0    64.0      0             1.0             0.0  \n",
              "4       6.0    64.0      0             1.0             0.0  \n",
              "\n",
              "[5 rows x 44 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d40e173d-a6c3-4e25-9183-ec33d0dbf6b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>frame.time_delta</th>\n",
              "      <th>frame.time_relative</th>\n",
              "      <th>frame.len</th>\n",
              "      <th>tcp.flags</th>\n",
              "      <th>tcp.time_delta</th>\n",
              "      <th>tcp.len</th>\n",
              "      <th>tcp.ack</th>\n",
              "      <th>tcp.connection.fin</th>\n",
              "      <th>tcp.connection.rst</th>\n",
              "      <th>...</th>\n",
              "      <th>mqtt.qos</th>\n",
              "      <th>mqtt.retain</th>\n",
              "      <th>mqtt.topic_len</th>\n",
              "      <th>mqtt.ver</th>\n",
              "      <th>mqtt.willmsg_len</th>\n",
              "      <th>ip.proto</th>\n",
              "      <th>ip.ttl</th>\n",
              "      <th>label</th>\n",
              "      <th>tcp.flags.ack</th>\n",
              "      <th>tcp.flags.fin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>105.0</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>4.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>0.000096</td>\n",
              "      <td>105.0</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>4.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000132</td>\n",
              "      <td>105.0</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 44 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d40e173d-a6c3-4e25-9183-ec33d0dbf6b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d40e173d-a6c3-4e25-9183-ec33d0dbf6b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d40e173d-a6c3-4e25-9183-ec33d0dbf6b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df_ICU_ENV.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ICU_ENV.info()"
      ],
      "metadata": {
        "id": "EM0wl5IiC8dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed73d66d-bc09-4fbb-f3e2-aec2d9a9a36c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 111882 entries, 0 to 111881\n",
            "Data columns (total 44 columns):\n",
            " #   Column                 Non-Null Count   Dtype  \n",
            "---  ------                 --------------   -----  \n",
            " 0   Unnamed: 0             111882 non-null  int64  \n",
            " 1   frame.time_delta       111882 non-null  float64\n",
            " 2   frame.time_relative    111882 non-null  float64\n",
            " 3   frame.len              111882 non-null  float64\n",
            " 4   tcp.flags              111882 non-null  object \n",
            " 5   tcp.time_delta         111882 non-null  float64\n",
            " 6   tcp.len                111882 non-null  float64\n",
            " 7   tcp.ack                111882 non-null  float64\n",
            " 8   tcp.connection.fin     111882 non-null  float64\n",
            " 9   tcp.connection.rst     111882 non-null  float64\n",
            " 10  tcp.connection.sack    111882 non-null  float64\n",
            " 11  tcp.connection.syn     111882 non-null  float64\n",
            " 12  tcp.flags.ack          111882 non-null  int64  \n",
            " 13  tcp.flags.fin          111882 non-null  int64  \n",
            " 14  tcp.flags.push         111882 non-null  float64\n",
            " 15  tcp.flags.reset        111882 non-null  float64\n",
            " 16  tcp.flags.syn          111882 non-null  float64\n",
            " 17  tcp.flags.urg          111882 non-null  float64\n",
            " 18  tcp.hdr_len            111882 non-null  float64\n",
            " 19  tcp.pdu.size           111882 non-null  float64\n",
            " 20  tcp.window_size_value  111882 non-null  float64\n",
            " 21  tcp.checksum           111882 non-null  object \n",
            " 22  mqtt.clientid_len      111882 non-null  float64\n",
            " 23  mqtt.conack.val        111882 non-null  float64\n",
            " 24  mqtt.conflag.passwd    111882 non-null  float64\n",
            " 25  mqtt.conflag.qos       111882 non-null  float64\n",
            " 26  mqtt.conflag.reserved  111882 non-null  float64\n",
            " 27  mqtt.conflag.retain    111882 non-null  float64\n",
            " 28  mqtt.conflag.willflag  111882 non-null  float64\n",
            " 29  mqtt.dupflag           111882 non-null  float64\n",
            " 30  mqtt.hdrflags          111882 non-null  object \n",
            " 31  mqtt.kalive            111882 non-null  float64\n",
            " 32  mqtt.len               111882 non-null  float64\n",
            " 33  mqtt.msgtype           111882 non-null  float64\n",
            " 34  mqtt.qos               111882 non-null  float64\n",
            " 35  mqtt.retain            111882 non-null  float64\n",
            " 36  mqtt.topic_len         111882 non-null  float64\n",
            " 37  mqtt.ver               111882 non-null  float64\n",
            " 38  mqtt.willmsg_len       111882 non-null  float64\n",
            " 39  ip.proto               111882 non-null  float64\n",
            " 40  ip.ttl                 111882 non-null  float64\n",
            " 41  label                  111882 non-null  int64  \n",
            " 42  tcp.flags.ack          111882 non-null  float64\n",
            " 43  tcp.flags.fin          111882 non-null  float64\n",
            "dtypes: float64(37), int64(4), object(3)\n",
            "memory usage: 37.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ICU_ENV['tcp.flags.urg'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC7dXUo3A-D8",
        "outputId": "8c21e3ff-1058-4be5-92c7-ad7f0ed99997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    111882\n",
              "Name: tcp.flags.urg, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etP7KmpLAqh1",
        "outputId": "163d4371-6b39-45c1-fc22-5f7856417421"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(111882, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "col = ['Unnamed: 0','tcp.flags', 'tcp.checksum', 'mqtt.hdrflags', 'tcp.flags.ack', 'tcp.flags.fin', 'mqtt.willmsg_len', 'mqtt.conflag.willflag'\n",
        ", 'mqtt.conflag.retain', 'mqtt.conflag.reserved', 'mqtt.conflag.qos', 'mqtt.conflag.passwd', 'mqtt.conack.val', 'tcp.flags.urg']\n",
        "df_ICU_ENV = df_ICU_ENV.drop(columns=col, axis=1)\n",
        "df_ICU_ENV.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ICU_ENV.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d50eB5k_VjFv",
        "outputId": "39bf3294-92a0-4145-ccd6-a5d7bdec1460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 188694 entries, 0 to 188693\n",
            "Data columns (total 12 columns):\n",
            " #   Column            Non-Null Count   Dtype  \n",
            "---  ------            --------------   -----  \n",
            " 0   Unnamed: 0        188694 non-null  int64  \n",
            " 1   frame.time_delta  188694 non-null  float64\n",
            " 2   tcp.time_delta    188694 non-null  float64\n",
            " 3   tcp.flags.ack     188694 non-null  int64  \n",
            " 4   tcp.flags.push    188694 non-null  int64  \n",
            " 5   tcp.flags.reset   188694 non-null  int64  \n",
            " 6   mqtt.hdrflags     188694 non-null  int64  \n",
            " 7   mqtt.msgtype      188694 non-null  float64\n",
            " 8   mqtt.qos          188694 non-null  float64\n",
            " 9   mqtt.retain       188694 non-null  float64\n",
            " 10  mqtt.ver          188694 non-null  float64\n",
            " 11  label             188694 non-null  int64  \n",
            "dtypes: float64(6), int64(6)\n",
            "memory usage: 17.3 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ICU_ENV.to_csv('/content/drive/MyDrive/ICU/clean_ICU.csv')"
      ],
      "metadata": {
        "id": "UvgyzedOvH-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#count_FL_0, count_FL_1 = df_ICU_ENV.label.value_counts()\n"
      ],
      "metadata": {
        "id": "CjBGTdMh_idy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_FL_0 = df_ICU_ENV[df_ICU_ENV['label'] == 0]\n",
        "#df_FL_1 = df_ICU_ENV[df_ICU_ENV['label'] == 1]"
      ],
      "metadata": {
        "id": "aNqdkgFt_5Q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_FL_1_under = df_FL_1.sample(count_FL_0)\n",
        "#df_FL_under = pd.concat([df_FL_1_under, df_FL_0], axis = 0)\n",
        "#print('Random under-sampling:')\n",
        "#print(df_FL_under.label.value_counts())"
      ],
      "metadata": {
        "id": "mRaymYsbDmDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_ENV_1_under = df_ENV_1.sample(count_ENV_0)\n",
        "#df_ENV_under = pd.concat([df_ENV_1_under, df_ENV_0], axis = 0)\n",
        "#print('Random under-sampling:')\n",
        "#print(df_ENV_under.label.value_counts())"
      ],
      "metadata": {
        "id": "Jaiouj-vAWig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMwOEML8Axs6",
        "outputId": "612fb0cd-2681-477e-ade7-3ab53b0ff114"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((111882, 29), (111882,))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "X = df_ICU_ENV.drop('label', axis = 1)\n",
        "y = df_ICU_ENV['label']\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uZ7iLDJKdDe"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import NearMiss\n",
        "# define the undersampling method\n",
        "undersample = NearMiss(version=1, n_neighbors=2)\n",
        "# transform the dataset\n",
        "X, y = undersample.fit_resample(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgXjrEIfCnh9"
      },
      "outputs": [],
      "source": [
        "#from sklearn.preprocessing import LabelEncoder\n",
        "#encoder = LabelEncoder()\n",
        "#y1 = encoder.fit_transform(y)\n",
        "#Y= pd.get_dummies(y1).values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaling = StandardScaler()\n",
        "X_train = scaling.fit_transform(X_train)\n",
        "X_test = scaling.transform(X_test)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
      ],
      "metadata": {
        "id": "-GekZ6mkbIII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gt5dWFczCs-j"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-5wiONBEGIB"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaling = StandardScaler()\n",
        "X_train = scaling.fit_transform(X_train)\n",
        "X_test = scaling.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuoRaE0wLdnz"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM**"
      ],
      "metadata": {
        "id": "o-cELddJgp1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import time\n",
        "import time\n",
        "start = time.time()\n",
        "#from keras.optimizers import SGD\n",
        "#opt = SGD(lr=0.0001)\n",
        "#batch_size = 64\n",
        "\n",
        "# 1. define the network\n",
        "model = Sequential()\n",
        "model.add(LSTM(4,input_shape = X_train[0].shape))  \n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size = 512, validation_data=(X_test, y_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_test, y_preds_cnn))\n",
        "print(accuracy_score(y_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_preds_cnn))\n",
        "\n",
        "print('Summary of the results after each epoch')\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Cross-Validation'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Cross-Validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tJBsOsk29oUk",
        "outputId": "617fa1fd-10dd-41c4-f261-27015808b01c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 4s 23ms/step - loss: 0.7075 - accuracy: 0.4931 - val_loss: 0.6869 - val_accuracy: 0.6665\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.6579 - accuracy: 0.5732 - val_loss: 0.5989 - val_accuracy: 0.6967\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.5930 - accuracy: 0.6670 - val_loss: 0.5488 - val_accuracy: 0.7462\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.5607 - accuracy: 0.6987 - val_loss: 0.5230 - val_accuracy: 0.7462\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.5424 - accuracy: 0.7203 - val_loss: 0.5025 - val_accuracy: 0.7462\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.5201 - accuracy: 0.7283 - val_loss: 0.4718 - val_accuracy: 0.7454\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.4021 - accuracy: 0.8187 - val_loss: 0.1745 - val_accuracy: 0.9750\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.2070 - accuracy: 0.9260 - val_loss: 0.0852 - val_accuracy: 0.9936\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.1635 - accuracy: 0.9322 - val_loss: 0.0533 - val_accuracy: 0.9973\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.1426 - accuracy: 0.9355 - val_loss: 0.0386 - val_accuracy: 0.9984\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.1312 - accuracy: 0.9353 - val_loss: 0.0297 - val_accuracy: 0.9980\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.1229 - accuracy: 0.9367 - val_loss: 0.0239 - val_accuracy: 0.9990\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.1187 - accuracy: 0.9357 - val_loss: 0.0194 - val_accuracy: 0.9987\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.1124 - accuracy: 0.9372 - val_loss: 0.0175 - val_accuracy: 0.9987\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.1102 - accuracy: 0.9378 - val_loss: 0.0144 - val_accuracy: 0.9986\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.1042 - accuracy: 0.9403 - val_loss: 0.0117 - val_accuracy: 0.9993\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0989 - accuracy: 0.9416 - val_loss: 0.0106 - val_accuracy: 0.9992\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.1010 - accuracy: 0.9413 - val_loss: 0.0090 - val_accuracy: 0.9995\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0929 - accuracy: 0.9526 - val_loss: 0.0083 - val_accuracy: 0.9993\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0917 - accuracy: 0.9518 - val_loss: 0.0073 - val_accuracy: 0.9994\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0885 - accuracy: 0.9528 - val_loss: 0.0072 - val_accuracy: 0.9994\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0854 - accuracy: 0.9528 - val_loss: 0.0065 - val_accuracy: 0.9994\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0823 - accuracy: 0.9540 - val_loss: 0.0071 - val_accuracy: 0.9989\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0807 - accuracy: 0.9547 - val_loss: 0.0050 - val_accuracy: 0.9997\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0802 - accuracy: 0.9529 - val_loss: 0.0065 - val_accuracy: 0.9988\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0776 - accuracy: 0.9547 - val_loss: 0.0039 - val_accuracy: 0.9999\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0774 - accuracy: 0.9601 - val_loss: 0.0044 - val_accuracy: 0.9996\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0754 - accuracy: 0.9629 - val_loss: 0.0041 - val_accuracy: 0.9998\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0728 - accuracy: 0.9677 - val_loss: 0.0030 - val_accuracy: 0.9992\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0740 - accuracy: 0.9653 - val_loss: 0.0038 - val_accuracy: 0.9998\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0719 - accuracy: 0.9663 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0710 - accuracy: 0.9665 - val_loss: 0.0032 - val_accuracy: 0.9997\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0699 - accuracy: 0.9663 - val_loss: 0.0029 - val_accuracy: 0.9987\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0695 - accuracy: 0.9667 - val_loss: 0.0031 - val_accuracy: 0.9998\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0682 - accuracy: 0.9665 - val_loss: 0.0023 - val_accuracy: 0.9998\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0690 - accuracy: 0.9653 - val_loss: 0.0022 - val_accuracy: 0.9988\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0666 - accuracy: 0.9670 - val_loss: 0.0026 - val_accuracy: 0.9998\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0664 - accuracy: 0.9665 - val_loss: 0.0022 - val_accuracy: 0.9999\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0659 - accuracy: 0.9662 - val_loss: 0.0021 - val_accuracy: 0.9999\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0667 - accuracy: 0.9661 - val_loss: 0.0019 - val_accuracy: 0.9988\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0630 - accuracy: 0.9680 - val_loss: 0.0025 - val_accuracy: 0.9998\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0648 - accuracy: 0.9660 - val_loss: 0.0022 - val_accuracy: 0.9988\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0629 - accuracy: 0.9666 - val_loss: 0.0021 - val_accuracy: 0.9994\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0632 - accuracy: 0.9662 - val_loss: 0.0016 - val_accuracy: 0.9999\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0620 - accuracy: 0.9683 - val_loss: 0.0036 - val_accuracy: 0.9988\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0632 - accuracy: 0.9670 - val_loss: 0.0032 - val_accuracy: 0.9988\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0614 - accuracy: 0.9667 - val_loss: 0.0012 - val_accuracy: 0.9999\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0599 - accuracy: 0.9677 - val_loss: 9.2519e-04 - val_accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0621 - accuracy: 0.9652 - val_loss: 8.5224e-04 - val_accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0612 - accuracy: 0.9661 - val_loss: 9.0572e-04 - val_accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0586 - accuracy: 0.9666 - val_loss: 0.0012 - val_accuracy: 0.9995\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0573 - accuracy: 0.9676 - val_loss: 7.4584e-04 - val_accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0585 - accuracy: 0.9677 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0583 - accuracy: 0.9661 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0559 - accuracy: 0.9689 - val_loss: 8.4956e-04 - val_accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0564 - accuracy: 0.9679 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0577 - accuracy: 0.9662 - val_loss: 5.8367e-04 - val_accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0561 - accuracy: 0.9673 - val_loss: 6.5387e-04 - val_accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0564 - accuracy: 0.9670 - val_loss: 5.8672e-04 - val_accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0543 - accuracy: 0.9673 - val_loss: 8.2916e-04 - val_accuracy: 0.9998\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0550 - accuracy: 0.9674 - val_loss: 4.7566e-04 - val_accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0542 - accuracy: 0.9675 - val_loss: 6.8724e-04 - val_accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0632 - accuracy: 0.9648 - val_loss: 0.0020 - val_accuracy: 0.9987\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0562 - accuracy: 0.9671 - val_loss: 6.7305e-04 - val_accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0533 - accuracy: 0.9678 - val_loss: 6.9587e-04 - val_accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0531 - accuracy: 0.9665 - val_loss: 4.1640e-04 - val_accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0517 - accuracy: 0.9688 - val_loss: 3.9552e-04 - val_accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0512 - accuracy: 0.9682 - val_loss: 6.3082e-04 - val_accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0521 - accuracy: 0.9667 - val_loss: 3.2558e-04 - val_accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0520 - accuracy: 0.9680 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0508 - accuracy: 0.9683 - val_loss: 3.9074e-04 - val_accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0517 - accuracy: 0.9681 - val_loss: 4.0355e-04 - val_accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0508 - accuracy: 0.9677 - val_loss: 2.7811e-04 - val_accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0509 - accuracy: 0.9675 - val_loss: 4.2917e-04 - val_accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0508 - accuracy: 0.9679 - val_loss: 2.9541e-04 - val_accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0495 - accuracy: 0.9686 - val_loss: 2.4702e-04 - val_accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0506 - accuracy: 0.9676 - val_loss: 2.7430e-04 - val_accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0495 - accuracy: 0.9678 - val_loss: 2.7537e-04 - val_accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0497 - accuracy: 0.9675 - val_loss: 1.9314e-04 - val_accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0477 - accuracy: 0.9689 - val_loss: 0.0011 - val_accuracy: 0.9995\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0480 - accuracy: 0.9685 - val_loss: 3.0433e-04 - val_accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0499 - accuracy: 0.9676 - val_loss: 2.3284e-04 - val_accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0488 - accuracy: 0.9677 - val_loss: 1.5660e-04 - val_accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0466 - accuracy: 0.9694 - val_loss: 1.6054e-04 - val_accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0497 - accuracy: 0.9667 - val_loss: 1.4888e-04 - val_accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0477 - accuracy: 0.9685 - val_loss: 2.0046e-04 - val_accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0479 - accuracy: 0.9678 - val_loss: 1.1864e-04 - val_accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0489 - accuracy: 0.9677 - val_loss: 0.0025 - val_accuracy: 0.9993\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0488 - accuracy: 0.9667 - val_loss: 2.1642e-04 - val_accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0471 - accuracy: 0.9678 - val_loss: 9.4083e-05 - val_accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0487 - accuracy: 0.9680 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0522 - accuracy: 0.9670 - val_loss: 2.0554e-04 - val_accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0470 - accuracy: 0.9677 - val_loss: 1.5180e-04 - val_accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0462 - accuracy: 0.9695 - val_loss: 1.2731e-04 - val_accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0460 - accuracy: 0.9685 - val_loss: 1.0187e-04 - val_accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0492 - accuracy: 0.9687 - val_loss: 2.1025e-04 - val_accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0457 - accuracy: 0.9683 - val_loss: 7.4783e-05 - val_accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0467 - accuracy: 0.9679 - val_loss: 5.7188e-05 - val_accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0456 - accuracy: 0.9689 - val_loss: 5.8716e-05 - val_accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0458 - accuracy: 0.9692 - val_loss: 4.6679e-05 - val_accuracy: 1.0000\n",
            "397/397 [==============================] - 1s 3ms/step - loss: 4.6679e-05 - accuracy: 1.0000\n",
            "[4.6678760554641485e-05, 1.0]\n",
            "397/397 [==============================] - 1s 2ms/step\n",
            "[[6262    0]\n",
            " [   0 6442]]\n",
            "1.0\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      6262\n",
            "           1       1.00      1.00      1.00      6442\n",
            "\n",
            "    accuracy                           1.00     12704\n",
            "   macro avg       1.00      1.00      1.00     12704\n",
            "weighted avg       1.00      1.00      1.00     12704\n",
            "\n",
            "Summary of the results after each epoch\n",
            "Training time: 8.988380432128906e-05\n",
            "Test time: 1.9550323486328125e-05\n",
            "\n",
            "TIME: 0.0003619194030761719seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6IShRTXHked"
      },
      "source": [
        "**DNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98-PeUhJEk7C",
        "outputId": "e907ebda-b961-45e8-d242-5ca946b72f93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2541/2541 [==============================] - 10s 3ms/step - loss: 0.2727 - accuracy: 0.9954 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
            "Epoch 2/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0061 - val_accuracy: 0.9985\n",
            "Epoch 3/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0064 - val_accuracy: 0.9985\n",
            "Epoch 4/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 5/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 6/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
            "Epoch 7/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0061 - val_accuracy: 0.9985\n",
            "Epoch 8/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0063 - val_accuracy: 0.9985\n",
            "Epoch 9/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
            "Epoch 10/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0062 - val_accuracy: 0.9985\n",
            "Epoch 11/50\n",
            "2541/2541 [==============================] - 7s 3ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0065 - val_accuracy: 0.9985\n",
            "Epoch 12/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0068 - val_accuracy: 0.9985\n",
            "Epoch 13/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
            "Epoch 14/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 15/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 16/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 17/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0062 - val_accuracy: 0.9985\n",
            "Epoch 18/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 19/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0067 - val_accuracy: 0.9985\n",
            "Epoch 20/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0061 - val_accuracy: 0.9985\n",
            "Epoch 21/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 22/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 23/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0062 - val_accuracy: 0.9985\n",
            "Epoch 24/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
            "Epoch 25/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 26/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
            "Epoch 27/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0062 - val_accuracy: 0.9985\n",
            "Epoch 28/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0064 - val_accuracy: 0.9985\n",
            "Epoch 29/50\n",
            "2541/2541 [==============================] - 7s 3ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 30/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
            "Epoch 31/50\n",
            "2541/2541 [==============================] - 8s 3ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
            "Epoch 32/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0061 - val_accuracy: 0.9985\n",
            "Epoch 33/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 34/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0063 - val_accuracy: 0.9985\n",
            "Epoch 35/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0063 - val_accuracy: 0.9985\n",
            "Epoch 36/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
            "Epoch 37/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
            "Epoch 38/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
            "Epoch 39/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
            "Epoch 40/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 41/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 42/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
            "Epoch 43/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0065 - val_accuracy: 0.9985\n",
            "Epoch 44/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
            "Epoch 45/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
            "Epoch 46/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0067 - val_accuracy: 0.9985\n",
            "Epoch 47/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
            "Epoch 48/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
            "Epoch 49/50\n",
            "2541/2541 [==============================] - 5s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0064 - val_accuracy: 0.9985\n",
            "Epoch 50/50\n",
            "2541/2541 [==============================] - 6s 2ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0061 - val_accuracy: 0.9985\n",
            "397/397 [==============================] - 1s 2ms/step - loss: 0.0061 - accuracy: 0.9985\n",
            "[0.006056053098291159, 0.9985044002532959]\n",
            "[[6236   19]\n",
            " [   0 6449]]\n",
            "0.9985044080604534\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      6255\n",
            "           1       1.00      1.00      1.00      6449\n",
            "\n",
            "    accuracy                           1.00     12704\n",
            "   macro avg       1.00      1.00      1.00     12704\n",
            "weighted avg       1.00      1.00      1.00     12704\n",
            "\n",
            "Training time: 4.410743713378906e-05\n",
            "Test time: 1.71661376953125e-05\n",
            "\n",
            "TIME: 0.0002980232238769531seconds\n"
          ]
        }
      ],
      "source": [
        "#from keras.layers import LSTM, SimpleRNN, GRU\n",
        "#from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "# 1. define the network\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(37,)),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer=Adam(lr=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_train, y_train, epochs=50, batch_size = 20, validation_data=(X_test, y_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_test, y_preds_cnn))\n",
        "print(accuracy_score(y_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_preds_cnn))\n",
        "\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51t_7QolWHxd"
      },
      "source": [
        "**CNN-LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZfzTYTHWLJb",
        "outputId": "69dd36aa-9554-40e8-ab06-190e0b0b7c1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 4s 59ms/step - loss: 0.1111 - accuracy: 0.9617 - val_loss: 0.0130 - val_accuracy: 0.9980\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 3s 54ms/step - loss: 0.0257 - accuracy: 0.9936 - val_loss: 0.0104 - val_accuracy: 0.9970\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 0.0118 - accuracy: 0.9976 - val_loss: 0.0314 - val_accuracy: 0.9893\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.0225 - accuracy: 0.9942 - val_loss: 0.0052 - val_accuracy: 0.9984\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 0.0441 - accuracy: 0.9910 - val_loss: 0.0104 - val_accuracy: 0.9980\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.0092 - accuracy: 0.9983 - val_loss: 0.0059 - val_accuracy: 0.9984\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0102 - val_accuracy: 0.9985\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.0026 - val_accuracy: 0.9994\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 3s 54ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0026 - val_accuracy: 0.9994\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 3s 54ms/step - loss: 0.0147 - accuracy: 0.9971 - val_loss: 0.0145 - val_accuracy: 0.9961\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 3s 54ms/step - loss: 0.0099 - accuracy: 0.9980 - val_loss: 0.0073 - val_accuracy: 0.9985\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.0052 - val_accuracy: 0.9985\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 3s 54ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0024 - val_accuracy: 0.9994\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0024 - val_accuracy: 0.9994\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.0135 - val_accuracy: 0.9966\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0012 - val_accuracy: 0.9994\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 9.9034e-04 - accuracy: 0.9997 - val_loss: 2.9511e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 5.5591e-04 - accuracy: 0.9999 - val_loss: 0.0322 - val_accuracy: 0.9850\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 0.1040 - accuracy: 0.9695 - val_loss: 0.0223 - val_accuracy: 0.9961\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 0.0143 - accuracy: 0.9978 - val_loss: 0.0101 - val_accuracy: 0.9980\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 0.0080 - accuracy: 0.9985 - val_loss: 0.0080 - val_accuracy: 0.9983\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 0.0080 - accuracy: 0.9984 - val_loss: 0.0081 - val_accuracy: 0.9983\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 0.0079 - accuracy: 0.9985 - val_loss: 0.0073 - val_accuracy: 0.9983\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 0.0072 - accuracy: 0.9985 - val_loss: 0.0063 - val_accuracy: 0.9983\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0058 - val_accuracy: 0.9984\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0084 - val_accuracy: 0.9985\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.0050 - val_accuracy: 0.9985\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0047 - val_accuracy: 0.9991\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0048 - val_accuracy: 0.9991\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.0049 - val_accuracy: 0.9991\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 4s 72ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0044 - val_accuracy: 0.9991\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.0047 - val_accuracy: 0.9991\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.0050 - val_accuracy: 0.9991\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.0045 - val_accuracy: 0.9991\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0050 - val_accuracy: 0.9991\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.0038 - val_accuracy: 0.9991\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.0051 - val_accuracy: 0.9991\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0045 - val_accuracy: 0.9991\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.0048 - val_accuracy: 0.9991\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0052 - val_accuracy: 0.9991\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.0051 - val_accuracy: 0.9991\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 3s 59ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9991\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0049 - val_accuracy: 0.9991\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.0044 - val_accuracy: 0.9991\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0047 - val_accuracy: 0.9991\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0041 - val_accuracy: 0.9991\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.0037 - val_accuracy: 0.9991\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0045 - val_accuracy: 0.9991\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.0040 - val_accuracy: 0.9991\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0044 - val_accuracy: 0.9991\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0039 - val_accuracy: 0.9991\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0037 - val_accuracy: 0.9991\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0038 - val_accuracy: 0.9991\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 3s 59ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0037 - val_accuracy: 0.9991\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 3s 59ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0045 - val_accuracy: 0.9991\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0040 - val_accuracy: 0.9991\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0045 - val_accuracy: 0.9991\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 3s 59ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0043 - val_accuracy: 0.9991\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 4s 89ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0040 - val_accuracy: 0.9991\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0040 - val_accuracy: 0.9991\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0038 - val_accuracy: 0.9991\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0042 - val_accuracy: 0.9991\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 3s 59ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0051 - val_accuracy: 0.9991\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0036 - val_accuracy: 0.9991\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0041 - val_accuracy: 0.9991\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0042 - val_accuracy: 0.9991\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 4s 73ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0028 - val_accuracy: 0.9991\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 3s 60ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0048 - val_accuracy: 0.9991\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 3s 60ms/step - loss: 0.0131 - accuracy: 0.9967 - val_loss: 0.0085 - val_accuracy: 0.9985\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 3s 59ms/step - loss: 0.0842 - accuracy: 0.9712 - val_loss: 0.0335 - val_accuracy: 0.9954\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 0.0326 - accuracy: 0.9923 - val_loss: 0.0076 - val_accuracy: 0.9983\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 3s 61ms/step - loss: 0.0092 - accuracy: 0.9981 - val_loss: 0.0071 - val_accuracy: 0.9985\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.0071 - val_accuracy: 0.9985\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 0.0072 - val_accuracy: 0.9985\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 3s 59ms/step - loss: 0.0080 - accuracy: 0.9984 - val_loss: 0.0071 - val_accuracy: 0.9985\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 3s 60ms/step - loss: 0.0076 - accuracy: 0.9986 - val_loss: 0.0077 - val_accuracy: 0.9983\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.0081 - val_accuracy: 0.9983\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.0088 - val_accuracy: 0.9983\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 0.0089 - val_accuracy: 0.9983\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 3s 60ms/step - loss: 0.0076 - accuracy: 0.9986 - val_loss: 0.0084 - val_accuracy: 0.9983\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 3s 59ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.0085 - val_accuracy: 0.9982\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.0081 - val_accuracy: 0.9982\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 3s 62ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.0084 - val_accuracy: 0.9983\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.0083 - val_accuracy: 0.9982\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 3s 62ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.0083 - val_accuracy: 0.9982\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 3s 60ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.0082 - val_accuracy: 0.9982\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.0082 - val_accuracy: 0.9982\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 3s 60ms/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.0071 - val_accuracy: 0.9982\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 3s 59ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9991\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 3s 61ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0042 - val_accuracy: 0.9991\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 3s 61ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9991\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 3s 60ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0042 - val_accuracy: 0.9991\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 3s 60ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9992\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 3s 62ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.0048 - val_accuracy: 0.9991\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 3s 61ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.0125 - val_accuracy: 0.9976\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 0.0108 - accuracy: 0.9978 - val_loss: 0.0088 - val_accuracy: 0.9980\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 3s 60ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 0.0063 - val_accuracy: 0.9984\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 3s 61ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.0027 - val_accuracy: 0.9994\n",
            "397/397 [==============================] - 2s 4ms/step - loss: 0.0027 - accuracy: 0.9994\n",
            "[0.002678212011232972, 0.999370276927948]\n",
            "397/397 [==============================] - 2s 4ms/step\n",
            "[[6247    8]\n",
            " [   0 6449]]\n",
            "0.9993702770780857\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      6255\n",
            "           1       1.00      1.00      1.00      6449\n",
            "\n",
            "    accuracy                           1.00     12704\n",
            "   macro avg       1.00      1.00      1.00     12704\n",
            "weighted avg       1.00      1.00      1.00     12704\n",
            "\n",
            "Training time: 8.749961853027344e-05\n",
            "Test time: 2.8848648071289062e-05\n",
            "\n",
            "TIME: 0.0004253387451171875seconds\n"
          ]
        }
      ],
      "source": [
        "###############LSTM###################################\n",
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda\n",
        "\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, Dense, Dropout, Flatten, MaxPooling1D\n",
        "\n",
        "from keras.layers import LSTM, GRU, SimpleRNN\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "lstm_output_size = 20\n",
        "epochs = 10\n",
        "model = Sequential()\n",
        "model.add(Conv1D(32, 2, activation='relu', input_shape = X_train[0].shape))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(SimpleRNN(lstm_output_size))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "#model.add(Dense(1, activation='sigmoid'))\n",
        "    #])\n",
        "model.compile(optimizer=Adam(lr=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_train, y_train, epochs=100, batch_size = 1024, validation_data=(X_test, y_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_test, y_preds_cnn))\n",
        "print(accuracy_score(y_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_preds_cnn))\n",
        "\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ0fCskRGW7Z"
      },
      "source": [
        "# **CENTRALIZED ICU-PAITIENT DATASET PREPROCESSING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3Xre7RgGgV5"
      },
      "outputs": [],
      "source": [
        "import numpy as np  \n",
        "import pandas as pd\n",
        "import os \n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISpFc6qgGjqp",
        "outputId": "cd4663b0-59ae-4f3d-fd4e-323e49a8c40d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (26,28,35) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Index(['frame.time_delta', 'frame.time_relative', 'frame.len', 'ip.src',\n",
              "       'ip.dst', 'tcp.srcport', 'tcp.dstport', 'tcp.flags', 'tcp.time_delta',\n",
              "       'tcp.len', 'tcp.ack', 'tcp.connection.fin', 'tcp.connection.rst',\n",
              "       'tcp.connection.sack', 'tcp.connection.syn', 'tcp.flags.ack',\n",
              "       'tcp.flags.fin', 'tcp.flags.push', 'tcp.flags.reset', 'tcp.flags.syn',\n",
              "       'tcp.flags.urg', 'tcp.hdr_len', 'tcp.payload', 'tcp.pdu.size',\n",
              "       'tcp.window_size_value', 'tcp.checksum', 'mqtt.clientid',\n",
              "       'mqtt.clientid_len', 'mqtt.conack.flags', 'mqtt.conack.val',\n",
              "       'mqtt.conflag.passwd', 'mqtt.conflag.qos', 'mqtt.conflag.reserved',\n",
              "       'mqtt.conflag.retain', 'mqtt.conflag.willflag', 'mqtt.conflags',\n",
              "       'mqtt.dupflag', 'mqtt.hdrflags', 'mqtt.kalive', 'mqtt.len', 'mqtt.msg',\n",
              "       'mqtt.msgtype', 'mqtt.qos', 'mqtt.retain', 'mqtt.topic',\n",
              "       'mqtt.topic_len', 'mqtt.ver', 'mqtt.willmsg_len', 'ip.proto', 'ip.ttl',\n",
              "       'class', 'label'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2 = pd.read_csv('/content/drive/MyDrive/ICU-Patient/patientMonitoring.csv')\n",
        "df2.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyqNO0SfGtq6",
        "outputId": "7e33be8d-8716-4312-fe42-8735c4dda85a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['patientMonitoring.csv', 'Attack.csv']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "path = '/content/drive/MyDrive/ICU-Patient/'\n",
        "csvs = os.listdir(path)\n",
        "csvs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gf-zuZ5zG1eI"
      },
      "outputs": [],
      "source": [
        "df2 = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFc05FDeG5sD",
        "outputId": "6cd78f20-582d-41fb-93c2-c0bfa0029e0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---- Reading patientMonitoring.csv ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (26,28,35) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "df.shape: (76810, 52)\n",
            "empty_cols: 0\n",
            "[]\n",
            "df2.shape: (76810, 52)\n",
            "---- Reading Attack.csv ----\n",
            "df.shape: (80126, 52)\n",
            "empty_cols: 0\n",
            "[]\n",
            "df2.shape: (156936, 52)\n"
          ]
        }
      ],
      "source": [
        "for csv in csvs:\n",
        "  print(f'---- Reading {csv} ----')\n",
        "  df = pd.read_csv(path+csv)\n",
        "  print(f'df.shape: {df.shape}')\n",
        "  empty_cols = [col for col in df.columns if df[col].isnull().all()]\n",
        "  print(f'empty_cols: {len(empty_cols)}')\n",
        "  print(empty_cols)\n",
        "  df.fillna(0, inplace=True)\n",
        "  df2 = df2.append(df, ignore_index=True)\n",
        "  print(f'df2.shape: {df2.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "KUUROopLIL0e",
        "outputId": "2ed152c2-6dc0-4424-9217-3afdc724df05"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-95947d7f-3914-439c-b679-da24d4c8598d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frame.time_delta</th>\n",
              "      <th>frame.time_relative</th>\n",
              "      <th>frame.len</th>\n",
              "      <th>ip.src</th>\n",
              "      <th>ip.dst</th>\n",
              "      <th>tcp.srcport</th>\n",
              "      <th>tcp.dstport</th>\n",
              "      <th>tcp.flags</th>\n",
              "      <th>tcp.time_delta</th>\n",
              "      <th>tcp.len</th>\n",
              "      <th>...</th>\n",
              "      <th>mqtt.qos</th>\n",
              "      <th>mqtt.retain</th>\n",
              "      <th>mqtt.topic</th>\n",
              "      <th>mqtt.topic_len</th>\n",
              "      <th>mqtt.ver</th>\n",
              "      <th>mqtt.willmsg_len</th>\n",
              "      <th>ip.proto</th>\n",
              "      <th>ip.ttl</th>\n",
              "      <th>class</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>105</td>\n",
              "      <td>10.5.126.141</td>\n",
              "      <td>10.5.126.56</td>\n",
              "      <td>35161</td>\n",
              "      <td>1883</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>64</td>\n",
              "      <td>patientMonitoring</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000249</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>105</td>\n",
              "      <td>10.5.126.143</td>\n",
              "      <td>10.5.126.56</td>\n",
              "      <td>34237</td>\n",
              "      <td>1883</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>64</td>\n",
              "      <td>patientMonitoring</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000037</td>\n",
              "      <td>0.000286</td>\n",
              "      <td>105</td>\n",
              "      <td>10.5.126.145</td>\n",
              "      <td>10.5.126.56</td>\n",
              "      <td>46623</td>\n",
              "      <td>1883</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>64</td>\n",
              "      <td>patientMonitoring</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000320</td>\n",
              "      <td>105</td>\n",
              "      <td>10.5.126.147</td>\n",
              "      <td>10.5.126.56</td>\n",
              "      <td>45663</td>\n",
              "      <td>1883</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>64</td>\n",
              "      <td>patientMonitoring</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000337</td>\n",
              "      <td>105</td>\n",
              "      <td>10.5.126.141</td>\n",
              "      <td>10.5.126.56</td>\n",
              "      <td>38901</td>\n",
              "      <td>1883</td>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>64</td>\n",
              "      <td>patientMonitoring</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 52 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95947d7f-3914-439c-b679-da24d4c8598d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-95947d7f-3914-439c-b679-da24d4c8598d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-95947d7f-3914-439c-b679-da24d4c8598d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   frame.time_delta  frame.time_relative  frame.len        ip.src  \\\n",
              "0          0.000000             0.000000        105  10.5.126.141   \n",
              "1          0.000249             0.000249        105  10.5.126.143   \n",
              "2          0.000037             0.000286        105  10.5.126.145   \n",
              "3          0.000034             0.000320        105  10.5.126.147   \n",
              "4          0.000017             0.000337        105  10.5.126.141   \n",
              "\n",
              "        ip.dst  tcp.srcport  tcp.dstport   tcp.flags  tcp.time_delta  tcp.len  \\\n",
              "0  10.5.126.56        35161         1883  0x00000018             0.0       37   \n",
              "1  10.5.126.56        34237         1883  0x00000018             0.0       37   \n",
              "2  10.5.126.56        46623         1883  0x00000018             0.0       37   \n",
              "3  10.5.126.56        45663         1883  0x00000018             0.0       37   \n",
              "4  10.5.126.56        38901         1883  0x00000018             0.0       37   \n",
              "\n",
              "   ...  mqtt.qos  mqtt.retain  mqtt.topic  mqtt.topic_len  mqtt.ver  \\\n",
              "0  ...       0.0          0.0           0             0.0       4.0   \n",
              "1  ...       0.0          0.0           0             0.0       4.0   \n",
              "2  ...       0.0          0.0           0             0.0       4.0   \n",
              "3  ...       0.0          0.0           0             0.0       4.0   \n",
              "4  ...       0.0          0.0           0             0.0       4.0   \n",
              "\n",
              "   mqtt.willmsg_len  ip.proto  ip.ttl              class  label  \n",
              "0               0.0         6      64  patientMonitoring      0  \n",
              "1               0.0         6      64  patientMonitoring      0  \n",
              "2               0.0         6      64  patientMonitoring      0  \n",
              "3               0.0         6      64  patientMonitoring      0  \n",
              "4               0.0         6      64  patientMonitoring      0  \n",
              "\n",
              "[5 rows x 52 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TLtWfbrIghR"
      },
      "outputs": [],
      "source": [
        "feats = ['ip.src', 'ip.dst', 'tcp.srcport', 'tcp.dstport','mqtt.topic', 'mqtt.msg', 'tcp.payload','mqtt.clientid', 'mqtt.conflags', 'mqtt.conack.flags', 'class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0yp8I5BIkl1",
        "outputId": "933477af-f319-460c-ec8c-7bb3499f6f6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(156936, 41)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.drop(labels=feats, axis=1, inplace=True)\n",
        "df2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ttRxWlvIuk4",
        "outputId": "0cb18d58-8968-4bcc-fb98-5b3b65cd7129"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    80126\n",
              "0    76810\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqpiSO3yI1Vq",
        "outputId": "a4c98bf4-7767-48c5-b9ca-35bb9d0e2149"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "frame.time_delta         0\n",
              "frame.time_relative      0\n",
              "frame.len                0\n",
              "tcp.flags                0\n",
              "tcp.time_delta           0\n",
              "tcp.len                  0\n",
              "tcp.ack                  0\n",
              "tcp.connection.fin       0\n",
              "tcp.connection.rst       0\n",
              "tcp.connection.sack      0\n",
              "tcp.connection.syn       0\n",
              "tcp.flags.ack            0\n",
              "tcp.flags.fin            0\n",
              "tcp.flags.push           0\n",
              "tcp.flags.reset          0\n",
              "tcp.flags.syn            0\n",
              "tcp.flags.urg            0\n",
              "tcp.hdr_len              0\n",
              "tcp.pdu.size             0\n",
              "tcp.window_size_value    0\n",
              "tcp.checksum             0\n",
              "mqtt.clientid_len        0\n",
              "mqtt.conack.val          0\n",
              "mqtt.conflag.passwd      0\n",
              "mqtt.conflag.qos         0\n",
              "mqtt.conflag.reserved    0\n",
              "mqtt.conflag.retain      0\n",
              "mqtt.conflag.willflag    0\n",
              "mqtt.dupflag             0\n",
              "mqtt.hdrflags            0\n",
              "mqtt.kalive              0\n",
              "mqtt.len                 0\n",
              "mqtt.msgtype             0\n",
              "mqtt.qos                 0\n",
              "mqtt.retain              0\n",
              "mqtt.topic_len           0\n",
              "mqtt.ver                 0\n",
              "mqtt.willmsg_len         0\n",
              "ip.proto                 0\n",
              "ip.ttl                   0\n",
              "label                    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPIXON8jI7Ru",
        "outputId": "162b6933-0d84-4145-cc55-ca643426dc2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3, 41)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2[df2.duplicated()].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czUTH_-2JBm4"
      },
      "outputs": [],
      "source": [
        "df2 = df2.drop(df2[df2.duplicated()].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNk9OPjZJIGy",
        "outputId": "4fba16c5-6b17-4076-ce57-3998623d24bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0, 41)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2[df2.duplicated()].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYVgnupSJKWT",
        "outputId": "7f29f83e-2b8d-4202-a496-d33acd0a2d91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 156933 entries, 0 to 156935\n",
            "Data columns (total 41 columns):\n",
            " #   Column                 Non-Null Count   Dtype  \n",
            "---  ------                 --------------   -----  \n",
            " 0   frame.time_delta       156933 non-null  float64\n",
            " 1   frame.time_relative    156933 non-null  float64\n",
            " 2   frame.len              156933 non-null  int64  \n",
            " 3   tcp.flags              156933 non-null  object \n",
            " 4   tcp.time_delta         156933 non-null  float64\n",
            " 5   tcp.len                156933 non-null  int64  \n",
            " 6   tcp.ack                156933 non-null  int64  \n",
            " 7   tcp.connection.fin     156933 non-null  float64\n",
            " 8   tcp.connection.rst     156933 non-null  float64\n",
            " 9   tcp.connection.sack    156933 non-null  float64\n",
            " 10  tcp.connection.syn     156933 non-null  float64\n",
            " 11  tcp.flags.ack          156933 non-null  int64  \n",
            " 12  tcp.flags.fin          156933 non-null  int64  \n",
            " 13  tcp.flags.push         156933 non-null  int64  \n",
            " 14  tcp.flags.reset        156933 non-null  int64  \n",
            " 15  tcp.flags.syn          156933 non-null  int64  \n",
            " 16  tcp.flags.urg          156933 non-null  int64  \n",
            " 17  tcp.hdr_len            156933 non-null  int64  \n",
            " 18  tcp.pdu.size           156933 non-null  float64\n",
            " 19  tcp.window_size_value  156933 non-null  int64  \n",
            " 20  tcp.checksum           156933 non-null  object \n",
            " 21  mqtt.clientid_len      156933 non-null  float64\n",
            " 22  mqtt.conack.val        156933 non-null  float64\n",
            " 23  mqtt.conflag.passwd    156933 non-null  float64\n",
            " 24  mqtt.conflag.qos       156933 non-null  float64\n",
            " 25  mqtt.conflag.reserved  156933 non-null  float64\n",
            " 26  mqtt.conflag.retain    156933 non-null  float64\n",
            " 27  mqtt.conflag.willflag  156933 non-null  float64\n",
            " 28  mqtt.dupflag           156933 non-null  float64\n",
            " 29  mqtt.hdrflags          156933 non-null  object \n",
            " 30  mqtt.kalive            156933 non-null  float64\n",
            " 31  mqtt.len               156933 non-null  float64\n",
            " 32  mqtt.msgtype           156933 non-null  float64\n",
            " 33  mqtt.qos               156933 non-null  float64\n",
            " 34  mqtt.retain            156933 non-null  float64\n",
            " 35  mqtt.topic_len         156933 non-null  float64\n",
            " 36  mqtt.ver               156933 non-null  float64\n",
            " 37  mqtt.willmsg_len       156933 non-null  float64\n",
            " 38  ip.proto               156933 non-null  int64  \n",
            " 39  ip.ttl                 156933 non-null  int64  \n",
            " 40  label                  156933 non-null  int64  \n",
            "dtypes: float64(24), int64(14), object(3)\n",
            "memory usage: 50.3+ MB\n"
          ]
        }
      ],
      "source": [
        "df2.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv12ZCckJ-Q_",
        "outputId": "3c89bc57-c3f9-43ba-ccf2-e23956570b83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 156933 entries, 0 to 156935\n",
            "Data columns (total 43 columns):\n",
            " #   Column                 Non-Null Count   Dtype  \n",
            "---  ------                 --------------   -----  \n",
            " 0   frame.time_delta       156933 non-null  float64\n",
            " 1   frame.time_relative    156933 non-null  float64\n",
            " 2   frame.len              156933 non-null  float64\n",
            " 3   tcp.flags              156933 non-null  object \n",
            " 4   tcp.time_delta         156933 non-null  float64\n",
            " 5   tcp.len                156933 non-null  float64\n",
            " 6   tcp.ack                156933 non-null  float64\n",
            " 7   tcp.connection.fin     156933 non-null  float64\n",
            " 8   tcp.connection.rst     156933 non-null  float64\n",
            " 9   tcp.connection.sack    156933 non-null  float64\n",
            " 10  tcp.connection.syn     156933 non-null  float64\n",
            " 11  tcp.flags.ack          156933 non-null  int64  \n",
            " 12  tcp.flags.fin          156933 non-null  int64  \n",
            " 13  tcp.flags.push         156933 non-null  float64\n",
            " 14  tcp.flags.reset        156933 non-null  float64\n",
            " 15  tcp.flags.syn          156933 non-null  float64\n",
            " 16  tcp.flags.urg          156933 non-null  float64\n",
            " 17  tcp.hdr_len            156933 non-null  float64\n",
            " 18  tcp.pdu.size           156933 non-null  float64\n",
            " 19  tcp.window_size_value  156933 non-null  float64\n",
            " 20  tcp.checksum           156933 non-null  object \n",
            " 21  mqtt.clientid_len      156933 non-null  float64\n",
            " 22  mqtt.conack.val        156933 non-null  float64\n",
            " 23  mqtt.conflag.passwd    156933 non-null  float64\n",
            " 24  mqtt.conflag.qos       156933 non-null  float64\n",
            " 25  mqtt.conflag.reserved  156933 non-null  float64\n",
            " 26  mqtt.conflag.retain    156933 non-null  float64\n",
            " 27  mqtt.conflag.willflag  156933 non-null  float64\n",
            " 28  mqtt.dupflag           156933 non-null  float64\n",
            " 29  mqtt.hdrflags          156933 non-null  object \n",
            " 30  mqtt.kalive            156933 non-null  float64\n",
            " 31  mqtt.len               156933 non-null  float64\n",
            " 32  mqtt.msgtype           156933 non-null  float64\n",
            " 33  mqtt.qos               156933 non-null  float64\n",
            " 34  mqtt.retain            156933 non-null  float64\n",
            " 35  mqtt.topic_len         156933 non-null  float64\n",
            " 36  mqtt.ver               156933 non-null  float64\n",
            " 37  mqtt.willmsg_len       156933 non-null  float64\n",
            " 38  ip.proto               156933 non-null  float64\n",
            " 39  ip.ttl                 156933 non-null  float64\n",
            " 40  label                  156933 non-null  int64  \n",
            " 41  tcp.flags.ack          156933 non-null  float64\n",
            " 42  tcp.flags.fin          156933 non-null  float64\n",
            "dtypes: float64(37), int64(3), object(3)\n",
            "memory usage: 52.7+ MB\n"
          ]
        }
      ],
      "source": [
        "df2['frame.len'] = df2['frame.len'].astype(float)\n",
        "#df1['tcp.flags'] = df1['tcp.flags'].astype(float)\n",
        "df2['tcp.len'] = df2['tcp.len'].astype(float)\n",
        "df2['tcp.ack'] = df2['tcp.ack'].astype(float)\n",
        "df2['tcp.flags.ack '] = df2['tcp.flags.ack'].astype(float)\n",
        "df2['tcp.flags.fin '] = df2['tcp.flags.fin'].astype(float)\n",
        "df2['tcp.flags.push'] = df2['tcp.flags.push'].astype(float)\n",
        "df2['tcp.flags.reset'] = df2['tcp.flags.reset'].astype(float)\n",
        "df2['tcp.flags.syn'] = df2['tcp.flags.syn'].astype(float)\n",
        "df2['tcp.flags.urg'] = df2['tcp.flags.urg'].astype(float)\n",
        "df2['tcp.hdr_len'] = df2['tcp.hdr_len'].astype(float)\n",
        "df2['tcp.window_size_value'] = df2['tcp.window_size_value'].astype(float)\n",
        "#df1['tcp.checksum'] = df1['tcp.checksum'].astype(float)\n",
        "\n",
        "#df1['mqtt.hdrflags'] = df1['mqtt.hdrflags'].astype(float)\n",
        "df2['ip.proto'] = df2['ip.proto'].astype(float)\n",
        "df2['ip.ttl'] = df2['ip.ttl'].astype(float)\n",
        "\n",
        "df2.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vROX_rs4Kjos"
      },
      "outputs": [],
      "source": [
        "col = ['tcp.flags', 'tcp.checksum', 'mqtt.hdrflags', 'tcp.flags.ack', 'tcp.flags.fin']\n",
        "df2 = df2.drop(columns=col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJ70czFNKuAE"
      },
      "outputs": [],
      "source": [
        "df2.to_csv('/content/drive/MyDrive/ICU-Patient/clean_ICU-PAI.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1HUISTyLsMV"
      },
      "outputs": [],
      "source": [
        "df_ICU_PAI1 = pd.read_csv('/content/drive/MyDrive/ICU-Patient/clean_ICU-PAI.csv')\n",
        "df_ICU_PAI= df_ICU_PAI1.sample(frac=1, random_state = 13).reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzssUUH2L64w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "for i, df in enumerate(np.array_split(df_ICU_PAI, 5)):\n",
        "    df.to_csv('/content/drive/MyDrive/ICU-Patient/'+f\"ICU-Pai{i+1}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9o50lmOO_EId"
      },
      "source": [
        "# **Centralized ICU-Patient**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIWNaAKP_T8X",
        "outputId": "8b1c0fd7-cead-46ee-9eb1-5d38e053d2ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156933, 39)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df_ICU_PAI = pd.read_csv('/content/drive/MyDrive/ICU-Patient/clean_ICU-PAI.csv')\n",
        "df_ICU_PAI.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "_S7azDwC_soc",
        "outputId": "5c3e59c8-99f7-4715-cf2d-a998d036b6bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  frame.time_delta  frame.time_relative  frame.len  \\\n",
              "0           0          0.000000             0.000000      105.0   \n",
              "1           1          0.000249             0.000249      105.0   \n",
              "2           2          0.000037             0.000286      105.0   \n",
              "3           3          0.000034             0.000320      105.0   \n",
              "4           4          0.000017             0.000337      105.0   \n",
              "\n",
              "   tcp.time_delta  tcp.len  tcp.ack  tcp.connection.fin  tcp.connection.rst  \\\n",
              "0             0.0     37.0      1.0                 0.0                 0.0   \n",
              "1             0.0     37.0      1.0                 0.0                 0.0   \n",
              "2             0.0     37.0      1.0                 0.0                 0.0   \n",
              "3             0.0     37.0      1.0                 0.0                 0.0   \n",
              "4             0.0     37.0      1.0                 0.0                 0.0   \n",
              "\n",
              "   tcp.connection.sack  ...  mqtt.qos  mqtt.retain  mqtt.topic_len  mqtt.ver  \\\n",
              "0                  0.0  ...       0.0          0.0             0.0       4.0   \n",
              "1                  0.0  ...       0.0          0.0             0.0       4.0   \n",
              "2                  0.0  ...       0.0          0.0             0.0       4.0   \n",
              "3                  0.0  ...       0.0          0.0             0.0       4.0   \n",
              "4                  0.0  ...       0.0          0.0             0.0       4.0   \n",
              "\n",
              "   mqtt.willmsg_len  ip.proto  ip.ttl  label  tcp.flags.ack   tcp.flags.fin   \n",
              "0               0.0       6.0    64.0      0             1.0             0.0  \n",
              "1               0.0       6.0    64.0      0             1.0             0.0  \n",
              "2               0.0       6.0    64.0      0             1.0             0.0  \n",
              "3               0.0       6.0    64.0      0             1.0             0.0  \n",
              "4               0.0       6.0    64.0      0             1.0             0.0  \n",
              "\n",
              "[5 rows x 39 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0850cfa-8448-4ef6-a708-8d0e7740aa58\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>frame.time_delta</th>\n",
              "      <th>frame.time_relative</th>\n",
              "      <th>frame.len</th>\n",
              "      <th>tcp.time_delta</th>\n",
              "      <th>tcp.len</th>\n",
              "      <th>tcp.ack</th>\n",
              "      <th>tcp.connection.fin</th>\n",
              "      <th>tcp.connection.rst</th>\n",
              "      <th>tcp.connection.sack</th>\n",
              "      <th>...</th>\n",
              "      <th>mqtt.qos</th>\n",
              "      <th>mqtt.retain</th>\n",
              "      <th>mqtt.topic_len</th>\n",
              "      <th>mqtt.ver</th>\n",
              "      <th>mqtt.willmsg_len</th>\n",
              "      <th>ip.proto</th>\n",
              "      <th>ip.ttl</th>\n",
              "      <th>label</th>\n",
              "      <th>tcp.flags.ack</th>\n",
              "      <th>tcp.flags.fin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>105.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>105.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000037</td>\n",
              "      <td>0.000286</td>\n",
              "      <td>105.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000320</td>\n",
              "      <td>105.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000337</td>\n",
              "      <td>105.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 39 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0850cfa-8448-4ef6-a708-8d0e7740aa58')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c0850cfa-8448-4ef6-a708-8d0e7740aa58 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c0850cfa-8448-4ef6-a708-8d0e7740aa58');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df_ICU_PAI.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icEFOyHx_0io",
        "outputId": "0ca17ffc-8bae-423c-a536-dbdf32d799a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156933, 38)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "col = ['Unnamed: 0']\n",
        "df_ICU_PAI = df_ICU_PAI.drop(columns=col, axis=1)\n",
        "df_ICU_PAI.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzfqFYo0AFYq",
        "outputId": "6214b181-a241-46be-cc4a-6cf573ac461b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((156933, 37), (156933,))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "X = df_ICU_PAI.drop('label', axis = 1)\n",
        "y = df_ICU_PAI['label']\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import NearMiss\n",
        "# define the undersampling method\n",
        "undersample = NearMiss(version=1, n_neighbors=2)\n",
        "# transform the dataset\n",
        "X, y = undersample.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "WK8q4aZYu9CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Htr962y4ANTX"
      },
      "outputs": [],
      "source": [
        "#from sklearn.preprocessing import LabelEncoder\n",
        "#encoder = LabelEncoder()\n",
        "#y1 = encoder.fit_transform(y)\n",
        "#Y= pd.get_dummies(y1).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "402UwOY9ARmO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1337)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYQkQanjAVQ8"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaling = StandardScaler()\n",
        "X_train = scaling.fit_transform(X_train)\n",
        "X_test = scaling.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdI8xuoKAX-T"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0Bc6maNAZdx"
      },
      "source": [
        "**LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oxJVRR2AcSi",
        "outputId": "cdc6f2ed-afc6-4e1b-f093-1e286d689fdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "121/121 [==============================] - 39s 312ms/step - loss: 0.4844 - accuracy: 0.7811 - val_loss: 0.3773 - val_accuracy: 0.8359\n",
            "Epoch 2/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.4016 - accuracy: 0.8140 - val_loss: 0.3354 - val_accuracy: 0.8361\n",
            "Epoch 3/100\n",
            "121/121 [==============================] - 2s 19ms/step - loss: 0.1497 - accuracy: 0.9370 - val_loss: 0.0185 - val_accuracy: 0.9974\n",
            "Epoch 4/100\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.0691 - accuracy: 0.9633 - val_loss: 0.0140 - val_accuracy: 0.9978\n",
            "Epoch 5/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0603 - accuracy: 0.9664 - val_loss: 0.0118 - val_accuracy: 0.9983\n",
            "Epoch 6/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0584 - accuracy: 0.9672 - val_loss: 0.0124 - val_accuracy: 0.9978\n",
            "Epoch 7/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0597 - accuracy: 0.9658 - val_loss: 0.0109 - val_accuracy: 0.9983\n",
            "Epoch 8/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0641 - accuracy: 0.9657 - val_loss: 0.0112 - val_accuracy: 0.9983\n",
            "Epoch 9/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0587 - accuracy: 0.9665 - val_loss: 0.0101 - val_accuracy: 0.9983\n",
            "Epoch 10/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0568 - accuracy: 0.9660 - val_loss: 0.0097 - val_accuracy: 0.9983\n",
            "Epoch 11/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0568 - accuracy: 0.9663 - val_loss: 0.0112 - val_accuracy: 0.9983\n",
            "Epoch 12/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0562 - accuracy: 0.9667 - val_loss: 0.0082 - val_accuracy: 0.9983\n",
            "Epoch 13/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0668 - accuracy: 0.9647 - val_loss: 0.0152 - val_accuracy: 0.9978\n",
            "Epoch 14/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0609 - accuracy: 0.9658 - val_loss: 0.0111 - val_accuracy: 0.9983\n",
            "Epoch 15/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0574 - accuracy: 0.9665 - val_loss: 0.0111 - val_accuracy: 0.9983\n",
            "Epoch 16/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0551 - accuracy: 0.9677 - val_loss: 0.0104 - val_accuracy: 0.9983\n",
            "Epoch 17/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0554 - accuracy: 0.9665 - val_loss: 0.0087 - val_accuracy: 0.9983\n",
            "Epoch 18/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0541 - accuracy: 0.9661 - val_loss: 0.0067 - val_accuracy: 0.9983\n",
            "Epoch 19/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0535 - accuracy: 0.9663 - val_loss: 0.0080 - val_accuracy: 0.9985\n",
            "Epoch 20/100\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.0526 - accuracy: 0.9673 - val_loss: 0.0063 - val_accuracy: 0.9992\n",
            "Epoch 21/100\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.0516 - accuracy: 0.9676 - val_loss: 0.0070 - val_accuracy: 0.9983\n",
            "Epoch 22/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0556 - accuracy: 0.9666 - val_loss: 0.0067 - val_accuracy: 0.9978\n",
            "Epoch 23/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0534 - accuracy: 0.9659 - val_loss: 0.0056 - val_accuracy: 0.9989\n",
            "Epoch 24/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0511 - accuracy: 0.9673 - val_loss: 0.0049 - val_accuracy: 0.9991\n",
            "Epoch 25/100\n",
            "121/121 [==============================] - 2s 18ms/step - loss: 0.0544 - accuracy: 0.9678 - val_loss: 0.0116 - val_accuracy: 0.9919\n",
            "Epoch 26/100\n",
            "121/121 [==============================] - 2s 18ms/step - loss: 0.0515 - accuracy: 0.9671 - val_loss: 0.0134 - val_accuracy: 0.9968\n",
            "Epoch 27/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0533 - accuracy: 0.9670 - val_loss: 0.0052 - val_accuracy: 0.9992\n",
            "Epoch 28/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0519 - accuracy: 0.9674 - val_loss: 0.0056 - val_accuracy: 0.9987\n",
            "Epoch 29/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0529 - accuracy: 0.9677 - val_loss: 0.0045 - val_accuracy: 0.9993\n",
            "Epoch 30/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0514 - accuracy: 0.9670 - val_loss: 0.0047 - val_accuracy: 0.9993\n",
            "Epoch 31/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0502 - accuracy: 0.9675 - val_loss: 0.0032 - val_accuracy: 0.9993\n",
            "Epoch 32/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0517 - accuracy: 0.9671 - val_loss: 0.0132 - val_accuracy: 0.9978\n",
            "Epoch 33/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0518 - accuracy: 0.9679 - val_loss: 0.0028 - val_accuracy: 0.9993\n",
            "Epoch 34/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0486 - accuracy: 0.9672 - val_loss: 0.0028 - val_accuracy: 0.9993\n",
            "Epoch 35/100\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.0511 - accuracy: 0.9668 - val_loss: 0.0034 - val_accuracy: 0.9993\n",
            "Epoch 36/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0524 - accuracy: 0.9655 - val_loss: 0.0046 - val_accuracy: 0.9993\n",
            "Epoch 37/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0499 - accuracy: 0.9677 - val_loss: 0.0028 - val_accuracy: 0.9993\n",
            "Epoch 38/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0487 - accuracy: 0.9676 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
            "Epoch 39/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0488 - accuracy: 0.9677 - val_loss: 0.0289 - val_accuracy: 0.9929\n",
            "Epoch 40/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0529 - accuracy: 0.9672 - val_loss: 0.0025 - val_accuracy: 0.9993\n",
            "Epoch 41/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0485 - accuracy: 0.9685 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
            "Epoch 42/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0502 - accuracy: 0.9669 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
            "Epoch 43/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0499 - accuracy: 0.9677 - val_loss: 0.0025 - val_accuracy: 0.9993\n",
            "Epoch 44/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0492 - accuracy: 0.9676 - val_loss: 0.0029 - val_accuracy: 0.9993\n",
            "Epoch 45/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0482 - accuracy: 0.9666 - val_loss: 0.0030 - val_accuracy: 0.9994\n",
            "Epoch 46/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0507 - accuracy: 0.9672 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
            "Epoch 47/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0493 - accuracy: 0.9671 - val_loss: 0.0031 - val_accuracy: 0.9993\n",
            "Epoch 48/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0474 - accuracy: 0.9675 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
            "Epoch 49/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0492 - accuracy: 0.9665 - val_loss: 0.0031 - val_accuracy: 0.9993\n",
            "Epoch 50/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0490 - accuracy: 0.9676 - val_loss: 0.0021 - val_accuracy: 0.9994\n",
            "Epoch 51/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0476 - accuracy: 0.9684 - val_loss: 0.0027 - val_accuracy: 0.9994\n",
            "Epoch 52/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0478 - accuracy: 0.9676 - val_loss: 0.0024 - val_accuracy: 0.9994\n",
            "Epoch 53/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0485 - accuracy: 0.9674 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
            "Epoch 54/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0477 - accuracy: 0.9677 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
            "Epoch 55/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0478 - accuracy: 0.9678 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
            "Epoch 56/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0483 - accuracy: 0.9678 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
            "Epoch 57/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0484 - accuracy: 0.9674 - val_loss: 0.0027 - val_accuracy: 0.9991\n",
            "Epoch 58/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0491 - accuracy: 0.9671 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
            "Epoch 59/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0489 - accuracy: 0.9670 - val_loss: 0.0031 - val_accuracy: 0.9995\n",
            "Epoch 60/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0486 - accuracy: 0.9676 - val_loss: 0.0021 - val_accuracy: 0.9994\n",
            "Epoch 61/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0728 - accuracy: 0.9605 - val_loss: 0.0428 - val_accuracy: 0.9893\n",
            "Epoch 62/100\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.0631 - accuracy: 0.9652 - val_loss: 0.0106 - val_accuracy: 0.9983\n",
            "Epoch 63/100\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.0564 - accuracy: 0.9663 - val_loss: 0.0085 - val_accuracy: 0.9983\n",
            "Epoch 64/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0520 - accuracy: 0.9672 - val_loss: 0.0049 - val_accuracy: 0.9990\n",
            "Epoch 65/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0500 - accuracy: 0.9676 - val_loss: 0.0039 - val_accuracy: 0.9992\n",
            "Epoch 66/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0496 - accuracy: 0.9683 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
            "Epoch 67/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0487 - accuracy: 0.9672 - val_loss: 0.0033 - val_accuracy: 0.9993\n",
            "Epoch 68/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0481 - accuracy: 0.9676 - val_loss: 0.0030 - val_accuracy: 0.9993\n",
            "Epoch 69/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0484 - accuracy: 0.9677 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
            "Epoch 70/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0499 - accuracy: 0.9671 - val_loss: 0.0062 - val_accuracy: 0.9987\n",
            "Epoch 71/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0516 - accuracy: 0.9672 - val_loss: 0.0033 - val_accuracy: 0.9988\n",
            "Epoch 72/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0491 - accuracy: 0.9671 - val_loss: 0.0030 - val_accuracy: 0.9994\n",
            "Epoch 73/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0480 - accuracy: 0.9679 - val_loss: 0.0020 - val_accuracy: 0.9994\n",
            "Epoch 74/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0477 - accuracy: 0.9679 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
            "Epoch 75/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0476 - accuracy: 0.9675 - val_loss: 0.0028 - val_accuracy: 0.9994\n",
            "Epoch 76/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0486 - accuracy: 0.9679 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
            "Epoch 77/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0480 - accuracy: 0.9674 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
            "Epoch 78/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0476 - accuracy: 0.9679 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
            "Epoch 79/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0459 - accuracy: 0.9684 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 80/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0481 - accuracy: 0.9668 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
            "Epoch 81/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0477 - accuracy: 0.9677 - val_loss: 0.0029 - val_accuracy: 0.9995\n",
            "Epoch 82/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0477 - accuracy: 0.9681 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 83/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0478 - accuracy: 0.9675 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
            "Epoch 84/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0474 - accuracy: 0.9677 - val_loss: 0.0028 - val_accuracy: 0.9995\n",
            "Epoch 85/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0483 - accuracy: 0.9671 - val_loss: 0.0027 - val_accuracy: 0.9995\n",
            "Epoch 86/100\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.0483 - accuracy: 0.9679 - val_loss: 0.0026 - val_accuracy: 0.9995\n",
            "Epoch 87/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0477 - accuracy: 0.9675 - val_loss: 0.0026 - val_accuracy: 0.9994\n",
            "Epoch 88/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0465 - accuracy: 0.9686 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
            "Epoch 89/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0486 - accuracy: 0.9666 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
            "Epoch 90/100\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.0477 - accuracy: 0.9681 - val_loss: 0.0025 - val_accuracy: 0.9993\n",
            "Epoch 91/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0478 - accuracy: 0.9675 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
            "Epoch 92/100\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.0480 - accuracy: 0.9667 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
            "Epoch 93/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0479 - accuracy: 0.9679 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
            "Epoch 94/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0484 - accuracy: 0.9681 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
            "Epoch 95/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0471 - accuracy: 0.9675 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
            "Epoch 96/100\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 0.0471 - accuracy: 0.9688 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
            "Epoch 97/100\n",
            "121/121 [==============================] - 2s 20ms/step - loss: 0.0480 - accuracy: 0.9670 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
            "Epoch 98/100\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 0.0474 - accuracy: 0.9684 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
            "Epoch 99/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0481 - accuracy: 0.9670 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 100/100\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 0.0471 - accuracy: 0.9680 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
            "961/961 [==============================] - 2s 2ms/step - loss: 0.0020 - accuracy: 0.9995\n",
            "[0.001963987946510315, 0.9994792342185974]\n",
            "961/961 [==============================] - 2s 2ms/step\n",
            "[[15340    15]\n",
            " [    1 15368]]\n",
            "0.9994792344746778\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     15355\n",
            "           1       1.00      1.00      1.00     15369\n",
            "\n",
            "    accuracy                           1.00     30724\n",
            "   macro avg       1.00      1.00      1.00     30724\n",
            "weighted avg       1.00      1.00      1.00     30724\n",
            "\n",
            "Training time: 4.76837158203125e-05\n",
            "Test time: 1.6927719116210938e-05\n",
            "\n",
            "TIME: 0.0003037452697753906seconds\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "#from keras.optimizers import SGD\n",
        "#opt = SGD(lr=0.0001)\n",
        "#batch_size = 64\n",
        "\n",
        "# 1. define the network\n",
        "model = Sequential()\n",
        "model.add(LSTM(4,input_shape = X_train[0].shape))  \n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2))\n",
        "\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "#model.add(Dense(1, activation='sigmoid'))\n",
        " \n",
        "model.compile(optimizer=Adam(lr=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_train, y_train, epochs=100, batch_size = 1024, validation_data=(X_test, y_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_test, y_preds_cnn))\n",
        "print(accuracy_score(y_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_preds_cnn))\n",
        "\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1gXRuO8AyKi"
      },
      "source": [
        "**DNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHA_bPIIA05d",
        "outputId": "5448de68-f2ff-4a79-dc66-4b2720ee02f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "121/121 [==============================] - 2s 7ms/step - loss: 0.0565 - accuracy: 0.9874 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
            "Epoch 2/100\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
            "Epoch 3/100\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
            "Epoch 4/100\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
            "Epoch 5/100\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
            "Epoch 6/100\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.1730 - accuracy: 0.9899 - val_loss: 18.3599 - val_accuracy: 0.8949\n",
            "Epoch 7/100\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 0.8443 - accuracy: 0.9936 - val_loss: 0.0066 - val_accuracy: 0.9995\n",
            "Epoch 8/100\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.0033 - val_accuracy: 0.9995\n",
            "Epoch 9/100\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0027 - val_accuracy: 0.9995\n",
            "Epoch 10/100\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
            "Epoch 11/100\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
            "Epoch 12/100\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 13/100\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 14/100\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 15/100\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 16/100\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 17/100\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 18/100\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 19/100\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 20/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 21/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 22/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 23/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 24/100\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 25/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 26/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 27/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 28/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 29/100\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 30/100\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 31/100\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 32/100\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 33/100\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 34/100\n",
            "121/121 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 35/100\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 36/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 37/100\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 38/100\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 39/100\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 40/100\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 41/100\n",
            "121/121 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 42/100\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 43/100\n",
            "121/121 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 44/100\n",
            "121/121 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 45/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 46/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 47/100\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 48/100\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 49/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 50/100\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 51/100\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 52/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 53/100\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 54/100\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 55/100\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 56/100\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 57/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 58/100\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 59/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 60/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 61/100\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 62/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 63/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 64/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 65/100\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 66/100\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 67/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 68/100\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 69/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 70/100\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 71/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 72/100\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 73/100\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 74/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 75/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 76/100\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 77/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 78/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 79/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 80/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 81/100\n",
            "121/121 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 82/100\n",
            "121/121 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
            "Epoch 83/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 84/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 85/100\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 86/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 87/100\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 88/100\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 89/100\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 90/100\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 91/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 92/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 93/100\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 94/100\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 95/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 96/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 97/100\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 98/100\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 99/100\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "Epoch 100/100\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
            "961/961 [==============================] - 1s 1ms/step - loss: 0.0023 - accuracy: 0.9995\n",
            "[0.002259530359879136, 0.9994792342185974]\n",
            "961/961 [==============================] - 1s 854us/step\n",
            "[[15339    16]\n",
            " [    0 15369]]\n",
            "0.9994792344746778\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     15355\n",
            "           1       1.00      1.00      1.00     15369\n",
            "\n",
            "    accuracy                           1.00     30724\n",
            "   macro avg       1.00      1.00      1.00     30724\n",
            "weighted avg       1.00      1.00      1.00     30724\n",
            "\n",
            "Training time: 6.818771362304688e-05\n",
            "Test time: 1.8358230590820312e-05\n",
            "\n",
            "TIME: 0.0003407001495361328seconds\n"
          ]
        }
      ],
      "source": [
        "#from keras.layers import LSTM, SimpleRNN, GRU\n",
        "#from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import time\n",
        "start = time.time()\n",
        "#from keras.optimizers import SGD\n",
        "#opt = SGD(lr=0.0001)\n",
        "#batch_size = 64\n",
        "\n",
        "# 1. define the network\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(37,)),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer=Adam(lr=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_train, y_train, epochs=100, batch_size = 1024, validation_data=(X_test, y_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_test, y_preds_cnn))\n",
        "print(accuracy_score(y_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_preds_cnn))\n",
        "\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6SJBOzJA2q0"
      },
      "source": [
        "**CNN-LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_CWx-zpA8cX",
        "outputId": "6acf26de-3365-42cf-d62a-f98a2c0938a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "121/121 [==============================] - 5s 29ms/step - loss: 0.1034 - accuracy: 0.9683 - val_loss: 0.0251 - val_accuracy: 0.9978\n",
            "Epoch 2/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0218 - accuracy: 0.9953 - val_loss: 0.0118 - val_accuracy: 0.9980\n",
            "Epoch 3/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0124 - accuracy: 0.9980 - val_loss: 0.0110 - val_accuracy: 0.9981\n",
            "Epoch 4/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0114 - accuracy: 0.9981 - val_loss: 0.0097 - val_accuracy: 0.9982\n",
            "Epoch 5/100\n",
            "121/121 [==============================] - 3s 27ms/step - loss: 0.0111 - accuracy: 0.9981 - val_loss: 0.0098 - val_accuracy: 0.9979\n",
            "Epoch 6/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0115 - accuracy: 0.9977 - val_loss: 0.0094 - val_accuracy: 0.9983\n",
            "Epoch 7/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.0083 - val_accuracy: 0.9983\n",
            "Epoch 8/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0404 - accuracy: 0.9859 - val_loss: 0.0475 - val_accuracy: 0.9984\n",
            "Epoch 9/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.2145 - accuracy: 0.9421 - val_loss: 0.0106 - val_accuracy: 0.9984\n",
            "Epoch 10/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0143 - accuracy: 0.9982 - val_loss: 0.0085 - val_accuracy: 0.9983\n",
            "Epoch 11/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0121 - accuracy: 0.9982 - val_loss: 0.0078 - val_accuracy: 0.9983\n",
            "Epoch 12/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0106 - accuracy: 0.9983 - val_loss: 0.0068 - val_accuracy: 0.9984\n",
            "Epoch 13/100\n",
            "121/121 [==============================] - 3s 29ms/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.0065 - val_accuracy: 0.9983\n",
            "Epoch 14/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.0061 - val_accuracy: 0.9984\n",
            "Epoch 15/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.1852 - accuracy: 0.9291 - val_loss: 0.2048 - val_accuracy: 0.9563\n",
            "Epoch 16/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.1048 - accuracy: 0.9772 - val_loss: 0.0649 - val_accuracy: 0.9870\n",
            "Epoch 17/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.2187 - accuracy: 0.9195 - val_loss: 0.3335 - val_accuracy: 0.8703\n",
            "Epoch 18/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.3537 - accuracy: 0.8582 - val_loss: 0.3094 - val_accuracy: 0.8811\n",
            "Epoch 19/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.3211 - accuracy: 0.8782 - val_loss: 0.2928 - val_accuracy: 0.8811\n",
            "Epoch 20/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.1030 - accuracy: 0.9683 - val_loss: 0.0364 - val_accuracy: 0.9917\n",
            "Epoch 21/100\n",
            "121/121 [==============================] - 4s 29ms/step - loss: 0.0399 - accuracy: 0.9910 - val_loss: 0.0461 - val_accuracy: 0.9917\n",
            "Epoch 22/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0457 - accuracy: 0.9921 - val_loss: 0.0441 - val_accuracy: 0.9917\n",
            "Epoch 23/100\n",
            "121/121 [==============================] - 4s 30ms/step - loss: 0.0445 - accuracy: 0.9921 - val_loss: 0.0427 - val_accuracy: 0.9917\n",
            "Epoch 24/100\n",
            "121/121 [==============================] - 4s 34ms/step - loss: 0.0435 - accuracy: 0.9921 - val_loss: 0.0432 - val_accuracy: 0.9917\n",
            "Epoch 25/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0417 - accuracy: 0.9921 - val_loss: 0.0351 - val_accuracy: 0.9917\n",
            "Epoch 26/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0230 - accuracy: 0.9951 - val_loss: 0.0053 - val_accuracy: 0.9989\n",
            "Epoch 27/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0083 - accuracy: 0.9984 - val_loss: 0.0101 - val_accuracy: 0.9981\n",
            "Epoch 28/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0107 - accuracy: 0.9982 - val_loss: 0.0099 - val_accuracy: 0.9983\n",
            "Epoch 29/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0111 - accuracy: 0.9983 - val_loss: 0.0096 - val_accuracy: 0.9983\n",
            "Epoch 30/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0104 - accuracy: 0.9983 - val_loss: 0.0094 - val_accuracy: 0.9983\n",
            "Epoch 31/100\n",
            "121/121 [==============================] - 4s 32ms/step - loss: 0.0103 - accuracy: 0.9983 - val_loss: 0.0093 - val_accuracy: 0.9983\n",
            "Epoch 32/100\n",
            "121/121 [==============================] - 4s 33ms/step - loss: 0.0101 - accuracy: 0.9984 - val_loss: 0.0091 - val_accuracy: 0.9983\n",
            "Epoch 33/100\n",
            "121/121 [==============================] - 4s 34ms/step - loss: 0.0099 - accuracy: 0.9984 - val_loss: 0.0085 - val_accuracy: 0.9983\n",
            "Epoch 34/100\n",
            "121/121 [==============================] - 3s 27ms/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 0.0080 - val_accuracy: 0.9983\n",
            "Epoch 35/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0226 - accuracy: 0.9960 - val_loss: 0.0073 - val_accuracy: 0.9983\n",
            "Epoch 36/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0083 - accuracy: 0.9984 - val_loss: 0.0070 - val_accuracy: 0.9986\n",
            "Epoch 37/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0083 - accuracy: 0.9985 - val_loss: 0.0070 - val_accuracy: 0.9986\n",
            "Epoch 38/100\n",
            "121/121 [==============================] - 3s 27ms/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 0.0063 - val_accuracy: 0.9986\n",
            "Epoch 39/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.0060 - val_accuracy: 0.9986\n",
            "Epoch 40/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 0.0079 - val_accuracy: 0.9984\n",
            "Epoch 41/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.0073 - val_accuracy: 0.9984\n",
            "Epoch 42/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 0.0069 - val_accuracy: 0.9984\n",
            "Epoch 43/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 0.0061 - val_accuracy: 0.9984\n",
            "Epoch 44/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.0066 - val_accuracy: 0.9984\n",
            "Epoch 45/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.0060 - val_accuracy: 0.9984\n",
            "Epoch 46/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.0062 - val_accuracy: 0.9984\n",
            "Epoch 47/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
            "Epoch 48/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0059 - val_accuracy: 0.9984\n",
            "Epoch 49/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.0060 - val_accuracy: 0.9984\n",
            "Epoch 50/100\n",
            "121/121 [==============================] - 3s 27ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
            "Epoch 51/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.0054 - val_accuracy: 0.9984\n",
            "Epoch 52/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.0057 - val_accuracy: 0.9983\n",
            "Epoch 53/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.0072 - val_accuracy: 0.9984\n",
            "Epoch 54/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
            "Epoch 55/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0055 - val_accuracy: 0.9984\n",
            "Epoch 56/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0053 - val_accuracy: 0.9984\n",
            "Epoch 57/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.0057 - val_accuracy: 0.9983\n",
            "Epoch 58/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.8503 - accuracy: 0.6780 - val_loss: 0.5377 - val_accuracy: 0.7332\n",
            "Epoch 59/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.5742 - accuracy: 0.6943 - val_loss: 0.5412 - val_accuracy: 0.7332\n",
            "Epoch 60/100\n",
            "121/121 [==============================] - 3s 27ms/step - loss: 0.5699 - accuracy: 0.7002 - val_loss: 0.5421 - val_accuracy: 0.7330\n",
            "Epoch 61/100\n",
            "121/121 [==============================] - 3s 27ms/step - loss: 0.5688 - accuracy: 0.7016 - val_loss: 0.5405 - val_accuracy: 0.7330\n",
            "Epoch 62/100\n",
            "121/121 [==============================] - 4s 32ms/step - loss: 0.5675 - accuracy: 0.7032 - val_loss: 0.5403 - val_accuracy: 0.7330\n",
            "Epoch 63/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.5698 - accuracy: 0.7027 - val_loss: 0.5412 - val_accuracy: 0.7330\n",
            "Epoch 64/100\n",
            "121/121 [==============================] - 3s 27ms/step - loss: 0.5682 - accuracy: 0.7029 - val_loss: 0.5408 - val_accuracy: 0.7329\n",
            "Epoch 65/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.5700 - accuracy: 0.7011 - val_loss: 0.5407 - val_accuracy: 0.7329\n",
            "Epoch 66/100\n",
            "121/121 [==============================] - 3s 27ms/step - loss: 0.5692 - accuracy: 0.7036 - val_loss: 0.5426 - val_accuracy: 0.7329\n",
            "Epoch 67/100\n",
            "121/121 [==============================] - 3s 27ms/step - loss: 0.5687 - accuracy: 0.7035 - val_loss: 0.5452 - val_accuracy: 0.7329\n",
            "Epoch 68/100\n",
            "121/121 [==============================] - 3s 27ms/step - loss: 0.5675 - accuracy: 0.7039 - val_loss: 0.5402 - val_accuracy: 0.7329\n",
            "Epoch 69/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.5683 - accuracy: 0.7041 - val_loss: 0.5406 - val_accuracy: 0.7329\n",
            "Epoch 70/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.5695 - accuracy: 0.7036 - val_loss: 0.5408 - val_accuracy: 0.7329\n",
            "Epoch 71/100\n",
            "121/121 [==============================] - 3s 27ms/step - loss: 0.5672 - accuracy: 0.7035 - val_loss: 0.5422 - val_accuracy: 0.7329\n",
            "Epoch 72/100\n",
            "121/121 [==============================] - 3s 27ms/step - loss: 0.5685 - accuracy: 0.7038 - val_loss: 0.5454 - val_accuracy: 0.7329\n",
            "Epoch 73/100\n",
            "121/121 [==============================] - 3s 27ms/step - loss: 0.5689 - accuracy: 0.7032 - val_loss: 0.5410 - val_accuracy: 0.7330\n",
            "Epoch 74/100\n",
            "121/121 [==============================] - 4s 35ms/step - loss: 0.3883 - accuracy: 0.8192 - val_loss: 0.1421 - val_accuracy: 0.9416\n",
            "Epoch 75/100\n",
            "121/121 [==============================] - 4s 29ms/step - loss: 0.4083 - accuracy: 0.8139 - val_loss: 0.2891 - val_accuracy: 0.8947\n",
            "Epoch 76/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.3204 - accuracy: 0.8831 - val_loss: 0.2789 - val_accuracy: 0.8950\n",
            "Epoch 77/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.3113 - accuracy: 0.8871 - val_loss: 0.2738 - val_accuracy: 0.8950\n",
            "Epoch 78/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.3091 - accuracy: 0.8864 - val_loss: 0.2735 - val_accuracy: 0.8950\n",
            "Epoch 79/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.3025 - accuracy: 0.8867 - val_loss: 0.2999 - val_accuracy: 0.8950\n",
            "Epoch 80/100\n",
            "121/121 [==============================] - 3s 27ms/step - loss: 0.3041 - accuracy: 0.8839 - val_loss: 0.2701 - val_accuracy: 0.8950\n",
            "Epoch 81/100\n",
            "121/121 [==============================] - 3s 27ms/step - loss: 0.2986 - accuracy: 0.8865 - val_loss: 0.2727 - val_accuracy: 0.8950\n",
            "Epoch 82/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.3023 - accuracy: 0.8845 - val_loss: 0.2705 - val_accuracy: 0.8950\n",
            "Epoch 83/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.3003 - accuracy: 0.8850 - val_loss: 0.2791 - val_accuracy: 0.8950\n",
            "Epoch 84/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.3015 - accuracy: 0.8855 - val_loss: 0.2693 - val_accuracy: 0.8950\n",
            "Epoch 85/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.2995 - accuracy: 0.8863 - val_loss: 0.2698 - val_accuracy: 0.8950\n",
            "Epoch 86/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.2983 - accuracy: 0.8866 - val_loss: 0.2856 - val_accuracy: 0.8950\n",
            "Epoch 87/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.3021 - accuracy: 0.8844 - val_loss: 0.2838 - val_accuracy: 0.8409\n",
            "Epoch 88/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.3428 - accuracy: 0.8517 - val_loss: 0.0784 - val_accuracy: 0.9873\n",
            "Epoch 89/100\n",
            "121/121 [==============================] - 3s 29ms/step - loss: 0.0761 - accuracy: 0.9798 - val_loss: 0.0155 - val_accuracy: 0.9981\n",
            "Epoch 90/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.1688 - accuracy: 0.9365 - val_loss: 0.5283 - val_accuracy: 0.8300\n",
            "Epoch 91/100\n",
            "121/121 [==============================] - 3s 27ms/step - loss: 0.3768 - accuracy: 0.8131 - val_loss: 0.0511 - val_accuracy: 0.9970\n",
            "Epoch 92/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.1279 - accuracy: 0.9410 - val_loss: 0.0295 - val_accuracy: 0.9970\n",
            "Epoch 93/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.1111 - accuracy: 0.9532 - val_loss: 0.0246 - val_accuracy: 0.9970\n",
            "Epoch 94/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.1061 - accuracy: 0.9538 - val_loss: 0.0220 - val_accuracy: 0.9970\n",
            "Epoch 95/100\n",
            "121/121 [==============================] - 3s 29ms/step - loss: 0.1061 - accuracy: 0.9523 - val_loss: 0.0209 - val_accuracy: 0.9970\n",
            "Epoch 96/100\n",
            "121/121 [==============================] - 3s 27ms/step - loss: 0.1053 - accuracy: 0.9526 - val_loss: 0.0195 - val_accuracy: 0.9970\n",
            "Epoch 97/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.1034 - accuracy: 0.9520 - val_loss: 0.0172 - val_accuracy: 0.9970\n",
            "Epoch 98/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0730 - accuracy: 0.9696 - val_loss: 0.0080 - val_accuracy: 0.9983\n",
            "Epoch 99/100\n",
            "121/121 [==============================] - 3s 28ms/step - loss: 0.0412 - accuracy: 0.9833 - val_loss: 0.0064 - val_accuracy: 0.9984\n",
            "Epoch 100/100\n",
            "121/121 [==============================] - 3s 27ms/step - loss: 0.0272 - accuracy: 0.9930 - val_loss: 0.0066 - val_accuracy: 0.9984\n",
            "961/961 [==============================] - 2s 2ms/step - loss: 0.0066 - accuracy: 0.9984\n",
            "[0.006609157659113407, 0.9983726143836975]\n",
            "961/961 [==============================] - 2s 2ms/step\n",
            "[[15323    32]\n",
            " [   18 15351]]\n",
            "0.998372607733368\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     15355\n",
            "           1       1.00      1.00      1.00     15369\n",
            "\n",
            "    accuracy                           1.00     30724\n",
            "   macro avg       1.00      1.00      1.00     30724\n",
            "weighted avg       1.00      1.00      1.00     30724\n",
            "\n",
            "Training time: 7.486343383789062e-05\n",
            "Test time: 3.457069396972656e-05\n",
            "\n",
            "TIME: 0.0004286766052246094seconds\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda\n",
        "\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, Dense, Dropout, Flatten, MaxPooling1D\n",
        "\n",
        "from keras.layers import LSTM, GRU, SimpleRNN\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "lstm_output_size = 20\n",
        "model = Sequential()\n",
        "model.add(Conv1D(32, 2, activation='relu', input_shape = X_train[0].shape))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(SimpleRNN(lstm_output_size))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "#model.add(Dense(1, activation='sigmoid'))\n",
        "    #])\n",
        "model.compile(optimizer=Adam(lr=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "   \n",
        "model.fit(X_train, y_train, epochs=100, batch_size = 1024, validation_data=(X_test, y_test), verbose=1)\n",
        "    \n",
        "print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "y_preds_cnn = model.predict(X_test)\n",
        "y_preds_cnn = np.round(y_preds_cnn)\n",
        "    \n",
        "\n",
        "    #y_preds_cnn = model.predict(X_test)\n",
        "    #y_preds_cnn = np.round(y_preds_cnn)\n",
        "cm = confusion_matrix(y_test, y_preds_cnn)\n",
        "print(confusion_matrix(y_test, y_preds_cnn))\n",
        "print(accuracy_score(y_test, y_preds_cnn))\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_preds_cnn))\n",
        "\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "start_time = time.time()\n",
        "end = time.time()\n",
        "diff=end-start\n",
        "starttest = time.time()  \n",
        "endtest =time.time()\n",
        "difftest = endtest-starttest\n",
        "\n",
        "endtest =time.time()\n",
        "#difftest = endtest-starttest\n",
        "print(\"Training time: \" + str(diff))\n",
        "print(\"Test time: \" + str(difftest))\n",
        "time_required = time.time() - start_time\n",
        "print('\\nTIME: {}seconds'.format(time_required))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "cu2ypkwsdlXF",
        "7zkiPlEhj59T",
        "nPvdsaOhkBxo",
        "vZ0fCskRGW7Z",
        "cjq7JjuUtC_f",
        "9o50lmOO_EId",
        "CfvVRjnuAiTs"
      ],
      "mount_file_id": "1-RdU_A7CeDurhzMIi6P7sPRA-rqE_tOk",
      "authorship_tag": "ABX9TyO5EeUOdVKs8Imcgr5MEN1j",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}